{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/examples/generative/ipynb/ddim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IDEAS \n",
        "1.   Normalization in embedding ?\n",
        "2.   Formula when I replace beta by t\n",
        "3.   Use keras inference for potential changes\n",
        "\n",
        "## What to try next?\n",
        "\n",
        "If you would like to dive in deeper to the topic, a recommend checking out\n",
        "[this repository](https://github.com/beresandras/clear-diffusion-keras) that I created in\n",
        "preparation for this code example, which implements a wider range of features in a\n",
        "similar style, such as:\n",
        "\n",
        "* stochastic sampling\n",
        "* second-order sampling based on the\n",
        "[differential equation view of DDIMs (Equation 13)](https://arxiv.org/abs/2010.02502)\n",
        "* more diffusion schedules\n",
        "* more network output types: predicting image or\n",
        "[velocity (Appendix D)](https://arxiv.org/abs/2202.00512) instead of noise\n",
        "* more datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rge41L-HIY-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkfNOJcD0Ym"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "    \n",
        "    %cd {REPO_DIR}\n"
      ],
      "metadata": {
        "id": "cqPH8VxsGGrb",
        "outputId": "b8d88e0e-3751-41c4-af86-8ad0e501c521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'flumy-wgan-mines'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 146 (delta 31), reused 74 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 140.19 MiB | 11.53 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (121/121), done.\n",
            "/content/flumy-wgan-mines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "R3E8qnnCGH5K",
        "outputId": "7700aa56-ef46-4423-c8b8-61ad4229446d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "2VQcRg8KD0Yn"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from data.load_data import load_data\n",
        "from utils.visualisation import get_color_map\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "1eF1rmySGCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful constants\n",
        "image_size = (64, 128)\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "facies_names = np.array([\"Sand, Channel lag\", \"Sand, Point bar\", \"Silts, Levee\", \"Shale, Overbank\"])\n",
        "x = load_data(image_size[0], image_size[1], \"./data/horizontal/dataFlumyHoriz.csv\")\n",
        "x_train = x[:2760]\n",
        "x_test = x[2760:]"
      ],
      "metadata": {
        "id": "4yPyDmhUGCTa"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-ElzPrD0Yq"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "FBoSc7iCD0Ys"
      },
      "outputs": [],
      "source": [
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "embedding_dims = 32\n",
        "embedding_max_frequency = 1000.0\n",
        "widths = [32, 64, 128, 256]\n",
        "block_depth = 2\n",
        "\n",
        "# Data values embedding\n",
        "img_embed_size = 24\n",
        "categories_nb = 4\n",
        "\n",
        "# optimization\n",
        "batch_size = 30\n",
        "ema = 0.999\n",
        "learning_rate = 1e-4\n",
        "embeding_net_lr = 1e-3\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(tf.keras.layers.Layer):\n",
        "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights during initialization. These weights are fixed \n",
        "        # during optimization and are not trainable.\n",
        "        self.W = self.add_weight(shape=(embed_dim // 2,),\n",
        "                                 trainable=False,\n",
        "                                 initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.), name=\"GFP\") * tf.constant(scale, dtype=tf.float32)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        x_proj = x * self.W * tf.constant(2., dtype=tf.float32) * tf.constant(np.pi, dtype=tf.float32)\n",
        "        y = tf.concat([tf.math.sin(x_proj), tf.cos(x_proj)], axis=-1)\n",
        "        return y # Probleme vient pas de l√† :()\n",
        "\n",
        "class CustomLinear(tf.keras.layers.Layer):\n",
        "    \"\"\"Rhaaah.\"\"\"  \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.W = tf.random.uniform((input_dim, output_dim), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "        self.b = tf.random.uniform((1, output_dim, ), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = tf.tensordot(x, self.W, 1) + self.b\n",
        "        y = tf.keras.activations.gelu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "@tf.function\n",
        "def embedding_normalization(logits):\n",
        "    # normalement vont avoir taille (batch_size, sequence_size, embedding_size)\n",
        "    # axis=-1 is embedding normalement\n",
        "    return (logits / tf.norm(logits, axis=-1, keepdims=True)) * tf.constant(np.sqrt(logits.shape[-1]), dtype=tf.float32)\n",
        "\n",
        "class NormalizedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\"\"\"  \n",
        "    def __init__(self, categories_nb, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.embed_layer = tf.keras.layers.Embedding(categories_nb, img_embed_size)\n",
        "        self.embed_layer2 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer3 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer4 = layers.Conv2D(img_embed_size, kernel_size=1, activation=None)\n",
        "        self.layer_norm = layer = tf.keras.layers.LayerNormalization(axis=[1, 2])\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = self.embed_layer(x)\n",
        "        y = self.embed_layer2(y)\n",
        "        y = self.embed_layer3(y)\n",
        "        y = self.embed_layer4(y)\n",
        "        y = embedding_normalization(y)\n",
        "        y = self.layer_norm(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "Ej4nARwoGmme"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "7V5eQBuUD0Y0"
      },
      "outputs": [],
      "source": [
        "def sinusoidal_embedding(x):\n",
        "    embedding_min_frequency = 1.0\n",
        "    frequencies = tf.exp(\n",
        "        tf.linspace(\n",
        "            tf.math.log(embedding_min_frequency),\n",
        "            tf.math.log(embedding_max_frequency),\n",
        "            embedding_dims // 2,\n",
        "        )\n",
        "    )\n",
        "    angular_speeds = 2.0 * math.pi * frequencies\n",
        "    embeddings = tf.concat(\n",
        "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
        "    )\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3]\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
        "        x = layers.Conv2D(\n",
        "            width, kernel_size=3, padding=\"same\", activation=keras.activations.swish\n",
        "        )(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def DownBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        for _ in range(block_depth):\n",
        "            x = ResidualBlock(width)(x)\n",
        "            skips.append(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def UpBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "        for _ in range(block_depth):\n",
        "            x = layers.Concatenate()([x, skips.pop()])\n",
        "            x = ResidualBlock(width)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def get_network(image_size, widths, block_depth, embed_size):\n",
        "    noisy_images = keras.Input(shape=(image_size[0], image_size[1], embed_size))\n",
        "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "    e = layers.UpSampling2D(size=image_size, interpolation=\"nearest\")(e)\n",
        "\n",
        "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
        "    x = layers.Concatenate()([x, e])\n",
        "\n",
        "    skips = []\n",
        "    for width in widths[:-1]:\n",
        "        x = DownBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1])(x)\n",
        "\n",
        "    for width in reversed(widths[:-1]):\n",
        "        x = UpBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    x = layers.Conv2D(4, kernel_size=1, kernel_initializer=\"zeros\", activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "lZ37576YD0Y5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth, img_embed_size, categories_nb, embedding_lr=1e-3, batch_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = get_network(image_size, widths, block_depth, img_embed_size)\n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Embedding\n",
        "        self.img_embed_size = img_embed_size\n",
        "        self.embedding_layer = NormalizedEmbedding(categories_nb, img_embed_size)\n",
        "        self.emb_optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=embedding_lr)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.image_loss_tracker]\n",
        "\n",
        "\n",
        "    def diffusion_schedule(self, diffusion_times):\n",
        "        # diffusion times -> angles\n",
        "        start_angle = tf.acos(max_signal_rate)\n",
        "        end_angle = tf.acos(min_signal_rate)\n",
        "\n",
        "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "\n",
        "        # angles -> signal and noise rates\n",
        "        signal_rates = tf.cos(diffusion_angles)\n",
        "        noise_rates = tf.sin(diffusion_angles)\n",
        "        # note that their squared sum is always: sin^2(x) + cos^2(x) = 1\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
        "        # the exponential moving average weights are used at evaluation\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        # predict noise component and calculate the image component using it\n",
        "        pred_images = network([noisy_images, noise_rates**2], training=training)\n",
        "\n",
        "        return pred_images\n",
        "\n",
        "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "        # reverse diffusion = sampling\n",
        "        num_images = initial_noise.shape[0]\n",
        "        step_size = 1.0 / diffusion_steps\n",
        "\n",
        "        # important line:\n",
        "        # at the first sampling step, the \"noisy image\" is pure noise\n",
        "        # but its signal rate is assumed to be nonzero (min_signal_rate)\n",
        "        next_noisy_images = initial_noise\n",
        "        for step in range(diffusion_steps):\n",
        "            noisy_images = next_noisy_images\n",
        "\n",
        "            # separate the current noisy image to its components\n",
        "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
        "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=False\n",
        "            )\n",
        "            # network used in eval mode\n",
        "\n",
        "            # remix the predicted components using the next signal and noise rates\n",
        "            next_diffusion_times = diffusion_times - step_size\n",
        "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
        "                next_diffusion_times\n",
        "            )\n",
        "            next_noisy_images = (\n",
        "                next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
        "            )\n",
        "            # this new noisy image will be used in the next step\n",
        "\n",
        "        return pred_images\n",
        "\n",
        "    def generate(self, num_images, diffusion_steps):\n",
        "        # noise -> images -> denormalized images\n",
        "        initial_noise = tf.random.normal(shape=(num_images, image_size, image_size, 3))\n",
        "        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
        "        generated_images = self.denormalize(generated_images)\n",
        "        return generated_images\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            embed_images = self.embedding_layer(int_encoded_img)\n",
        "            noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True\n",
        "            )\n",
        "\n",
        "            image_loss = self.loss(images, pred_images)  # training loss\n",
        "            \n",
        "\n",
        "        gradients_model = tape1.gradient(image_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.network.trainable_weights))\n",
        "\n",
        "        gradients_embeddings = tape2.gradient(image_loss, self.embedding_layer.trainable_weights)\n",
        "        self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        # KID is not measured during the training phase for computational efficiency\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        embed_images = self.embedding_layer(int_encoded_img)\n",
        "\n",
        "        #std = marginal_prob_std(diffusion_times, sigma=sigma)\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "        #noisy_images = embed_images + noises * tf.reshape(std, (-1, 1, 1, 1))\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_images = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False\n",
        "        )\n",
        "\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYrG2VPD0Y7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "LHcHZit9D0Y8"
      },
      "outputs": [],
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth, img_embed_size=img_embed_size, categories_nb=categories_nb)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate,\n",
        "    ),\n",
        "    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, batch_size=batch_size, epochs=50, validation_data=(x_test,))"
      ],
      "metadata": {
        "id": "RDSktS3wIy4C",
        "outputId": "978312e9-08fa-4dae-a075-2176464c527a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "92/92 [==============================] - 42s 227ms/step - i_loss: 0.6599 - val_i_loss: 1.3856\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 20s 222ms/step - i_loss: 0.2336 - val_i_loss: 1.3850\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 21s 224ms/step - i_loss: 0.1244 - val_i_loss: 1.3827\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 21s 228ms/step - i_loss: 0.0918 - val_i_loss: 1.3745\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 20s 222ms/step - i_loss: 0.0749 - val_i_loss: 1.3560\n",
            "Epoch 6/50\n",
            "12/92 [==>...........................] - ETA: 17s - i_loss: 0.0685"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6ewS3D0Y-"
      },
      "source": [
        "## Inference"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddim",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}