{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wgan2d_horizontal_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/wgan2d_gs_horizontal_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I86cGpU7BzZc"
      },
      "source": [
        "# Wasserstein GAN with Spectral Norm and MaxSort Activation (WGAN-GS)\n",
        "(source paper : https://proceedings.mlr.press/v97/anil19a.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install deel.lip"
      ],
      "metadata": {
        "id": "OZuCjVFpVa29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d47d6e8-9abb-4863-c052-f22300908a0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deel.lip\n",
            "  Downloading deel_lip-1.4.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m512.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deel.lip) (1.22.4)\n",
            "Requirement already satisfied: tensorflow~=2.2 in /usr/local/lib/python3.10/dist-packages (from deel.lip) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.2->deel.lip) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.2.2)\n",
            "Installing collected packages: deel.lip\n",
            "Successfully installed deel.lip-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "2S1mBEC41CUm",
        "outputId": "846f0bfe-4052-4afb-8e26-da736134a7e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/612.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m532.5/612.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gb9PaarB1sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450412f5-b27e-4175-b653-52c795c06265"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import image\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.layers import Dense, Conv2D, InputSpec\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deel.lip.activations import GroupSort\n",
        "from deel.lip.layers import (\n",
        "    InvertibleDownSampling,\n",
        ")\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "import math\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DenseSN(Dense):\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[-1]\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                 initializer=initializers.RandomNormal(0, 1),\n",
        "                                 name='sn',\n",
        "                                 trainable=False)\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "\n",
        "        def power_iteration(W, u):\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        # Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        # Calculate Sigma\n",
        "        sigma = K.dot(_v, W_reshaped)\n",
        "        sigma = K.dot(sigma, K.transpose(_u))\n",
        "        # normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        # reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "        output = K.dot(inputs, W_bar)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ConvSN2D(Conv2D):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                 initializer=initializers.RandomNormal(0, 1),\n",
        "                                 name='sn',\n",
        "                                 trainable=False)\n",
        "\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "\n",
        "        def power_iteration(W, u):\n",
        "            # Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "\n",
        "        # Spectral Normalization\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        # Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        # Calculate Sigma\n",
        "        sigma = K.dot(_v, W_reshaped)\n",
        "        sigma = K.dot(sigma, K.transpose(_u))\n",
        "        # normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        # reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "\n",
        "        outputs = K.conv2d(\n",
        "            inputs,\n",
        "            W_bar,\n",
        "            strides=self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format,\n",
        "            dilation_rate=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "oMvJCVelS66C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def maxsort(x):\n",
        "    return GroupSort(2)(x)\n",
        "\n",
        "\n",
        "class StationaryWasserteinApprox(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(StationaryWasserteinApprox, self).__init__()\n",
        "        self.conv = ConvSN2D(filters=1, kernel_size=(3, 3), strides=(1, 1), padding='valid')\n",
        "\n",
        "    def call(self, x):\n",
        "        y = self.conv(x)\n",
        "        y = tf.math.reduce_mean(y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class InitialDiscriminatorBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, features, kernel_size=(3, 3), avg_pooling=(2, 2), padding=\"same\", name=\"initial-disc-block\"):\n",
        "        super(InitialDiscriminatorBlock, self).__init__()\n",
        "\n",
        "        self.conv_1 = ConvSN2D(filters=features, kernel_size=kernel_size,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv1\")\n",
        "\n",
        "        self.conv_2 = ConvSN2D(filters=features, kernel_size=kernel_size,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv2\")\n",
        "\n",
        "        self.avg_pool = InvertibleDownSampling(pool_size=avg_pooling, name=name + \"-avg-pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.conv_1(inputs)\n",
        "        y = self.conv_2(y)\n",
        "        y = self.avg_pool(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class DiscriminatorBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, features, kernel_size=(3, 3), avg_pooling=(2, 2), padding=\"same\", name=\"inter-disc-block\"):\n",
        "        super(DiscriminatorBlock, self).__init__()\n",
        "\n",
        "        self.conv_1 = ConvSN2D(filters=features, kernel_size=kernel_size,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv1\")\n",
        "\n",
        "        self.conv_2 = ConvSN2D(filters=features, kernel_size=kernel_size,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv2\")\n",
        "\n",
        "        self.avg_pool = InvertibleDownSampling(pool_size=avg_pooling, name=name + \"-avg-pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.conv_1(inputs)\n",
        "        y = self.conv_2(y)\n",
        "        y = self.avg_pool(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class FinalDiscriminatorBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, features, kernel_size_1=(3, 3), kernel_size_2=(3, 3), padding=\"same\", name=\"final-disc-block\"):\n",
        "        super(FinalDiscriminatorBlock, self).__init__()\n",
        "\n",
        "        self.conv_1 = ConvSN2D(filters=features, kernel_size=kernel_size_1,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv1\")\n",
        "\n",
        "        self.conv_2 = ConvSN2D(filters=features, kernel_size=kernel_size_2,\n",
        "                               strides=(1, 1), padding=padding,\n",
        "                               activation=maxsort,\n",
        "                               name=name + \"-conv2\")\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(1, name=\"disc-dense-output\", activation=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.conv_1(inputs)\n",
        "        y = self.conv_2(y)\n",
        "        y = self.dense(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "def get_wgs_discriminator_model(input_dims, kernel_size=(3, 3), layers_features=None):\n",
        "    if layers_features is None:\n",
        "        layers_features = [16, 32, 64, 128, 256]\n",
        "\n",
        "    padding = \"same\"\n",
        "\n",
        "    x_high_res = tf.keras.layers.Input(shape=(input_dims[0], input_dims[1], input_dims[2]))\n",
        "\n",
        "    y = InitialDiscriminatorBlock(layers_features[0], kernel_size=kernel_size)(x_high_res)\n",
        "    y = DiscriminatorBlock(layers_features[1], kernel_size=kernel_size, padding=padding, name=\"disc-block-1\")(y)\n",
        "    y = DiscriminatorBlock(layers_features[2], kernel_size=kernel_size, padding=padding, name=\"disc-block-2\")(y)\n",
        "    y = DiscriminatorBlock(layers_features[3], kernel_size=kernel_size, padding=padding, avg_pooling=(1, 1),\n",
        "                           name=\"disc-block-3\")(y)\n",
        "    y = FinalDiscriminatorBlock(layers_features[4], kernel_size_1=kernel_size, padding=padding)(y)\n",
        "\n",
        "    d_model = keras.models.Model(x_high_res, y, name=\"discriminator\")\n",
        "    return d_model"
      ],
      "metadata": {
        "id": "Suk2Xc3LShdk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class GeneratorInitial(tf.keras.layers.Layer):\n",
        "    # First layer of the Multi-Scale Generator\n",
        "    # It is a simple convolution, but without skip connection, 256 channels and a large kernel size\n",
        "    def __init__(self, features=4, kernel_size=(3, 3), padding=\"valid\"):\n",
        "        super(GeneratorInitial, self).__init__()\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "        self.conv = tf.keras.layers.Conv2D(filters=features, kernel_size=kernel_size,\n",
        "                                           strides=(1, 1), activation=\"relu\", padding=padding, name=\"gen-init-conv\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.conv(inputs)\n",
        "        y = self.batch_norm(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class GeneratorBlock(tf.keras.layers.Layer):\n",
        "    # Intermediate layers of the Multi-Scale Generator\n",
        "    # This block has: One upsampling layer, two convolutions,\n",
        "    # one skip connections and a Batch Normalisation\n",
        "    def __init__(self, features, output_features, upsampling_size=(1, 1), kernel_size=(3, 3), padding=\"valid\",\n",
        "                 name=\"gen-block\"):\n",
        "        super(GeneratorBlock, self).__init__()\n",
        "        self.upsample = tf.keras.layers.UpSampling2D(size=upsampling_size,\n",
        "                                                     interpolation='nearest',\n",
        "                                                     name=name + \"-upsampling\")\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(filters=features, kernel_size=kernel_size,\n",
        "                                             strides=(1, 1), padding=padding,\n",
        "                                             activation=tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "                                             name=name + \"-conv1\")\n",
        "\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(filters=features, kernel_size=kernel_size,\n",
        "                                             strides=(1, 1), padding=padding,\n",
        "                                             activation=tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "                                             name=name + \"-conv2\")\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.upsample(inputs)\n",
        "        y = self.conv_1(y)\n",
        "        y = self.batch_norm(y)\n",
        "        y = self.conv_2(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class LastGeneratorBlock(tf.keras.layers.Layer):\n",
        "    # Last block of the Multi-Scale Generator model\n",
        "    # Same as intermediate blocks but without skip connections\n",
        "    # The resizing method is also changed to bilinear for a smoother result\n",
        "    def __init__(self, features, output_features, kernel_size=(3, 3), upsampling=(1, 1), padding=\"valid\",\n",
        "                 name=\"gen-fin-block\"):\n",
        "        super(LastGeneratorBlock, self).__init__()\n",
        "        self.upsample = tf.keras.layers.UpSampling2D(size=upsampling,\n",
        "                                                     interpolation='bilinear',\n",
        "                                                     name=name + \"-upsampling\")\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(filters=features, kernel_size=kernel_size,\n",
        "                                             strides=(1, 1), padding=padding,\n",
        "                                             activation=tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "                                             name=name + \"-conv1\")\n",
        "\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(filters=output_features, kernel_size=kernel_size,\n",
        "                                             strides=(1, 1), padding=padding, activation=None,\n",
        "                                             name=name + \"-final-conv\")\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization(momentum=0.9)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Conv\n",
        "        y = self.upsample(inputs)\n",
        "        y = self.conv_1(y)\n",
        "        y = self.batch_norm(y)\n",
        "        y = self.conv_2(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class WassersteinGSGenerator(tf.keras.Model):\n",
        "    def __init__(self, output_dims, kernel_size=(3, 3), layers_features=None):\n",
        "        \"\"\"\n",
        "        Generator class for Multi-Scale model\n",
        "        Args:\n",
        "            output_dims: tuple (h, w, c) giving the dimensions\n",
        "            kernel_size: dimension of convolution kernels\n",
        "        \"\"\"\n",
        "        super(WassersteinGSGenerator, self).__init__()\n",
        "        if layers_features is None:\n",
        "            layers_features = [4, 64, 32, 16, 4]\n",
        "        padding = \"same\"\n",
        "        output_features = output_dims[-1]\n",
        "\n",
        "        self.block_1 = GeneratorInitial(layers_features[0], kernel_size=kernel_size, padding=padding)\n",
        "        self.block_2 = GeneratorBlock(layers_features[1], output_features, upsampling_size=(1, 1),\n",
        "                                      kernel_size=kernel_size, padding=padding, name=\"gen-block-1\")\n",
        "        self.block_3 = GeneratorBlock(layers_features[2], output_features, upsampling_size=(1, 1),\n",
        "                                      kernel_size=kernel_size, padding=padding, name=\"gen-block-2\")\n",
        "        self.block_4 = GeneratorBlock(layers_features[3], output_features, upsampling_size=(1, 1),\n",
        "                                      kernel_size=kernel_size, padding=padding, name=\"gen-block-3\")\n",
        "        self.block_5 = LastGeneratorBlock(layers_features[-1], output_features, kernel_size=kernel_size,\n",
        "                                          padding=padding)\n",
        "\n",
        "        self.generator_blocks = [self.block_1, self.block_2, self.block_3, self.block_4, self.block_5]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = self.block_1(inputs)\n",
        "\n",
        "        for i in range(1, len(self.generator_blocks) - 1):\n",
        "            y = self.generator_blocks[i](y)\n",
        "\n",
        "        y = self.generator_blocks[-1](y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "ddoFBvBjSq7a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network(\n",
        "    image_size,\n",
        "    block_depth,\n",
        "    widths,\n",
        "    attentions,\n",
        "    patch_size,\n",
        "):\n",
        "    def ResidualBlock(width, attention):\n",
        "        def forward(x):\n",
        "            input_width = x.shape[3]\n",
        "            if input_width == width:\n",
        "                residual = x\n",
        "            else:\n",
        "                residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([residual, x])\n",
        "\n",
        "            if attention:\n",
        "                residual = x\n",
        "                x = tfa.layers.GroupNormalization(groups=8, center=False, scale=False)(\n",
        "                    x\n",
        "                )\n",
        "                x = layers.MultiHeadAttention(\n",
        "                    num_heads=4, key_dim=width, attention_axes=(1, 2)\n",
        "                )(x, x)\n",
        "\n",
        "                x = layers.Add()([residual, x])\n",
        "\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def DownBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, skips = x\n",
        "            for _ in range(block_depth):\n",
        "                x = ResidualBlock(width, attention)(x)\n",
        "                skips.append(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def UpBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, skips = x\n",
        "            x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "            for _ in range(block_depth):\n",
        "                x = layers.Concatenate()([x, skips.pop()])\n",
        "                x = ResidualBlock(width, attention)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    images = keras.Input(shape=(None, None, 3))\n",
        "    x = layers.Conv2D(64, kernel_size=patch_size, strides=patch_size)(\n",
        "        images\n",
        "    )\n",
        "\n",
        "    skips = []\n",
        "    for width, attention in zip(widths[:-1], attentions[:-1]):\n",
        "        x = DownBlock(block_depth, width, attention)([x, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1], attentions[-1])(x)\n",
        "\n",
        "    for width, attention in zip(widths[-2::-1], attentions[-2::-1]):\n",
        "        x = UpBlock(block_depth, width, attention)([x, skips])\n",
        "\n",
        "    x = layers.Conv2DTranspose(\n",
        "        widths[-1], kernel_size=patch_size, strides=patch_size, activation=None\n",
        "    )(x)\n",
        "\n",
        "    x = LastGeneratorBlock(3, 3, kernel_size=(3, 3), padding=\"same\")(x)\n",
        "\n",
        "    return keras.Model(images, x, name=\"residual_unet\")"
      ],
      "metadata": {
        "id": "i7ATOxpN0bmj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.config.run_functions_eagerly(True)\n",
        "\n",
        "\n",
        "def discriminator_loss(real_img, fake_img):\n",
        "    real_loss = tf.reduce_mean(real_img)\n",
        "    fake_loss = tf.reduce_mean(fake_img)\n",
        "    return fake_loss - real_loss\n",
        "\n",
        "\n",
        "def generator_loss(fake_img):\n",
        "    return -tf.reduce_mean(fake_img)\n",
        "\n",
        "\n",
        "class WassersteinGANGS(keras.Model):\n",
        "    \"\"\"\n",
        "    WGAN-GS (Wasserstein Generative Adversarial Network) Spectral Norm and MaxSort Activation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, discriminator, generator, latent_shape, discriminator_extra_steps=3, generator_extra_steps=1):\n",
        "        super(WassersteinGANGS, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_shape = latent_shape\n",
        "        self.d_steps = discriminator_extra_steps\n",
        "        self.g_steps = generator_extra_steps\n",
        "        self.d_optimizer = None\n",
        "        self.g_optimizer = None\n",
        "        self.d_loss_fn = None\n",
        "        self.g_loss_fn = None\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn=discriminator_loss, g_loss_fn=generator_loss):\n",
        "        super(WassersteinGANGS, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_fn = d_loss_fn\n",
        "        self.g_loss_fn = g_loss_fn\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, *self.latent_shape))\n",
        "        generated_images = self.generator(random_latent_vectors, training=True)\n",
        "        return generated_images\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        for i in range(self.d_steps):\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, *self.latent_shape))\n",
        "            with tf.GradientTape() as tape:\n",
        "                fake_images = self.generator(random_latent_vectors, training=True)\n",
        "                fake_logits = self.discriminator(fake_images, training=True)\n",
        "                real_logits = self.discriminator(real_images, training=True)\n",
        "\n",
        "                d_loss = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
        "                d_loss = d_loss + 0.0001 * tf.reduce_mean(tf.square(tf.stack([fake_logits, real_logits], axis=0)))\n",
        "\n",
        "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(d_gradient, self.discriminator.trainable_variables)\n",
        "            )\n",
        "\n",
        "        for i in range(self.g_steps):\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, *self.latent_shape))\n",
        "            with tf.GradientTape() as tape:\n",
        "                generated_images = self.generator(random_latent_vectors, training=True)\n",
        "                gen_img_logits = self.discriminator(generated_images, training=True)\n",
        "                g_loss = self.g_loss_fn(gen_img_logits)\n",
        "\n",
        "            gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "            self.g_optimizer.apply_gradients(\n",
        "                zip(gen_gradient, self.generator.trainable_variables)\n",
        "            )\n",
        "\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
      ],
      "metadata": {
        "id": "TB9rBLN4SnEj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAEJUKYKCIfY"
      },
      "source": [
        "## Data  \n",
        "Load the data and create a Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "dataset_name = \"oxford_flowers102\"\n",
        "dataset_repetitions = 5\n",
        "num_epochs = 1  # train for at least 50 epochs for good results\n",
        "image_size = 64\n",
        "# KID = Kernel Inception Distance, see related section\n",
        "kid_image_size = 75\n",
        "kid_diffusion_steps = 5\n",
        "plot_diffusion_steps = 20\n",
        "\n",
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "embedding_dims = 32\n",
        "embedding_max_frequency = 1000.0\n",
        "widths = [32, 64, 96, 128]\n",
        "block_depth = 2\n",
        "\n",
        "# optimization\n",
        "batch_size = 20\n",
        "ema = 0.999\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "9nCWd7sA7jha"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(data):\n",
        "    # center crop image\n",
        "    height = tf.shape(data[\"image\"])[0]\n",
        "    width = tf.shape(data[\"image\"])[1]\n",
        "    crop_size = tf.minimum(height, width)\n",
        "    image = tf.image.crop_to_bounding_box(\n",
        "        data[\"image\"],\n",
        "        (height - crop_size) // 2,\n",
        "        (width - crop_size) // 2,\n",
        "        crop_size,\n",
        "        crop_size,\n",
        "    )\n",
        "\n",
        "    # resize and clip\n",
        "    # for image downsampling it is important to turn on antialiasing\n",
        "    image = tf.image.resize(image, size=[image_size, image_size], antialias=True)\n",
        "    return tf.clip_by_value(image / 255.0, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def prepare_dataset(split):\n",
        "    # the validation dataset is shuffled as well, because data order matters\n",
        "    # for the KID estimation\n",
        "    return (\n",
        "        tfds.load(dataset_name, split=split, shuffle_files=True)\n",
        "        .map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .cache()\n",
        "        .repeat(dataset_repetitions)\n",
        "        .shuffle(10 * batch_size)\n",
        "        .batch(batch_size, drop_remainder=True)\n",
        "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "\n",
        "# load dataset\n",
        "train_dataset = prepare_dataset(\"train[:80%]+validation[:80%]+test[:80%]\")\n",
        "val_dataset = prepare_dataset(\"train[80%:]+validation[80%:]+test[80%:]\")"
      ],
      "metadata": {
        "id": "LophAyvf7ejp"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ_Litz-B33A"
      },
      "source": [
        "slice_size = (64, 64, 3)\n",
        "batch_size = 20\n",
        "noise_shape = (64, 64)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3qDsUf2B5Ec"
      },
      "source": [
        "# Horizontal data is 64x128\n",
        "# We made the latent space size relative to the output size, such that no resize\n",
        "# are necessary, only upsamples\n",
        "\n",
        "dataloader = train_dataset"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFT65Mp9CcMz"
      },
      "source": [
        "## Generator and Discriminator Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_depth = 2\n",
        "large_model = False\n",
        "if large_model:\n",
        "    widths = [64, 128, 256, 512]\n",
        "    attentions = [False, False, True, True]\n",
        "else:\n",
        "    widths = [64, 96, 128, 256]\n",
        "    attentions = [False, False, False, False]\n",
        "\n",
        "patch_size = 1\n",
        "g_model = get_network(image_size, block_depth, widths, attentions, patch_size,)\n",
        "g_model.build([None, *noise_shape, 1])\n",
        "generator_optimizer = keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5, beta_2=0.99)\n",
        "g_model.summary()"
      ],
      "metadata": {
        "id": "MBisKcK81yyi",
        "outputId": "506d25a8-ff9c-402d-8d07-0915681b623f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"residual_unet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, None, None,   256         ['input_5[0][0]']                \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_56 (GroupN  (None, None, None,   128        ['conv2d_76[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_56 (TFOpLambda)     (None, None, None,   0           ['group_normalization_56[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, None, None,   36928       ['tf.nn.silu_56[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_57 (GroupN  (None, None, None,   128        ['conv2d_77[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_57 (TFOpLambda)     (None, None, None,   0           ['group_normalization_57[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, None, None,   36928       ['tf.nn.silu_57[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, None, None,   0           ['conv2d_76[0][0]',              \n",
            "                                64)                               'conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " group_normalization_58 (GroupN  (None, None, None,   128        ['add_28[0][0]']                 \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_58 (TFOpLambda)     (None, None, None,   0           ['group_normalization_58[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, None, None,   36928       ['tf.nn.silu_58[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_59 (GroupN  (None, None, None,   128        ['conv2d_79[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_59 (TFOpLambda)     (None, None, None,   0           ['group_normalization_59[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, None, None,   36928       ['tf.nn.silu_59[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, None, None,   0           ['add_28[0][0]',                 \n",
            "                                64)                               'conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, None, None,   0          ['add_29[0][0]']                 \n",
            " oling2D)                       64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_60 (GroupN  (None, None, None,   128        ['average_pooling2d_6[0][0]']    \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_60 (TFOpLambda)     (None, None, None,   0           ['group_normalization_60[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, None, None,   55392       ['tf.nn.silu_60[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_61 (GroupN  (None, None, None,   192        ['conv2d_82[0][0]']              \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_61 (TFOpLambda)     (None, None, None,   0           ['group_normalization_61[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, None, None,   6240        ['average_pooling2d_6[0][0]']    \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, None, None,   83040       ['tf.nn.silu_61[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, None, None,   0           ['conv2d_81[0][0]',              \n",
            "                                96)                               'conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " group_normalization_62 (GroupN  (None, None, None,   192        ['add_30[0][0]']                 \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_62 (TFOpLambda)     (None, None, None,   0           ['group_normalization_62[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, None, None,   83040       ['tf.nn.silu_62[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_63 (GroupN  (None, None, None,   192        ['conv2d_84[0][0]']              \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_63 (TFOpLambda)     (None, None, None,   0           ['group_normalization_63[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, None, None,   83040       ['tf.nn.silu_63[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, None, None,   0           ['add_30[0][0]',                 \n",
            "                                96)                               'conv2d_85[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, None, None,   0          ['add_31[0][0]']                 \n",
            " oling2D)                       96)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_64 (GroupN  (None, None, None,   192        ['average_pooling2d_7[0][0]']    \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_64 (TFOpLambda)     (None, None, None,   0           ['group_normalization_64[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, None, None,   110720      ['tf.nn.silu_64[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_65 (GroupN  (None, None, None,   256        ['conv2d_87[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_65 (TFOpLambda)     (None, None, None,   0           ['group_normalization_65[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, None, None,   12416       ['average_pooling2d_7[0][0]']    \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, None, None,   147584      ['tf.nn.silu_65[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, None, None,   0           ['conv2d_86[0][0]',              \n",
            "                                128)                              'conv2d_88[0][0]']              \n",
            "                                                                                                  \n",
            " group_normalization_66 (GroupN  (None, None, None,   256        ['add_32[0][0]']                 \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_66 (TFOpLambda)     (None, None, None,   0           ['group_normalization_66[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, None, None,   147584      ['tf.nn.silu_66[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_67 (GroupN  (None, None, None,   256        ['conv2d_89[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_67 (TFOpLambda)     (None, None, None,   0           ['group_normalization_67[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, None, None,   147584      ['tf.nn.silu_67[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, None, None,   0           ['add_32[0][0]',                 \n",
            "                                128)                              'conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, None, None,   0          ['add_33[0][0]']                 \n",
            " oling2D)                       128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_68 (GroupN  (None, None, None,   256        ['average_pooling2d_8[0][0]']    \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_68 (TFOpLambda)     (None, None, None,   0           ['group_normalization_68[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, None, None,   295168      ['tf.nn.silu_68[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_69 (GroupN  (None, None, None,   512        ['conv2d_92[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_69 (TFOpLambda)     (None, None, None,   0           ['group_normalization_69[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, None, None,   33024       ['average_pooling2d_8[0][0]']    \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, None, None,   590080      ['tf.nn.silu_69[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_34 (Add)                   (None, None, None,   0           ['conv2d_91[0][0]',              \n",
            "                                256)                              'conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " group_normalization_70 (GroupN  (None, None, None,   512        ['add_34[0][0]']                 \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_70 (TFOpLambda)     (None, None, None,   0           ['group_normalization_70[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, None, None,   590080      ['tf.nn.silu_70[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_71 (GroupN  (None, None, None,   512        ['conv2d_94[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_71 (TFOpLambda)     (None, None, None,   0           ['group_normalization_71[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, None, None,   590080      ['tf.nn.silu_71[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_35 (Add)                   (None, None, None,   0           ['add_34[0][0]',                 \n",
            "                                256)                              'conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, None, None,   0          ['add_35[0][0]']                 \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, None, None,   0           ['up_sampling2d_6[0][0]',        \n",
            "                                384)                              'add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_72 (GroupN  (None, None, None,   768        ['concatenate_12[0][0]']         \n",
            " ormalization)                  384)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_72 (TFOpLambda)     (None, None, None,   0           ['group_normalization_72[0][0]'] \n",
            "                                384)                                                              \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, None, None,   442496      ['tf.nn.silu_72[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_73 (GroupN  (None, None, None,   256        ['conv2d_97[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_73 (TFOpLambda)     (None, None, None,   0           ['group_normalization_73[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, None, None,   49280       ['concatenate_12[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, None, None,   147584      ['tf.nn.silu_73[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, None, None,   0           ['conv2d_96[0][0]',              \n",
            "                                128)                              'conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, None, None,   0           ['add_36[0][0]',                 \n",
            "                                256)                              'add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_74 (GroupN  (None, None, None,   512        ['concatenate_13[0][0]']         \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_74 (TFOpLambda)     (None, None, None,   0           ['group_normalization_74[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, None, None,   295040      ['tf.nn.silu_74[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_75 (GroupN  (None, None, None,   256        ['conv2d_100[0][0]']             \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_75 (TFOpLambda)     (None, None, None,   0           ['group_normalization_75[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, None, None,   32896       ['concatenate_13[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_75[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_37 (Add)                   (None, None, None,   0           ['conv2d_99[0][0]',              \n",
            "                                128)                              'conv2d_101[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, None, None,   0          ['add_37[0][0]']                 \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, None, None,   0           ['up_sampling2d_7[0][0]',        \n",
            "                                224)                              'add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_76 (GroupN  (None, None, None,   448        ['concatenate_14[0][0]']         \n",
            " ormalization)                  224)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_76 (TFOpLambda)     (None, None, None,   0           ['group_normalization_76[0][0]'] \n",
            "                                224)                                                              \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, None, None,   193632      ['tf.nn.silu_76[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_77 (GroupN  (None, None, None,   192        ['conv2d_103[0][0]']             \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_77 (TFOpLambda)     (None, None, None,   0           ['group_normalization_77[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, None, None,   21600       ['concatenate_14[0][0]']         \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, None, None,   83040       ['tf.nn.silu_77[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " add_38 (Add)                   (None, None, None,   0           ['conv2d_102[0][0]',             \n",
            "                                96)                               'conv2d_104[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, None, None,   0           ['add_38[0][0]',                 \n",
            "                                192)                              'add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_78 (GroupN  (None, None, None,   384        ['concatenate_15[0][0]']         \n",
            " ormalization)                  192)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_78 (TFOpLambda)     (None, None, None,   0           ['group_normalization_78[0][0]'] \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, None, None,   165984      ['tf.nn.silu_78[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_79 (GroupN  (None, None, None,   192        ['conv2d_106[0][0]']             \n",
            " ormalization)                  96)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_79 (TFOpLambda)     (None, None, None,   0           ['group_normalization_79[0][0]'] \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, None, None,   18528       ['concatenate_15[0][0]']         \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, None, None,   83040       ['tf.nn.silu_79[0][0]']          \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " add_39 (Add)                   (None, None, None,   0           ['conv2d_105[0][0]',             \n",
            "                                96)                               'conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, None, None,   0          ['add_39[0][0]']                 \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, None, None,   0           ['up_sampling2d_8[0][0]',        \n",
            "                                160)                              'add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_80 (GroupN  (None, None, None,   320        ['concatenate_16[0][0]']         \n",
            " ormalization)                  160)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_80 (TFOpLambda)     (None, None, None,   0           ['group_normalization_80[0][0]'] \n",
            "                                160)                                                              \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, None, None,   92224       ['tf.nn.silu_80[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_81 (GroupN  (None, None, None,   128        ['conv2d_109[0][0]']             \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_81 (TFOpLambda)     (None, None, None,   0           ['group_normalization_81[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, None, None,   10304       ['concatenate_16[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_81[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_40 (Add)                   (None, None, None,   0           ['conv2d_108[0][0]',             \n",
            "                                64)                               'conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, None, None,   0           ['add_40[0][0]',                 \n",
            "                                128)                              'add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " group_normalization_82 (GroupN  (None, None, None,   256        ['concatenate_17[0][0]']         \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_82 (TFOpLambda)     (None, None, None,   0           ['group_normalization_82[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, None, None,   73792       ['tf.nn.silu_82[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_83 (GroupN  (None, None, None,   128        ['conv2d_112[0][0]']             \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_83 (TFOpLambda)     (None, None, None,   0           ['group_normalization_83[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, None, None,   8256        ['concatenate_17[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_83[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_41 (Add)                   (None, None, None,   0           ['conv2d_111[0][0]',             \n",
            "                                64)                               'conv2d_113[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, None, None,   16640      ['add_41[0][0]']                 \n",
            " spose)                         256)                                                              \n",
            "                                                                                                  \n",
            " last_generator_block (LastGene  (None, None, None,   7011       ['conv2d_transpose_2[0][0]']     \n",
            " ratorBlock)                    3)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,093,635\n",
            "Trainable params: 5,093,629\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB2EJ0A5ne4X"
      },
      "source": [
        "#g_model = WassersteinGSGenerator(output_dims=slice_size)\n",
        "#g_model.build([None, *noise_shape, 1])\n",
        "#generator_optimizer = keras.optimizers.Adam(learning_rate=5e-4, beta_1=0.5, beta_2=0.99)\n",
        "#g_model.summary()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDTi_Qklngmn",
        "outputId": "b8368cdc-cdb4-4a93-f26c-72fe45c01d10"
      },
      "source": [
        "d_model = get_wgs_discriminator_model(slice_size)\n",
        "discriminator_optimizer = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.99)\n",
        "d_model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " initial_discriminator_block  (None, 32, 32, 64)       2800      \n",
            " _2 (InitialDiscriminatorBlo                                     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " discriminator_block_6 (Disc  (None, 16, 16, 128)      27776     \n",
            " riminatorBlock)                                                 \n",
            "                                                                 \n",
            " discriminator_block_7 (Disc  (None, 8, 8, 256)        110848    \n",
            " riminatorBlock)                                                 \n",
            "                                                                 \n",
            " discriminator_block_8 (Disc  (None, 8, 8, 128)        442880    \n",
            " riminatorBlock)                                                 \n",
            "                                                                 \n",
            " final_discriminator_block_2  (None, 8, 8, 1)          886017    \n",
            "  (FinalDiscriminatorBlock)                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,470,321\n",
            "Trainable params: 1,469,329\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK3ocyykCglU"
      },
      "source": [
        "## WGAN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh_9yZn8nia4"
      },
      "source": [
        "# Instantiate the WGAN model.\n",
        "wgan2d = WassersteinGANGS(\n",
        "    discriminator=d_model,\n",
        "    generator=g_model,\n",
        "    latent_shape=(64, 64, 3),\n",
        "    discriminator_extra_steps=3, # More tests could be done on the right amount of extra steps\n",
        ")\n",
        "\n",
        "wgan2d.compile(d_optimizer=discriminator_optimizer, g_optimizer=generator_optimizer)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzOmc1RvCoRW"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k08tvWU_nnuT"
      },
      "source": [
        "epochs = 150\n",
        "#checkpoint = CheckpointSaving()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = wgan2d.fit(dataloader, batch_size=batch_size, epochs=150, callbacks=[])"
      ],
      "metadata": {
        "id": "p0vY26_SE8HS",
        "outputId": "e41eb17c-fc9a-44b6-94c2-d9b86edb497b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1637/1637 [==============================] - 908s 493ms/step - d_loss: -946.3587 - g_loss: 707.6808\n",
            "Epoch 2/150\n",
            "1637/1637 [==============================] - 807s 493ms/step - d_loss: -901.1509 - g_loss: 227.1460\n",
            "Epoch 3/150\n",
            "1637/1637 [==============================] - 806s 493ms/step - d_loss: -571.0991 - g_loss: 257.8554\n",
            "Epoch 4/150\n",
            "1164/1637 [====================>.........] - ETA: 3:52 - d_loss: -840.4502 - g_loss: 513.8428"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-6bb7f8634785>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgan2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZVGbxa3EfGO",
        "outputId": "b8a8c55b-e255-40ac-a83e-57d1827c1cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "g_loss_history = history.history['g_loss']\n",
        "d_loss_history = history.history['d_loss']\n",
        "epochs = range(len(d_loss_history))\n",
        "\n",
        "plt.plot(epochs, g_loss_history)\n",
        "plt.plot(epochs, d_loss_history)\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-058842a13747>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhAhlwQPntIK"
      },
      "source": [
        "## Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvhG71A4nstE"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def show_images(array_img, cmap, norm):\n",
        "    # IMAGES\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "    slice_h = array_img.numpy().shape[1]\n",
        "    slice_w = array_img.numpy().shape[2]\n",
        "\n",
        "\n",
        "    size_high_res = (slice_h, slice_w)\n",
        "\n",
        "    plt.imshow(np.argmax(array_img.numpy(), axis=-1).reshape(size_high_res),\n",
        "               interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  random_latent_vectors = tf.random.normal(shape=(1, *noise_shape, 3))\n",
        "  generated_images = np.squeeze(g_model(random_latent_vectors, training=False))\n",
        "\n",
        "  plt.imshow(generated_images)"
      ],
      "metadata": {
        "id": "f9InIrWIUvZd",
        "outputId": "16e04f8f-31fd-4f8d-84ca-2db772b6b608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}