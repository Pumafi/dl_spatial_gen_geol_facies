{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/fast_stationary_ddim_tests_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "TA0koXfT2e7k",
        "outputId": "128e7dd8-63f6-4236-f3d3-6a39d7b5edaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 23 13:46:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IDEAS\n",
        "1.   Normalization in embedding ?\n",
        "2.   Formula when I replace beta by t\n",
        "3.   Use keras inference for potential changes\n",
        "\n",
        "## What to try next?\n",
        "\n",
        "If you would like to dive in deeper to the topic, a recommend checking out\n",
        "[this repository](https://github.com/beresandras/clear-diffusion-keras) that I created in\n",
        "preparation for this code example, which implements a wider range of features in a\n",
        "similar style, such as:\n",
        "\n",
        "* stochastic sampling\n",
        "* second-order sampling based on the\n",
        "[differential equation view of DDIMs (Equation 13)](https://arxiv.org/abs/2010.02502)\n",
        "* more diffusion schedules\n",
        "* more network output types: predicting image or\n",
        "[velocity (Appendix D)](https://arxiv.org/abs/2202.00512) instead of noise\n",
        "* more datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rge41L-HIY-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkfNOJcD0Ym"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install deel.lip\n",
        "!python -m pip install -i https://test.pypi.org/simple/ gstlearn"
      ],
      "metadata": {
        "id": "u03Nq4eK2ems",
        "outputId": "a5a256b9-b415-4807-c925-0b4044f7213e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deel.lip\n",
            "  Downloading deel_lip-1.4.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deel.lip) (1.22.4)\n",
            "Requirement already satisfied: tensorflow~=2.2 in /usr/local/lib/python3.10/dist-packages (from deel.lip) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.2->deel.lip) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.2.2)\n",
            "Installing collected packages: deel.lip\n",
            "Successfully installed deel.lip-1.4.0\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gstlearn\n",
            "  Downloading https://test-files.pythonhosted.org/packages/4b/33/9b8e2546cfe286525409a1d17279b325a7a1d2968eba07357a0e30976d29/gstlearn-0.2.1-cp310-cp310-manylinux1_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gstlearn) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from gstlearn) (5.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.5.3)\n",
            "INFO: pip is looking at multiple versions of gstlearn to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://test-files.pythonhosted.org/packages/ea/39/5475c8fac8f0b9897ef6be34b92d40dae6d209dbfe2a7db0fb7a9386fadc/gstlearn-0.1.38-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/6.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
            "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
            "    data = self.__fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
            "    s = self.fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "TimeoutError: The read operation timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 237, in _attempt_to_pin_criterion\n",
            "    for candidate in criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
            "    file = get_http_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
            "    for chunk in iterable:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
            "    for chunk in response.raw.stream(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
            "    with self._error_catcher():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
            "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
            "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='test-files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "\n",
        "    %cd {REPO_DIR}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPH8VxsGGrb",
        "outputId": "859bf397-28f8-459c-e054-5519e6361ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'flumy-wgan-mines'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "R3E8qnnCGH5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VQcRg8KD0Yn"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from data.load_data import load_data\n",
        "from utils.visualisation import get_color_map\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "1eF1rmySGCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful constants\n",
        "image_size = (64, 128)\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "facies_names = np.array([\"Sand, Channel lag\", \"Sand, Point bar\", \"Silts, Levee\", \"Shale, Overbank\"])\n",
        "x = load_data(image_size[0], image_size[1], \"./data/horizontal/dataFlumyHoriz.csv\")\n",
        "x_train = x[:2760]\n",
        "x_test = x[2760:]"
      ],
      "metadata": {
        "id": "4yPyDmhUGCTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-ElzPrD0Yq"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBoSc7iCD0Ys"
      },
      "outputs": [],
      "source": [
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "widths = [32, 64, 128, 256]\n",
        "block_depth = 2\n",
        "\n",
        "# Data values embedding\n",
        "img_embed_size = 64\n",
        "categories_nb = 4\n",
        "\n",
        "# optimization\n",
        "batch_size = 30\n",
        "ema = 0.999\n",
        "learning_rate = 1e-4\n",
        "embeding_net_lr = 1e-3\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diffusion Schedules"
      ],
      "metadata": {
        "id": "acL9rhHAdCCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DiffusionSchedule(ABC):\n",
        "    def __init__(self, start_log_snr, end_log_snr):\n",
        "        assert (\n",
        "            start_log_snr > end_log_snr\n",
        "        ), \"The starting SNR has to be higher than the final SNR.\"\n",
        "\n",
        "        self.end_beta = 20\n",
        "        self.start_beta = 0.1\n",
        "\n",
        "        self.start_snr = tf.exp(start_log_snr)\n",
        "        self.end_snr = tf.exp(end_log_snr)\n",
        "\n",
        "        #self.start_noise_power = 1.0 / (1.0 + self.start_snr)\n",
        "        #self.end_noise_power = 1.0 / (1.0 + self.end_snr)\n",
        "\n",
        "    def __call__(self, diffusion_times):\n",
        "        signal_powers = self.get_noise_powers(diffusion_times)\n",
        "        signal_rates = tf.math.exp(signal_powers)\n",
        "\n",
        "        noise_rates = (1 - signal_rates**2)**0.5\n",
        "\n",
        "\n",
        "        # the signal and noise power will always sum to one\n",
        "        #signal_powers = 1.0 - noise_powers\n",
        "\n",
        "        # the rates are the square roots of the powers\n",
        "        # variance**0.5 -> standard deviation\n",
        "        #signal_rates = signal_powers**0.5\n",
        "        #noise_rates = noise_powers**0.5\n",
        "\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SignalStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current signal powers decreases approximately linearly to 1\n",
        "    # similar to the \"linear schedule\" of DDPM https://arxiv.org/abs/2006.11239\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "\n",
        "        return -(self.end_beta - self.start_beta) / 4 * diffusion_times**2 - self.start_beta / 2 * diffusion_times\n",
        "\n",
        "        #return 1.0 - (1.0 - self.start_noise_power) * (\n",
        "        #    (1.0 - self.end_noise_power) / (1.0 - self.start_noise_power)\n",
        "        #) ** (diffusion_times**2)"
      ],
      "metadata": {
        "id": "Z5U9ClBmdDxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_snr(signal_rate, noise_rate):\n",
        "    return tf.math.log(signal_rate / noise_rate)\n",
        "\n",
        "def get_t_from_snr(snr):\n",
        "    max_beta = 20.\n",
        "    min_beta = 0.1\n",
        "    return 2 * tf.math.log(tf.math.exp(-2*snr)+1) / (tf.math.sqrt(min_beta**2 + 2\n",
        "                                                                 * (max_beta - min_beta)\n",
        "                                                                 * tf.math.log(tf.math.exp(-2*snr)+1)) + min_beta)"
      ],
      "metadata": {
        "id": "WKvodkeuyJFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "t = np.array([0.486,])\n",
        "noise_rates, signal_rates = diff_schedule(t)\n",
        "snr = compute_snr(signal_rates, noise_rates)\n",
        "t_prime = get_t_from_snr(snr)\n",
        "print(t_prime)"
      ],
      "metadata": {
        "id": "qItvy_HRVox_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "QxyZaS_UJ_YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(tf.keras.layers.Layer):\n",
        "    \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights during initialization. These weights are fixed\n",
        "        # during optimization and are not trainable.\n",
        "        self.W = self.add_weight(shape=(embed_dim // 2,),\n",
        "                                 trainable=False,\n",
        "                                 initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.), name=\"GFP\") * tf.constant(scale, dtype=tf.float32)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        x_proj = x * self.W * tf.constant(2., dtype=tf.float32) * tf.constant(np.pi, dtype=tf.float32)\n",
        "        y = tf.concat([tf.math.sin(x_proj), tf.cos(x_proj)], axis=-1)\n",
        "        return y # Probleme vient pas de là :()\n",
        "\n",
        "class CustomLinear(tf.keras.layers.Layer):\n",
        "    \"\"\"Rhaaah.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.W = tf.random.uniform((input_dim, output_dim), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "        self.b = tf.random.uniform((1, output_dim, ), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = tf.tensordot(x, self.W, 1) + self.b\n",
        "        y = tf.keras.activations.gelu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "class EmbedLayerNormalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.beta = self.add_weight(shape=(1, 1, 1, 1),\n",
        "                                    initializer=tf.keras.initializers.Zeros(),\n",
        "                                    dtype=tf.float32,\n",
        "                                    name=\"beta_embed_layer\",\n",
        "                                    trainable=True)\n",
        "        self.gamma = self.add_weight(shape=(1, 1, 1, 1),\n",
        "                                     initializer=tf.keras.initializers.Ones(),\n",
        "                                     dtype=tf.float32,\n",
        "                                     name=\"gamma_embed_layer\",\n",
        "                                     trainable=True)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "\n",
        "        mean, variance = tf.nn.moments(inputs, -1, keepdims=True)\n",
        "        outputs = tf.nn.batch_normalization(\n",
        "            inputs,\n",
        "            mean,\n",
        "            variance,\n",
        "            offset=self.beta,\n",
        "            scale=self.gamma,\n",
        "            variance_epsilon=1e-8,\n",
        "        )\n",
        "\n",
        "        return outputs #* self.gamma + self.beta\n",
        "\n",
        "@tf.function\n",
        "def embedding_normalization(logits):\n",
        "    # normalement vont avoir taille (batch_size, 64, 128, embedding_size)\n",
        "    # axis=-1 is embedding normalement\n",
        "    return (logits / tf.norm(logits, axis=-1, keepdims=True)) * tf.constant(np.sqrt(logits.shape[-1]), dtype=tf.float32)\n",
        "\n",
        "class NormalizedEmbedding(tf.keras.Model):\n",
        "    \"\"\"\"\"\"\n",
        "    def __init__(self, categories_nb, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.embed_layer = tf.keras.layers.Embedding(categories_nb, img_embed_size)\n",
        "        self.embed_layer2 = layers.Conv2D(img_embed_size, kernel_size=1, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer3 = layers.Conv2D(img_embed_size, kernel_size=1, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer4 = layers.Conv2D(img_embed_size, kernel_size=1, activation=None)\n",
        "        self.layer_norm = EmbedLayerNormalization(img_embed_size=16)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        # I tested the embedding it's perfectly pixel by pixel\n",
        "        y = self.embed_layer(x)\n",
        "        y = self.embed_layer2(y)\n",
        "        y = self.embed_layer3(y)\n",
        "        y = self.embed_layer4(y)\n",
        "        #y = embedding_normalization(y)\n",
        "        y = self.layer_norm(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "Ej4nARwoGmme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network(\n",
        "    image_size,\n",
        "    noise_embedding_max_frequency,\n",
        "    noise_embedding_dims,\n",
        "    image_embedding_dims,\n",
        "    block_depth,\n",
        "    widths,\n",
        "    attentions,\n",
        "    patch_size,\n",
        "    embed_size\n",
        "):\n",
        "    def EmbeddingLayer(embedding_max_frequency, embedding_dims):\n",
        "        def sinusoidal_embedding(x):\n",
        "            embedding_min_frequency = 1.0\n",
        "            frequencies = tf.exp(\n",
        "                tf.linspace(\n",
        "                    tf.math.log(embedding_min_frequency),\n",
        "                    tf.math.log(embedding_max_frequency),\n",
        "                    embedding_dims // 2,\n",
        "                )\n",
        "            )\n",
        "            angular_speeds = 2.0 * math.pi * frequencies\n",
        "            embeddings = tf.concat(\n",
        "                [\n",
        "                    tf.sin(angular_speeds * x),\n",
        "                    tf.cos(angular_speeds * x),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "            return embeddings\n",
        "\n",
        "        def forward(x):\n",
        "            x = layers.Lambda(sinusoidal_embedding)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def ResidualBlock(width, attention):\n",
        "        def forward(x):\n",
        "            x, n = x\n",
        "            input_width = x.shape[3]\n",
        "            if input_width == width:\n",
        "                residual = x\n",
        "            else:\n",
        "                residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "\n",
        "            n = layers.Dense(width)(n)\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([x, n])\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([residual, x])\n",
        "\n",
        "            if attention:\n",
        "                residual = x\n",
        "                x = tfa.layers.GroupNormalization(groups=8, center=False, scale=False)(\n",
        "                    x\n",
        "                )\n",
        "                x = layers.MultiHeadAttention(\n",
        "                    num_heads=4, key_dim=width, attention_axes=(1, 2)\n",
        "                )(x, x)\n",
        "\n",
        "                x = layers.Add()([residual, x])\n",
        "\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def DownBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            for _ in range(block_depth):\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "                skips.append(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def UpBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "            for _ in range(block_depth):\n",
        "                x = layers.Concatenate()([x, skips.pop()])\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    images = keras.Input(shape=(None, None, embed_size))\n",
        "    noise_powers = keras.Input(shape=(1, 1, 1))\n",
        "    mask = keras.Input(shape=(None, None, 1))\n",
        "    conditioning_pixels = keras.Input(shape=(None, None, embed_size))\n",
        "\n",
        "    x = tf.keras.layers.Concatenate(axis=-1)([images, mask, conditioning_pixels])\n",
        "\n",
        "    x = layers.Conv2D(image_embedding_dims, kernel_size=patch_size, strides=patch_size)(\n",
        "        x\n",
        "    )\n",
        "\n",
        "    # NOISE EMBEDDING\n",
        "    #print(noise_powers)\n",
        "    n = EmbeddingLayer(noise_embedding_max_frequency, noise_embedding_dims)(\n",
        "        noise_powers\n",
        "    )\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "\n",
        "    skips = []\n",
        "    for width, attention in zip(widths[:-1], attentions[:-1]):\n",
        "        x = DownBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1], attentions[-1])([x, n])\n",
        "\n",
        "    for width, attention in zip(widths[-2::-1], attentions[-2::-1]):\n",
        "        x = UpBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    x = layers.Conv2DTranspose(\n",
        "        4, kernel_size=patch_size, strides=patch_size, kernel_initializer=\"zeros\", activation=\"softmax\"\n",
        "    )(x)\n",
        "\n",
        "    return keras.Model([images, noise_powers, mask, conditioning_pixels], x, name=\"residual_unet\")"
      ],
      "metadata": {
        "id": "IgeH9voVvsN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling\n",
        "def make_mask(image_to_condition):\n",
        "    nb_conditioning_points = np.random.randint(low=1.0, high=image_to_condition.shape[0] * image_to_condition.shape[1])\n",
        "    random_x_coordinates = np.random.choice(image_to_condition.shape[0], nb_conditioning_points)\n",
        "    random_y_coordinates = np.random.choice(image_to_condition.shape[1], nb_conditioning_points)\n",
        "    mask = np.zeros((image_to_condition.shape[0], image_to_condition.shape[1], 1))\n",
        "    mask[random_x_coordinates, random_y_coordinates, :] = 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "XEMZlA-xdLcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ37576YD0Y5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth, img_embed_size,\n",
        "                 categories_nb, embedding_lr=1e-3, batch_size=30,\n",
        "                 large_model=False):\n",
        "        super().__init__()\n",
        "\n",
        "        noise_embedding_max_frequency = 1000.0\n",
        "        noise_embedding_dims = 64\n",
        "        image_embedding_dims = 64\n",
        "        block_depth = 2\n",
        "\n",
        "        if large_model:\n",
        "            widths = [64, 128, 256, 512]\n",
        "            attentions = [False, False, True, True]\n",
        "        else:\n",
        "            widths = [64, 96, 128, 256]\n",
        "            attentions = [False, False, False, False]\n",
        "\n",
        "        patch_size = 1\n",
        "\n",
        "        self.diffusion_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        #self.diffusion_schedule = CosineSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        self.network = get_network(image_size, noise_embedding_max_frequency,\n",
        "                                   noise_embedding_dims, image_embedding_dims,\n",
        "                                   block_depth, widths, attentions, patch_size,\n",
        "                                   img_embed_size)\n",
        "\n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Embedding\n",
        "        self.img_embed_size = img_embed_size\n",
        "        self.embedding_layer = NormalizedEmbedding(categories_nb, img_embed_size)\n",
        "        self.emb_optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=embedding_lr)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "        self.noise_loss_tracker = keras.metrics.Mean(name=\"n_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.image_loss_tracker, self.noise_loss_tracker]\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training, mask=None, pixels=None):\n",
        "        # the exponential moving average weights are used at evaluation\n",
        "\n",
        "        if mask is None or pixels is None:\n",
        "            mask = tf.zeros(noisy_images.shape)\n",
        "            pixels = tf.zeros(noisy_images.shape)\n",
        "\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        # predict noise component and calculate the image component using it\n",
        "        pred_images = network([noisy_images, noise_rates**2, mask, pixels], training=training)\n",
        "\n",
        "\n",
        "        int_encoded_img = tf.argmax(pred_images, axis=-1)\n",
        "        embed_pred_images = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        pred_noises = (noisy_images - signal_rates * embed_pred_images) / noise_rates\n",
        "\n",
        "        return pred_images, pred_noises\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(self.batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        mask_uncondi = tf.zeros((self.batch_size // 2, images.shape[1], images.shape[2], 1))\n",
        "        mask_condi = tf.map_fn(make_mask, images[self.batch_size // 2:])\n",
        "        mask = tf.concat([mask_uncondi, mask_condi], axis=0)\n",
        "\n",
        "\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            embed_images = self.embedding_layer(int_encoded_img)\n",
        "            pixels = tf.math.multiply(embed_images, mask)\n",
        "\n",
        "            noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "            noisy_images = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_images, pred_noise = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True, mask=mask, pixels=pixels\n",
        "            )\n",
        "\n",
        "            image_loss = self.loss(images, pred_images)  # training loss\n",
        "\n",
        "            n_loss = keras.losses.mean_absolute_error(noises, pred_noise)\n",
        "\n",
        "        gradients_model = tape1.gradient(n_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.network.trainable_weights))\n",
        "\n",
        "        gradients_embeddings = tape2.gradient(n_loss, self.embedding_layer.trainable_weights)\n",
        "        self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        #gradients_embeddings = tape3.gradient(image_loss, self.embedding_layer.trainable_weights)\n",
        "        #self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "        self.noise_loss_tracker.update_state(n_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        # KID is not measured during the training phase for computational efficiency\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "\n",
        "        mask_uncondi = tf.zeros((self.batch_size // 2, images.shape[1], images.shape[2], 1))\n",
        "        mask_condi = tf.map_fn(make_mask, images[self.batch_size // 2:])\n",
        "        mask = tf.concat([mask_uncondi, mask_condi], axis=0)\n",
        "\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        embed_images = self.embedding_layer(int_encoded_img)\n",
        "\n",
        "        #std = marginal_prob_std(diffusion_times, sigma=sigma)\n",
        "        pixels = tf.math.multiply(embed_images, mask)\n",
        "\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "        noisy_images = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "        #noisy_images = embed_images + noises * tf.reshape(std, (-1, 1, 1, 1))\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_images, pred_noise = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels\n",
        "        )\n",
        "        n_loss = keras.losses.mean_absolute_error(noises, pred_noise)\n",
        "\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "        self.noise_loss_tracker.update_state(n_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYrG2VPD0Y7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHcHZit9D0Y8"
      },
      "outputs": [],
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth, img_embed_size=img_embed_size, categories_nb=categories_nb, large_model=True)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "t_epochs_nb=100\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, batch_size=batch_size, epochs=t_epochs_nb, validation_data=(x_test,))"
      ],
      "metadata": {
        "id": "RDSktS3wIy4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.network.summary()"
      ],
      "metadata": {
        "id": "Jcm7Vh6v9R0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = np.arange(t_epochs_nb)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_axis, history.history[\"i_loss\"], label=\"Training image CE loss\")\n",
        "plt.plot(x_axis, history.history[\"val_i_loss\"], label=\"Testing image CE loss\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efA4YUlX723d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6ewS3D0Y-"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm"
      ],
      "metadata": {
        "id": "PoJyZzMZqAIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def second_order_correction(\n",
        "    model,\n",
        "    diffusion_times,\n",
        "    step_size,\n",
        "    noisy_images,\n",
        "    signal_rates,\n",
        "    noise_rates,\n",
        "    pred_images,\n",
        "    pred_noises,\n",
        "    second_order_alpha,\n",
        "    mask,\n",
        "    pixels,\n",
        "):\n",
        "    # generic second-order Runge-Kutta method\n",
        "    # https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods#Generic_second-order_method\n",
        "    # based on https://arxiv.org/abs/2206.00364\n",
        "    #batch_size=noisy_images.shape[0]\n",
        "    #mask = tf.zeros((batch_size, image_size[0], image_size[1], 1))\n",
        "    #pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "\n",
        "    # use first estimate to sample alpha steps away\n",
        "    alpha_signal_rates, alpha_noise_rates = model.diffusion_schedule(\n",
        "        diffusion_times - second_order_alpha * step_size\n",
        "    )\n",
        "    alpha_noisy_images = (\n",
        "        alpha_signal_rates * pred_images + alpha_noise_rates * pred_noises\n",
        "    )\n",
        "    x_input = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "    pred_x0, alpha_pred_noises = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "    int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "    embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "    # linearly combine the two noise estimates\n",
        "    pred_noises = (1.0 - 1.0 / (2.0 * second_order_alpha)) * pred_noises + 1.0 / (\n",
        "        2.0 * second_order_alpha\n",
        "        ) * alpha_pred_noises\n",
        "\n",
        "    pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "    return pred_images, pred_noises"
      ],
      "metadata": {
        "id": "SEJciKNQzCGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_beta(curr_alphas, prev_alphas):\n",
        "\n",
        "    betas = 1 - (prev_alphas / curr_alphas)\n",
        "    return betas"
      ],
      "metadata": {
        "id": "wVWp820FKVRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_sampler(model, img_embed_size, image_size, batch_size=10, num_steps=10, eps=1e-3, mask=None, pixels=None):\n",
        "    second_order_alpha = 1.1\n",
        "    # T and schedule\n",
        "    t_max = 1.0\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    if mask is None:\n",
        "        mask = tf.zeros((batch_size, image_size[0], image_size[1], 1), dtype=tf.float32)\n",
        "        pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size), dtype=tf.float32)\n",
        "    else:\n",
        "\n",
        "        pixels = tf.argmax(pixels, axis=-1)\n",
        "        pixels = model.embedding_layer(pixels)\n",
        "        pixels = tf.math.multiply(pixels, mask)\n",
        "\n",
        "        mask = tf.repeat(mask, batch_size, axis=0)\n",
        "        mask = tf.cast(mask,  dtype=tf.float32)\n",
        "        pixels = tf.repeat(pixels, batch_size, axis=0)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, image_size[0], image_size[1]), 0, 4, dtype=tf.dtypes.int32)\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = noises #signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the chain\n",
        "    samples_list = []\n",
        "    samples_list.append( tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    time_steps = tf.linspace(1., eps, num_steps)\n",
        "    step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    prev_alphas = signal_rates**2\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for time_step in tqdm.tqdm(time_steps):\n",
        "        #print(time_step)\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        #print(batch_time_step)\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "        #print(noise_rates, signal_rates)\n",
        "        cur_alphas = signal_rates**2\n",
        "        betas = compute_beta(cur_alphas, prev_alphas)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        x_input = tf.math.multiply(x, tf.math.abs(mask - 1))\n",
        "        pred_x0, pred_noise = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        # optional second order sampling\n",
        "        if second_order_alpha is not None:\n",
        "            embed_pred_x0, pred_noises = second_order_correction(\n",
        "                model,\n",
        "                batch_time_step,\n",
        "                step_size,\n",
        "                x,\n",
        "                signal_rates,\n",
        "                noise_rates,\n",
        "                embed_pred_x0,\n",
        "                pred_noise,\n",
        "                second_order_alpha,\n",
        "                mask,\n",
        "                pixels,)\n",
        "\n",
        "        mean_x0 = tf.math.sqrt(cur_alphas) * betas / (1 - prev_alphas) * embed_pred_x0\n",
        "        mean_x = tf.math.sqrt(1 - betas) * (1 - cur_alphas) / (1 - prev_alphas) * x\n",
        "        x = mean_x + mean_x0 + tf.reshape(tf.math.sqrt(betas), (-1, 1, 1, 1)) * tf.random.normal(x.shape)\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        prev_alphas = cur_alphas\n",
        "\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "Krk0-qfIKNk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_snr_list(nb_steps, model, eps):\n",
        "\n",
        "    start_noise_rates, start_signal_rates = model.diffusion_schedule(np.array([eps, ]))\n",
        "    start_snr = compute_snr(start_signal_rates, start_noise_rates)\n",
        "    end_noise_rates, end_signal_rates = model.diffusion_schedule(np.array([1., ]))\n",
        "    end_snr = compute_snr(end_signal_rates, end_noise_rates)\n",
        "    list_i = np.arange(0, nb_steps, 1.0, dtype=int)\n",
        "    all_snr = tf.cast(list_i / nb_steps * (start_snr - end_snr) + end_snr, dtype=tf.float32)\n",
        "    all_t = tf.cast(get_t_from_snr(all_snr), dtype=tf.float32)\n",
        "\n",
        "    return all_snr, all_t"
      ],
      "metadata": {
        "id": "MYg3ZH4rpjqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_solver(model, img_embed_size, image_size, batch_size=10, num_steps=50, eps=1e-3, mask=None, pixels=None):\n",
        "    second_order_alpha = 1.1\n",
        "    # T and schedule\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    if mask is None:\n",
        "        mask = tf.zeros((batch_size, image_size[0], image_size[1], 1), dtype=tf.float32)\n",
        "        pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size), dtype=tf.float32)\n",
        "    else:\n",
        "\n",
        "        pixels = tf.argmax(pixels, axis=-1)\n",
        "        pixels = model.embedding_layer(pixels)\n",
        "        pixels = tf.math.multiply(pixels, mask)\n",
        "\n",
        "        mask = tf.repeat(mask, batch_size, axis=0)\n",
        "        mask = tf.cast(mask,  dtype=tf.float32)\n",
        "        pixels = tf.repeat(pixels, batch_size, axis=0)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, image_size[0], image_size[1]), 0, 4, dtype=tf.dtypes.int32)\n",
        "    # Pure white noise\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = noises #signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the Markov chain\n",
        "    samples_list = []\n",
        "    samples_list.append(tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    #time_steps = tf.linspace(1., eps, num_steps)\n",
        "    #step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    #prev_alphas = signal_rates**2\n",
        "    #prev_snr = compute_snr(signal_rates, noise_rates)\n",
        "    all_snr, time_steps = get_snr_list(num_steps, model, eps)\n",
        "\n",
        "    prev_noise_rates, prev_signal_rates = noise_rates, signal_rates\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for i, time_step in enumerate(tqdm.tqdm(time_steps)):\n",
        "        prev_snr = all_snr[i]\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        x_input = tf.math.multiply(x, tf.math.abs(mask - 1))\n",
        "        pred_x0, pred_noise = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "        samples_list.append(pred_x0)\n",
        "        #int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        # embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "        #predicted_noise = x_input - embed_pred_x0\n",
        "\n",
        "        #snr = compute_snr(signal_rates, noise_rates)\n",
        "        if i < len(time_steps)-1:\n",
        "            snr = all_snr[i+1]\n",
        "\n",
        "            s_t = get_t_from_snr((snr + prev_snr) / 2)\n",
        "            s_t = tf.repeat(tf.reshape(s_t, (1, 1, 1, 1)), batch_size, axis=0)\n",
        "\n",
        "            s_noise_rates, s_signal_rates = model.diffusion_schedule(s_t)\n",
        "\n",
        "\n",
        "            u = s_signal_rates / prev_signal_rates * x - s_noise_rates * (tf.math.exp((snr - prev_snr) / 2) - 1) * pred_noise\n",
        "\n",
        "            # PREDICT IMAGE 2\n",
        "            x_input = tf.math.multiply(u, tf.math.abs(mask - 1))\n",
        "            pred_x0, pred_noise = model.denoise(x_input, s_signal_rates, s_noise_rates, training=False, mask=mask, pixels=pixels)\n",
        "            #int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "            # embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "            # predicted_noise = x_input - embed_pred_x0\n",
        "            # print(noise_rates * (tf.math.exp((snr - prev_snr)) - 1))\n",
        "\n",
        "            x = signal_rates / prev_signal_rates * x - noise_rates * (tf.math.exp((snr - prev_snr)) - 1) * pred_noise\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        #prev_alphas = cur_alphas\n",
        "        prev_snr = snr\n",
        "        prev_noise_rates, prev_signal_rates = noise_rates, signal_rates\n",
        "    pred_x0, pred_noise = model.denoise(x, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "RBs0D0Ts6qNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_solver #@param ['ddpm_sampler', 'ddpm_solver'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (64, 128),\n",
        "                                sample_batch_size,\n",
        "                                num_steps=50,\n",
        "                                mask=None,\n",
        "                                pixels=None)"
      ],
      "metadata": {
        "id": "T0uowLytML_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "O4GzBJX-MUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data.load_data import ConditionalDataGenerator\n",
        "\n",
        "# Load Data\n",
        "slice_size = (64, 128, 4)\n",
        "dataloader = ConditionalDataGenerator(x_test, 1, slice_size, wells=10, mode=3)\n",
        "pixels, mask, ground_truth = dataloader.__getitem__(0)\n",
        "print(pixels.shape, mask.shape, ground_truth.shape)"
      ],
      "metadata": {
        "id": "LAAAFTajBiUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "images = []\n",
        "for i, batch in enumerate(samples_list):\n",
        "    figure = plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Timestep {0:.3f}\".format(1 - (i / 350)))\n",
        "    plt.imshow(np.argmax(batch[0].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.savefig('foo.png', bbox_inches='tight')\n",
        "    images.append(imageio.imread('foo.png'))\n",
        "    plt.show() #close(figure)\n",
        "#imageio.mimsave('/movie.gif', images)"
      ],
      "metadata": {
        "id": "m9JzX8pVMf7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(\"DEBUG\")"
      ],
      "metadata": {
        "id": "fJZxsZYbtlnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler #@param ['ddpm_sampler', 'pc_sampler'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (64, 128),\n",
        "                                sample_batch_size,\n",
        "                                mask=mask,\n",
        "                                pixels=pixels)"
      ],
      "metadata": {
        "id": "iGnksfxx3JRB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QjbvDyWoK7fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from utils.visualisation import *\n",
        "from data.load_data import get_3d_flumy_data, load_data, ConditionalDataGenerator\n",
        "from models.load_trained_models import load_msgen_horizontal, wgan_horizontal,\\\n",
        "    load_msnwgen_2d_gs_horizontal, load_wgan_gs_horizontal, load_mswgen_sn_3d_horizontal\n",
        "from utils.utils import generate_noise, correct_percentage\n"
      ],
      "metadata": {
        "id": "pP5_ix6TCLdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_simulations = 3\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "\n",
        "print_conditioned_results(ground_truth, samples, mask, nb_simulations, cmap, norm)"
      ],
      "metadata": {
        "id": "0nla2sslCFTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.imshow(np.argmax(ground_truth, axis=-1).reshape((64, 128)),\n",
        "            interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "URj4sIq1BlYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler #@param ['ddpm_sampler', 'pc_sampler'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (128, 256),\n",
        "                                sample_batch_size,)"
      ],
      "metadata": {
        "id": "gzMLizIXPUAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((128, 256)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p88yuQgCPUA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF"
      ],
      "metadata": {
        "id": "8X9v42ujwnt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Models"
      ],
      "metadata": {
        "id": "GCPKYflD2fyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SAVE_AND_TAR_RESULTS_WEIGHTS = True\n",
        "\n",
        "if SAVE_AND_TAR_RESULTS_WEIGHTS:\n",
        "  diffusion_checkpoint_path = \"diffusion_weights_horiz/cp-diffusion2d_net_horiz.ckpt\"\n",
        "  diffusion_checkpoint_dir = os.path.dirname(diffusion_checkpoint_path)\n",
        "\n",
        "  model.ema_network.save_weights(diffusion_checkpoint_path)\n",
        "\n",
        "  !tar -czvf diffusion_weights_horiz.tar.gz ./diffusion_weights_horiz\n",
        "\n",
        "  diffusion_checkpoint_path = \"diffusion_weights_horiz/cp-diffusion2d_embed_horiz.ckpt\"\n",
        "  diffusion_checkpoint_dir = os.path.dirname(diffusion_checkpoint_path)\n",
        "\n",
        "  model.embedding_layer.save_weights(diffusion_checkpoint_path)\n",
        "\n",
        "  !tar -czvf diffusion_weights_horiz.tar.gz ./diffusion_weights_horiz"
      ],
      "metadata": {
        "id": "gi9sVjP0QHdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddim",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}