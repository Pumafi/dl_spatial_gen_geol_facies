{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/fast_stationary_ddim_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "TA0koXfT2e7k",
        "outputId": "2475076e-b259-4d4d-ca82-249d82ba2020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 12 13:04:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IDEAS \n",
        "1.   Normalization in embedding ?\n",
        "2.   Formula when I replace beta by t\n",
        "3.   Use keras inference for potential changes\n",
        "\n",
        "## What to try next?\n",
        "\n",
        "If you would like to dive in deeper to the topic, a recommend checking out\n",
        "[this repository](https://github.com/beresandras/clear-diffusion-keras) that I created in\n",
        "preparation for this code example, which implements a wider range of features in a\n",
        "similar style, such as:\n",
        "\n",
        "* stochastic sampling\n",
        "* second-order sampling based on the\n",
        "[differential equation view of DDIMs (Equation 13)](https://arxiv.org/abs/2010.02502)\n",
        "* more diffusion schedules\n",
        "* more network output types: predicting image or\n",
        "[velocity (Appendix D)](https://arxiv.org/abs/2202.00512) instead of noise\n",
        "* more datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rge41L-HIY-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkfNOJcD0Ym"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install deel.lip\n",
        "!python -m pip install -i https://test.pypi.org/simple/ gstlearn"
      ],
      "metadata": {
        "id": "u03Nq4eK2ems",
        "outputId": "6721aa3d-ac8c-41af-f3c6-25ae4662cfc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deel.lip\n",
            "  Downloading deel_lip-1.4.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deel.lip) (1.22.4)\n",
            "Requirement already satisfied: tensorflow~=2.2 in /usr/local/lib/python3.10/dist-packages (from deel.lip) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.2->deel.lip) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.2->deel.lip) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.2->deel.lip) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.2->deel.lip) (3.2.2)\n",
            "Installing collected packages: deel.lip\n",
            "Successfully installed deel.lip-1.4.0\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gstlearn\n",
            "  Downloading https://test-files.pythonhosted.org/packages/4b/33/9b8e2546cfe286525409a1d17279b325a7a1d2968eba07357a0e30976d29/gstlearn-0.2.1-cp310-cp310-manylinux1_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gstlearn) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from gstlearn) (5.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gstlearn) (1.5.3)\n",
            "INFO: pip is looking at multiple versions of gstlearn to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://test-files.pythonhosted.org/packages/ea/39/5475c8fac8f0b9897ef6be34b92d40dae6d209dbfe2a7db0fb7a9386fadc/gstlearn-0.1.38-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://test-files.pythonhosted.org/packages/11/e9/eee76162b77c60d4c57aea94c230259605295eb3ad7e76b4b3c67773ff0f/gstlearn-0.1.37-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gstlearn\n",
            "Successfully installed gstlearn-0.1.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "    \n",
        "    %cd {REPO_DIR}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPH8VxsGGrb",
        "outputId": "3f421c6d-ad7e-49eb-d1b0-04c8efdd0c26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'flumy-wgan-mines'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 146 (delta 31), reused 74 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 140.19 MiB | 10.37 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (121/121), done.\n",
            "/content/flumy-wgan-mines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3E8qnnCGH5K",
        "outputId": "63d1967f-e21b-4eff-832a-f3e9ee9fdfc4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2VQcRg8KD0Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983f4268-8352-4e71-d12d-dba7d95073be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from data.load_data import load_data\n",
        "from utils.visualisation import get_color_map\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "1eF1rmySGCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful constants\n",
        "image_size = (64, 128)\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "facies_names = np.array([\"Sand, Channel lag\", \"Sand, Point bar\", \"Silts, Levee\", \"Shale, Overbank\"])\n",
        "x = load_data(image_size[0], image_size[1], \"./data/horizontal/dataFlumyHoriz.csv\")\n",
        "x_train = x[:2760]\n",
        "x_test = x[2760:]"
      ],
      "metadata": {
        "id": "4yPyDmhUGCTa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-ElzPrD0Yq"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FBoSc7iCD0Ys"
      },
      "outputs": [],
      "source": [
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "widths = [32, 64, 128, 256]\n",
        "block_depth = 2\n",
        "\n",
        "# Data values embedding\n",
        "img_embed_size = 64\n",
        "categories_nb = 4\n",
        "\n",
        "# optimization\n",
        "batch_size = 30\n",
        "ema = 0.999\n",
        "learning_rate = 1e-4\n",
        "embeding_net_lr = 1e-3\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diffusion Schedules"
      ],
      "metadata": {
        "id": "acL9rhHAdCCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DiffusionSchedule(ABC):\n",
        "    def __init__(self, start_log_snr, end_log_snr):\n",
        "        assert (\n",
        "            start_log_snr > end_log_snr\n",
        "        ), \"The starting SNR has to be higher than the final SNR.\"\n",
        "\n",
        "        self.end_beta = 20\n",
        "        self.start_beta = 0.1\n",
        "\n",
        "        self.start_snr = tf.exp(start_log_snr)\n",
        "        self.end_snr = tf.exp(end_log_snr)\n",
        "\n",
        "        #self.start_noise_power = 1.0 / (1.0 + self.start_snr)\n",
        "        #self.end_noise_power = 1.0 / (1.0 + self.end_snr)\n",
        "\n",
        "    def __call__(self, diffusion_times):\n",
        "        signal_powers = self.get_noise_powers(diffusion_times)\n",
        "        signal_rates = tf.math.exp(signal_powers)\n",
        "\n",
        "        noise_rates = (1 - signal_rates**2)**0.5\n",
        "\n",
        "\n",
        "        # the signal and noise power will always sum to one\n",
        "        #signal_powers = 1.0 - noise_powers\n",
        "\n",
        "        # the rates are the square roots of the powers\n",
        "        # variance**0.5 -> standard deviation\n",
        "        #signal_rates = signal_powers**0.5\n",
        "        #noise_rates = noise_powers**0.5\n",
        "\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SignalStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current signal powers decreases approximately linearly to 1\n",
        "    # similar to the \"linear schedule\" of DDPM https://arxiv.org/abs/2006.11239\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        \n",
        "        return -(self.end_beta - self.start_beta) / 4 * diffusion_times**2 - self.start_beta / 2 * diffusion_times\n",
        "\n",
        "        #return 1.0 - (1.0 - self.start_noise_power) * (\n",
        "        #    (1.0 - self.end_noise_power) / (1.0 - self.start_noise_power)\n",
        "        #) ** (diffusion_times**2)"
      ],
      "metadata": {
        "id": "Z5U9ClBmdDxI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_snr(signal_rate, noise_rate):\n",
        "    return tf.math.log(signal_rate / noise_rate)\n",
        "\n",
        "def get_t_from_snr(snr):\n",
        "    max_beta = 20.\n",
        "    min_beta = 0.1\n",
        "    return 2 * tf.math.log(tf.math.exp(-2*snr)+1) / (tf.math.sqrt(min_beta**2 + 2\n",
        "                                                                 * (max_beta - min_beta)\n",
        "                                                                 * tf.math.log(tf.math.exp(-2*snr)+1)) + min_beta)"
      ],
      "metadata": {
        "id": "WKvodkeuyJFb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "t = np.array([0.486,])\n",
        "noise_rates, signal_rates = diff_schedule(t)\n",
        "snr = compute_snr(signal_rates, noise_rates)\n",
        "t_prime = get_t_from_snr(snr)\n",
        "print(t_prime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qItvy_HRVox_",
        "outputId": "e93a1f4b-a1eb-49d1-8149-85d0dc7116ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.486], shape=(1,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "QxyZaS_UJ_YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(tf.keras.layers.Layer):\n",
        "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights during initialization. These weights are fixed \n",
        "        # during optimization and are not trainable.\n",
        "        self.W = self.add_weight(shape=(embed_dim // 2,),\n",
        "                                 trainable=False,\n",
        "                                 initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.), name=\"GFP\") * tf.constant(scale, dtype=tf.float32)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        x_proj = x * self.W * tf.constant(2., dtype=tf.float32) * tf.constant(np.pi, dtype=tf.float32)\n",
        "        y = tf.concat([tf.math.sin(x_proj), tf.cos(x_proj)], axis=-1)\n",
        "        return y # Probleme vient pas de là :()\n",
        "\n",
        "class CustomLinear(tf.keras.layers.Layer):\n",
        "    \"\"\"Rhaaah.\"\"\"  \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.W = tf.random.uniform((input_dim, output_dim), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "        self.b = tf.random.uniform((1, output_dim, ), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = tf.tensordot(x, self.W, 1) + self.b\n",
        "        y = tf.keras.activations.gelu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "class EmbedLayerNormalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.beta = self.add_weight(shape=(1, 1, 1, 1),\n",
        "                                    initializer=tf.keras.initializers.Zeros(),\n",
        "                                    dtype=tf.float32,\n",
        "                                    name=\"beta_embed_layer\",\n",
        "                                    trainable=True)\n",
        "        self.gamma = self.add_weight(shape=(1, 1, 1, 1),\n",
        "                                     initializer=tf.keras.initializers.Ones(),\n",
        "                                     dtype=tf.float32,\n",
        "                                     name=\"gamma_embed_layer\",\n",
        "                                     trainable=True)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "\n",
        "        mean, variance = tf.nn.moments(inputs, -1, keepdims=True)\n",
        "        outputs = tf.nn.batch_normalization(\n",
        "            inputs,\n",
        "            mean,\n",
        "            variance,\n",
        "            offset=self.beta,\n",
        "            scale=self.gamma,\n",
        "            variance_epsilon=1e-8,\n",
        "        )\n",
        "\n",
        "        return outputs #* self.gamma + self.beta\n",
        "\n",
        "@tf.function\n",
        "def embedding_normalization(logits):\n",
        "    # normalement vont avoir taille (batch_size, 64, 128, embedding_size)\n",
        "    # axis=-1 is embedding normalement\n",
        "    return (logits / tf.norm(logits, axis=-1, keepdims=True)) * tf.constant(np.sqrt(logits.shape[-1]), dtype=tf.float32)\n",
        "\n",
        "class NormalizedEmbedding(tf.keras.Model):\n",
        "    \"\"\"\"\"\"  \n",
        "    def __init__(self, categories_nb, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.embed_layer = tf.keras.layers.Embedding(categories_nb, img_embed_size)\n",
        "        self.embed_layer2 = layers.Conv2D(img_embed_size, kernel_size=1, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer3 = layers.Conv2D(img_embed_size, kernel_size=1, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer4 = layers.Conv2D(img_embed_size, kernel_size=1, activation=None)\n",
        "        self.layer_norm = EmbedLayerNormalization(img_embed_size=16)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        # I tested the embedding it's perfectly pixel by pixel\n",
        "        y = self.embed_layer(x)\n",
        "        y = self.embed_layer2(y)\n",
        "        y = self.embed_layer3(y)\n",
        "        y = self.embed_layer4(y)\n",
        "        #y = embedding_normalization(y)\n",
        "        y = self.layer_norm(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "Ej4nARwoGmme"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network(\n",
        "    image_size,\n",
        "    noise_embedding_max_frequency,\n",
        "    noise_embedding_dims,\n",
        "    image_embedding_dims,\n",
        "    block_depth,\n",
        "    widths,\n",
        "    attentions,\n",
        "    patch_size,\n",
        "    embed_size\n",
        "):\n",
        "    def EmbeddingLayer(embedding_max_frequency, embedding_dims):\n",
        "        def sinusoidal_embedding(x):\n",
        "            embedding_min_frequency = 1.0\n",
        "            frequencies = tf.exp(\n",
        "                tf.linspace(\n",
        "                    tf.math.log(embedding_min_frequency),\n",
        "                    tf.math.log(embedding_max_frequency),\n",
        "                    embedding_dims // 2,\n",
        "                )\n",
        "            )\n",
        "            angular_speeds = 2.0 * math.pi * frequencies\n",
        "            embeddings = tf.concat(\n",
        "                [\n",
        "                    tf.sin(angular_speeds * x),\n",
        "                    tf.cos(angular_speeds * x),\n",
        "                ],\n",
        "                axis=-1,\n",
        "            )\n",
        "            return embeddings\n",
        "\n",
        "        def forward(x):\n",
        "            x = layers.Lambda(sinusoidal_embedding)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def ResidualBlock(width, attention):\n",
        "        def forward(x):\n",
        "            x, n = x\n",
        "            input_width = x.shape[3]\n",
        "            if input_width == width:\n",
        "                residual = x\n",
        "            else:\n",
        "                residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "\n",
        "            n = layers.Dense(width)(n)\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([x, n])\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([residual, x])\n",
        "\n",
        "            if attention:\n",
        "                residual = x\n",
        "                x = tfa.layers.GroupNormalization(groups=8, center=False, scale=False)(\n",
        "                    x\n",
        "                )\n",
        "                x = layers.MultiHeadAttention(\n",
        "                    num_heads=4, key_dim=width, attention_axes=(1, 2)\n",
        "                )(x, x)\n",
        "\n",
        "                x = layers.Add()([residual, x])\n",
        "\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def DownBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            for _ in range(block_depth):\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "                skips.append(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def UpBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "            for _ in range(block_depth):\n",
        "                x = layers.Concatenate()([x, skips.pop()])\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    images = keras.Input(shape=(None, None, embed_size))\n",
        "    noise_powers = keras.Input(shape=(1, 1, 1))\n",
        "    mask = keras.Input(shape=(None, None, 1))\n",
        "    conditioning_pixels = keras.Input(shape=(None, None, embed_size))\n",
        "\n",
        "    x = tf.keras.layers.Concatenate(axis=-1)([images, mask, conditioning_pixels])\n",
        "\n",
        "    x = layers.Conv2D(image_embedding_dims, kernel_size=patch_size, strides=patch_size)(\n",
        "        x\n",
        "    )\n",
        "\n",
        "    # NOISE EMBEDDING\n",
        "    #print(noise_powers)\n",
        "    n = EmbeddingLayer(noise_embedding_max_frequency, noise_embedding_dims)(\n",
        "        noise_powers\n",
        "    )\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "\n",
        "    skips = []\n",
        "    for width, attention in zip(widths[:-1], attentions[:-1]):\n",
        "        x = DownBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1], attentions[-1])([x, n])\n",
        "\n",
        "    for width, attention in zip(widths[-2::-1], attentions[-2::-1]):\n",
        "        x = UpBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    x = layers.Conv2DTranspose(\n",
        "        4, kernel_size=patch_size, strides=patch_size, kernel_initializer=\"zeros\", activation=\"softmax\"\n",
        "    )(x)\n",
        "\n",
        "    return keras.Model([images, noise_powers, mask, conditioning_pixels], x, name=\"residual_unet\")"
      ],
      "metadata": {
        "id": "IgeH9voVvsN5"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling\n",
        "def make_mask(image_to_condition):\n",
        "    nb_conditioning_points = np.random.randint(low=1.0, high=image_to_condition.shape[0] * image_to_condition.shape[1])\n",
        "    random_x_coordinates = np.random.choice(image_to_condition.shape[0], nb_conditioning_points)\n",
        "    random_y_coordinates = np.random.choice(image_to_condition.shape[1], nb_conditioning_points)\n",
        "    mask = np.zeros((image_to_condition.shape[0], image_to_condition.shape[1], 1))\n",
        "    mask[random_x_coordinates, random_y_coordinates, :] = 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "XEMZlA-xdLcT"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "lZ37576YD0Y5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth, img_embed_size,\n",
        "                 categories_nb, embedding_lr=1e-3, batch_size=30,\n",
        "                 large_model=False):\n",
        "        super().__init__()\n",
        "\n",
        "        noise_embedding_max_frequency = 1000.0\n",
        "        noise_embedding_dims = 64\n",
        "        image_embedding_dims = 64\n",
        "        block_depth = 2\n",
        "\n",
        "        if large_model:\n",
        "            widths = [64, 128, 256, 512]\n",
        "            attentions = [False, False, True, True]\n",
        "        else:\n",
        "            widths = [64, 96, 128, 256]\n",
        "            attentions = [False, False, False, False]\n",
        "            \n",
        "        patch_size = 1\n",
        "\n",
        "        self.diffusion_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        #self.diffusion_schedule = CosineSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        self.network = get_network(image_size, noise_embedding_max_frequency,\n",
        "                                   noise_embedding_dims, image_embedding_dims,\n",
        "                                   block_depth, widths, attentions, patch_size,\n",
        "                                   img_embed_size)\n",
        "        \n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Embedding\n",
        "        self.img_embed_size = img_embed_size\n",
        "        self.embedding_layer = NormalizedEmbedding(categories_nb, img_embed_size)\n",
        "        self.emb_optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=embedding_lr)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.image_loss_tracker]\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training, mask=None, pixels=None):\n",
        "        # the exponential moving average weights are used at evaluation\n",
        "\n",
        "        if mask is None or pixels is None:\n",
        "            mask = tf.zeros(noisy_images.shape)\n",
        "            pixels = tf.zeros(noisy_images.shape)\n",
        "\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        # predict noise component and calculate the image component using it\n",
        "        pred_images = network([noisy_images, noise_rates**2, mask, pixels], training=training)\n",
        "\n",
        "        \n",
        "        int_encoded_img = tf.argmax(pred_images, axis=-1)\n",
        "        embed_pred_images = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        pred_noises = (noisy_images - signal_rates * embed_pred_images) / noise_rates\n",
        "\n",
        "        return pred_images, pred_noises\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(self.batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        mask_uncondi = tf.zeros((self.batch_size // 2, images.shape[1], images.shape[2], 1))\n",
        "        mask_condi = tf.map_fn(make_mask, images[self.batch_size // 2:])\n",
        "        mask = tf.concat([mask_uncondi, mask_condi], axis=0)\n",
        "\n",
        "\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            embed_images = self.embedding_layer(int_encoded_img)\n",
        "            pixels = tf.math.multiply(embed_images, mask)\n",
        "\n",
        "            noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "            noisy_images = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_images, pred_noise = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True, mask=mask, pixels=pixels\n",
        "            )\n",
        "\n",
        "            image_loss = self.loss(images, pred_images)  # training loss\n",
        "            \n",
        "\n",
        "        gradients_model = tape1.gradient(image_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.network.trainable_weights))\n",
        "\n",
        "        gradients_embeddings = tape2.gradient(image_loss, self.embedding_layer.trainable_weights)\n",
        "        self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        # KID is not measured during the training phase for computational efficiency\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "\n",
        "        mask_uncondi = tf.zeros((self.batch_size // 2, images.shape[1], images.shape[2], 1))\n",
        "        mask_condi = tf.map_fn(make_mask, images[self.batch_size // 2:])\n",
        "        mask = tf.concat([mask_uncondi, mask_condi], axis=0)\n",
        "\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        embed_images = self.embedding_layer(int_encoded_img)\n",
        "\n",
        "        #std = marginal_prob_std(diffusion_times, sigma=sigma)\n",
        "        pixels = tf.math.multiply(embed_images, mask)\n",
        "\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "        noisy_images = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "        #noisy_images = embed_images + noises * tf.reshape(std, (-1, 1, 1, 1))\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_images, pred_noise = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels\n",
        "        )\n",
        "\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYrG2VPD0Y7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "LHcHZit9D0Y8"
      },
      "outputs": [],
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth, img_embed_size=img_embed_size, categories_nb=categories_nb, large_model=True)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "t_epochs_nb=1\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, batch_size=batch_size, epochs=t_epochs_nb, validation_data=(x_test,))"
      ],
      "metadata": {
        "id": "RDSktS3wIy4C",
        "outputId": "a73689d9-0b0f-4d73-daf1-c5aa19bf9ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 180s 1s/step - i_loss: 0.5995 - val_i_loss: 1.3849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.network.summary()"
      ],
      "metadata": {
        "id": "Jcm7Vh6v9R0s",
        "outputId": "10473cc2-77bc-45bf-981f-7da8521d8665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"residual_unet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None, None, None,  0           []                               \n",
            "                                 64)]                                                             \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)          [(None, None, None,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " input_24 (InputLayer)          [(None, None, None,  0           []                               \n",
            "                                 64)]                                                             \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, None, None,   0           ['input_21[0][0]',               \n",
            "                                129)                              'input_23[0][0]',               \n",
            "                                                                  'input_24[0][0]']               \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)          [(None, 1, 1, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, None, None,   8320        ['concatenate_35[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 64)     0           ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_170 (Group  (None, None, None,   128        ['conv2d_205[0][0]']             \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " dense_80 (Dense)               (None, 1, 1, 64)     4160        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " tf.nn.silu_140 (TFOpLambda)    (None, None, None,   0           ['group_normalization_170[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " dense_81 (Dense)               (None, 1, 1, 64)     4160        ['dense_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_140[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " dense_82 (Dense)               (None, 1, 1, 64)     4160        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_170 (Add)                  (None, None, None,   0           ['conv2d_206[0][0]',             \n",
            "                                64)                               'dense_82[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_171 (Group  (None, None, None,   128        ['add_170[0][0]']                \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_141 (TFOpLambda)    (None, None, None,   0           ['group_normalization_171[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_141[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_171 (Add)                  (None, None, None,   0           ['conv2d_205[0][0]',             \n",
            "                                64)                               'conv2d_207[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_172 (Group  (None, None, None,   128        ['add_171[0][0]']                \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_142 (TFOpLambda)    (None, None, None,   0           ['group_normalization_172[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_142[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " dense_83 (Dense)               (None, 1, 1, 64)     4160        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_172 (Add)                  (None, None, None,   0           ['conv2d_208[0][0]',             \n",
            "                                64)                               'dense_83[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_173 (Group  (None, None, None,   128        ['add_172[0][0]']                \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_143 (TFOpLambda)    (None, None, None,   0           ['group_normalization_173[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_143[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_173 (Add)                  (None, None, None,   0           ['add_171[0][0]',                \n",
            "                                64)                               'conv2d_209[0][0]']             \n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, None, None,   0          ['add_173[0][0]']                \n",
            " ooling2D)                      64)                                                               \n",
            "                                                                                                  \n",
            " group_normalization_174 (Group  (None, None, None,   128        ['average_pooling2d_15[0][0]']   \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_144 (TFOpLambda)    (None, None, None,   0           ['group_normalization_174[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, None, None,   73856       ['tf.nn.silu_144[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " dense_84 (Dense)               (None, 1, 1, 128)    8320        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_174 (Add)                  (None, None, None,   0           ['conv2d_211[0][0]',             \n",
            "                                128)                              'dense_84[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_175 (Group  (None, None, None,   256        ['add_174[0][0]']                \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_145 (TFOpLambda)    (None, None, None,   0           ['group_normalization_175[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, None, None,   8320        ['average_pooling2d_15[0][0]']   \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_145[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_175 (Add)                  (None, None, None,   0           ['conv2d_210[0][0]',             \n",
            "                                128)                              'conv2d_212[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_176 (Group  (None, None, None,   256        ['add_175[0][0]']                \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_146 (TFOpLambda)    (None, None, None,   0           ['group_normalization_176[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_146[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " dense_85 (Dense)               (None, 1, 1, 128)    8320        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_176 (Add)                  (None, None, None,   0           ['conv2d_213[0][0]',             \n",
            "                                128)                              'dense_85[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_177 (Group  (None, None, None,   256        ['add_176[0][0]']                \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_147 (TFOpLambda)    (None, None, None,   0           ['group_normalization_177[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_147[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_177 (Add)                  (None, None, None,   0           ['add_175[0][0]',                \n",
            "                                128)                              'conv2d_214[0][0]']             \n",
            "                                                                                                  \n",
            " average_pooling2d_16 (AverageP  (None, None, None,   0          ['add_177[0][0]']                \n",
            " ooling2D)                      128)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_178 (Group  (None, None, None,   256        ['average_pooling2d_16[0][0]']   \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_148 (TFOpLambda)    (None, None, None,   0           ['group_normalization_178[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, None, None,   295168      ['tf.nn.silu_148[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " dense_86 (Dense)               (None, 1, 1, 256)    16640       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_178 (Add)                  (None, None, None,   0           ['conv2d_216[0][0]',             \n",
            "                                256)                              'dense_86[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_179 (Group  (None, None, None,   512        ['add_178[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_149 (TFOpLambda)    (None, None, None,   0           ['group_normalization_179[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, None, None,   33024       ['average_pooling2d_16[0][0]']   \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, None, None,   590080      ['tf.nn.silu_149[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_179 (Add)                  (None, None, None,   0           ['conv2d_215[0][0]',             \n",
            "                                256)                              'conv2d_217[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_180 (Group  (None, None, None,   0          ['add_179[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_30 (Multi  (None, None, None,   1051904    ['group_normalization_180[0][0]',\n",
            " HeadAttention)                 256)                              'group_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " add_180 (Add)                  (None, None, None,   0           ['add_179[0][0]',                \n",
            "                                256)                              'multi_head_attention_30[0][0]']\n",
            "                                                                                                  \n",
            " group_normalization_181 (Group  (None, None, None,   512        ['add_180[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_150 (TFOpLambda)    (None, None, None,   0           ['group_normalization_181[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, None, None,   590080      ['tf.nn.silu_150[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " dense_87 (Dense)               (None, 1, 1, 256)    16640       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_181 (Add)                  (None, None, None,   0           ['conv2d_218[0][0]',             \n",
            "                                256)                              'dense_87[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_182 (Group  (None, None, None,   512        ['add_181[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_151 (TFOpLambda)    (None, None, None,   0           ['group_normalization_182[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, None, None,   590080      ['tf.nn.silu_151[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_182 (Add)                  (None, None, None,   0           ['add_180[0][0]',                \n",
            "                                256)                              'conv2d_219[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_183 (Group  (None, None, None,   0          ['add_182[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_31 (Multi  (None, None, None,   1051904    ['group_normalization_183[0][0]',\n",
            " HeadAttention)                 256)                              'group_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " add_183 (Add)                  (None, None, None,   0           ['add_182[0][0]',                \n",
            "                                256)                              'multi_head_attention_31[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_17 (AverageP  (None, None, None,   0          ['add_183[0][0]']                \n",
            " ooling2D)                      256)                                                              \n",
            "                                                                                                  \n",
            " group_normalization_184 (Group  (None, None, None,   512        ['average_pooling2d_17[0][0]']   \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_152 (TFOpLambda)    (None, None, None,   0           ['group_normalization_184[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, None, None,   1180160     ['tf.nn.silu_152[0][0]']         \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " dense_88 (Dense)               (None, 1, 1, 512)    33280       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_184 (Add)                  (None, None, None,   0           ['conv2d_221[0][0]',             \n",
            "                                512)                              'dense_88[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_185 (Group  (None, None, None,   1024       ['add_184[0][0]']                \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_153 (TFOpLambda)    (None, None, None,   0           ['group_normalization_185[0][0]']\n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, None, None,   131584      ['average_pooling2d_17[0][0]']   \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, None, None,   2359808     ['tf.nn.silu_153[0][0]']         \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " add_185 (Add)                  (None, None, None,   0           ['conv2d_220[0][0]',             \n",
            "                                512)                              'conv2d_222[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_186 (Group  (None, None, None,   0          ['add_185[0][0]']                \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_32 (Multi  (None, None, None,   4200960    ['group_normalization_186[0][0]',\n",
            " HeadAttention)                 512)                              'group_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " add_186 (Add)                  (None, None, None,   0           ['add_185[0][0]',                \n",
            "                                512)                              'multi_head_attention_32[0][0]']\n",
            "                                                                                                  \n",
            " group_normalization_187 (Group  (None, None, None,   1024       ['add_186[0][0]']                \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_154 (TFOpLambda)    (None, None, None,   0           ['group_normalization_187[0][0]']\n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, None, None,   2359808     ['tf.nn.silu_154[0][0]']         \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " dense_89 (Dense)               (None, 1, 1, 512)    33280       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_187 (Add)                  (None, None, None,   0           ['conv2d_223[0][0]',             \n",
            "                                512)                              'dense_89[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_188 (Group  (None, None, None,   1024       ['add_187[0][0]']                \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_155 (TFOpLambda)    (None, None, None,   0           ['group_normalization_188[0][0]']\n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, None, None,   2359808     ['tf.nn.silu_155[0][0]']         \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " add_188 (Add)                  (None, None, None,   0           ['add_186[0][0]',                \n",
            "                                512)                              'conv2d_224[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_189 (Group  (None, None, None,   0          ['add_188[0][0]']                \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_33 (Multi  (None, None, None,   4200960    ['group_normalization_189[0][0]',\n",
            " HeadAttention)                 512)                              'group_normalization_189[0][0]']\n",
            "                                                                                                  \n",
            " add_189 (Add)                  (None, None, None,   0           ['add_188[0][0]',                \n",
            "                                512)                              'multi_head_attention_33[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_15 (UpSampling2D  (None, None, None,   0          ['add_189[0][0]']                \n",
            " )                              512)                                                              \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, None, None,   0           ['up_sampling2d_15[0][0]',       \n",
            "                                768)                              'add_183[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_190 (Group  (None, None, None,   1536       ['concatenate_36[0][0]']         \n",
            " Normalization)                 768)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_156 (TFOpLambda)    (None, None, None,   0           ['group_normalization_190[0][0]']\n",
            "                                768)                                                              \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, None, None,   1769728     ['tf.nn.silu_156[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " dense_90 (Dense)               (None, 1, 1, 256)    16640       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_190 (Add)                  (None, None, None,   0           ['conv2d_226[0][0]',             \n",
            "                                256)                              'dense_90[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_191 (Group  (None, None, None,   512        ['add_190[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_157 (TFOpLambda)    (None, None, None,   0           ['group_normalization_191[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, None, None,   196864      ['concatenate_36[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)            (None, None, None,   590080      ['tf.nn.silu_157[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_191 (Add)                  (None, None, None,   0           ['conv2d_225[0][0]',             \n",
            "                                256)                              'conv2d_227[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_192 (Group  (None, None, None,   0          ['add_191[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_34 (Multi  (None, None, None,   1051904    ['group_normalization_192[0][0]',\n",
            " HeadAttention)                 256)                              'group_normalization_192[0][0]']\n",
            "                                                                                                  \n",
            " add_192 (Add)                  (None, None, None,   0           ['add_191[0][0]',                \n",
            "                                256)                              'multi_head_attention_34[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, None, None,   0           ['add_192[0][0]',                \n",
            "                                512)                              'add_180[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_193 (Group  (None, None, None,   1024       ['concatenate_37[0][0]']         \n",
            " Normalization)                 512)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_158 (TFOpLambda)    (None, None, None,   0           ['group_normalization_193[0][0]']\n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)            (None, None, None,   1179904     ['tf.nn.silu_158[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " dense_91 (Dense)               (None, 1, 1, 256)    16640       ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_193 (Add)                  (None, None, None,   0           ['conv2d_229[0][0]',             \n",
            "                                256)                              'dense_91[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_194 (Group  (None, None, None,   512        ['add_193[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_159 (TFOpLambda)    (None, None, None,   0           ['group_normalization_194[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)            (None, None, None,   131328      ['concatenate_37[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)            (None, None, None,   590080      ['tf.nn.silu_159[0][0]']         \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " add_194 (Add)                  (None, None, None,   0           ['conv2d_228[0][0]',             \n",
            "                                256)                              'conv2d_230[0][0]']             \n",
            "                                                                                                  \n",
            " group_normalization_195 (Group  (None, None, None,   0          ['add_194[0][0]']                \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " multi_head_attention_35 (Multi  (None, None, None,   1051904    ['group_normalization_195[0][0]',\n",
            " HeadAttention)                 256)                              'group_normalization_195[0][0]']\n",
            "                                                                                                  \n",
            " add_195 (Add)                  (None, None, None,   0           ['add_194[0][0]',                \n",
            "                                256)                              'multi_head_attention_35[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_16 (UpSampling2D  (None, None, None,   0          ['add_195[0][0]']                \n",
            " )                              256)                                                              \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, None, None,   0           ['up_sampling2d_16[0][0]',       \n",
            "                                384)                              'add_177[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_196 (Group  (None, None, None,   768        ['concatenate_38[0][0]']         \n",
            " Normalization)                 384)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_160 (TFOpLambda)    (None, None, None,   0           ['group_normalization_196[0][0]']\n",
            "                                384)                                                              \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)            (None, None, None,   442496      ['tf.nn.silu_160[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " dense_92 (Dense)               (None, 1, 1, 128)    8320        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_196 (Add)                  (None, None, None,   0           ['conv2d_232[0][0]',             \n",
            "                                128)                              'dense_92[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_197 (Group  (None, None, None,   256        ['add_196[0][0]']                \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_161 (TFOpLambda)    (None, None, None,   0           ['group_normalization_197[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)            (None, None, None,   49280       ['concatenate_38[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_161[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_197 (Add)                  (None, None, None,   0           ['conv2d_231[0][0]',             \n",
            "                                128)                              'conv2d_233[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, None, None,   0           ['add_197[0][0]',                \n",
            "                                256)                              'add_175[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_198 (Group  (None, None, None,   512        ['concatenate_39[0][0]']         \n",
            " Normalization)                 256)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_162 (TFOpLambda)    (None, None, None,   0           ['group_normalization_198[0][0]']\n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)            (None, None, None,   295040      ['tf.nn.silu_162[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " dense_93 (Dense)               (None, 1, 1, 128)    8320        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_198 (Add)                  (None, None, None,   0           ['conv2d_235[0][0]',             \n",
            "                                128)                              'dense_93[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_199 (Group  (None, None, None,   256        ['add_198[0][0]']                \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_163 (TFOpLambda)    (None, None, None,   0           ['group_normalization_199[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)            (None, None, None,   32896       ['concatenate_39[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)            (None, None, None,   147584      ['tf.nn.silu_163[0][0]']         \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " add_199 (Add)                  (None, None, None,   0           ['conv2d_234[0][0]',             \n",
            "                                128)                              'conv2d_236[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_17 (UpSampling2D  (None, None, None,   0          ['add_199[0][0]']                \n",
            " )                              128)                                                              \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, None, None,   0           ['up_sampling2d_17[0][0]',       \n",
            "                                192)                              'add_173[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_200 (Group  (None, None, None,   384        ['concatenate_40[0][0]']         \n",
            " Normalization)                 192)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_164 (TFOpLambda)    (None, None, None,   0           ['group_normalization_200[0][0]']\n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)            (None, None, None,   110656      ['tf.nn.silu_164[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " dense_94 (Dense)               (None, 1, 1, 64)     4160        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_200 (Add)                  (None, None, None,   0           ['conv2d_238[0][0]',             \n",
            "                                64)                               'dense_94[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_201 (Group  (None, None, None,   128        ['add_200[0][0]']                \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_165 (TFOpLambda)    (None, None, None,   0           ['group_normalization_201[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)            (None, None, None,   12352       ['concatenate_40[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_165[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_201 (Add)                  (None, None, None,   0           ['conv2d_237[0][0]',             \n",
            "                                64)                               'conv2d_239[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, None, None,   0           ['add_201[0][0]',                \n",
            "                                128)                              'add_171[0][0]']                \n",
            "                                                                                                  \n",
            " group_normalization_202 (Group  (None, None, None,   256        ['concatenate_41[0][0]']         \n",
            " Normalization)                 128)                                                              \n",
            "                                                                                                  \n",
            " tf.nn.silu_166 (TFOpLambda)    (None, None, None,   0           ['group_normalization_202[0][0]']\n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)            (None, None, None,   73792       ['tf.nn.silu_166[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " dense_95 (Dense)               (None, 1, 1, 64)     4160        ['dense_81[0][0]']               \n",
            "                                                                                                  \n",
            " add_202 (Add)                  (None, None, None,   0           ['conv2d_241[0][0]',             \n",
            "                                64)                               'dense_95[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_203 (Group  (None, None, None,   128        ['add_202[0][0]']                \n",
            " Normalization)                 64)                                                               \n",
            "                                                                                                  \n",
            " tf.nn.silu_167 (TFOpLambda)    (None, None, None,   0           ['group_normalization_203[0][0]']\n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)            (None, None, None,   8256        ['concatenate_41[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)            (None, None, None,   36928       ['tf.nn.silu_167[0][0]']         \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " add_203 (Add)                  (None, None, None,   0           ['conv2d_240[0][0]',             \n",
            "                                64)                               'conv2d_242[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, None, None,   260        ['add_203[0][0]']                \n",
            " spose)                         4)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 29,836,548\n",
            "Trainable params: 29,836,548\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = np.arange(t_epochs_nb)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(x_axis, history.history[\"i_loss\"], label=\"Training image CE loss\")\n",
        "plt.plot(x_axis, history.history[\"val_i_loss\"], label=\"Testing image CE loss\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efA4YUlX723d",
        "outputId": "93035be0-ca33-49b9-c8e0-1949b0baad99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6ewS3D0Y-"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm"
      ],
      "metadata": {
        "id": "PoJyZzMZqAIZ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def second_order_correction(\n",
        "    model,\n",
        "    diffusion_times,\n",
        "    step_size,\n",
        "    noisy_images,\n",
        "    signal_rates,\n",
        "    noise_rates,\n",
        "    pred_images,\n",
        "    pred_noises,\n",
        "    second_order_alpha,\n",
        "    mask,\n",
        "    pixels,\n",
        "):\n",
        "    # generic second-order Runge-Kutta method\n",
        "    # https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods#Generic_second-order_method\n",
        "    # based on https://arxiv.org/abs/2206.00364\n",
        "    #batch_size=noisy_images.shape[0]\n",
        "    #mask = tf.zeros((batch_size, image_size[0], image_size[1], 1))\n",
        "    #pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "\n",
        "    # use first estimate to sample alpha steps away\n",
        "    alpha_signal_rates, alpha_noise_rates = model.diffusion_schedule(\n",
        "        diffusion_times - second_order_alpha * step_size\n",
        "    )\n",
        "    alpha_noisy_images = (\n",
        "        alpha_signal_rates * pred_images + alpha_noise_rates * pred_noises\n",
        "    )\n",
        "    x_input = tf.math.multiply(noisy_images, tf.math.abs(mask - 1))\n",
        "    pred_x0, alpha_pred_noises = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "    int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "    embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "    # linearly combine the two noise estimates\n",
        "    pred_noises = (1.0 - 1.0 / (2.0 * second_order_alpha)) * pred_noises + 1.0 / (\n",
        "        2.0 * second_order_alpha\n",
        "        ) * alpha_pred_noises\n",
        "\n",
        "    pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "    return pred_images, pred_noises"
      ],
      "metadata": {
        "id": "SEJciKNQzCGs"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_beta(curr_alphas, prev_alphas):\n",
        "\n",
        "    betas = 1 - (prev_alphas / curr_alphas)\n",
        "    return betas"
      ],
      "metadata": {
        "id": "wVWp820FKVRV"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_sampler(model, img_embed_size, image_size, batch_size=10, num_steps=10, eps=1e-3, mask=None, pixels=None):\n",
        "    second_order_alpha = 1.1\n",
        "    # T and schedule\n",
        "    t_max = 1.0\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    if mask is None:\n",
        "        mask = tf.zeros((batch_size, image_size[0], image_size[1], 1), dtype=tf.float32)\n",
        "        pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size), dtype=tf.float32)\n",
        "    else:\n",
        "        \n",
        "        pixels = tf.argmax(pixels, axis=-1)\n",
        "        pixels = model.embedding_layer(pixels)\n",
        "        pixels = tf.math.multiply(pixels, mask)\n",
        "\n",
        "        mask = tf.repeat(mask, batch_size, axis=0)\n",
        "        mask = tf.cast(mask,  dtype=tf.float32)\n",
        "        pixels = tf.repeat(pixels, batch_size, axis=0)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, image_size[0], image_size[1]), 0, 4, dtype=tf.dtypes.int32)\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the chain\n",
        "    samples_list = []\n",
        "    samples_list.append( tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    time_steps = tf.linspace(1., eps, num_steps)\n",
        "    step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    prev_alphas = signal_rates**2\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for time_step in tqdm.tqdm(time_steps):\n",
        "        #print(time_step)\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        #print(batch_time_step)\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "        #print(noise_rates, signal_rates)\n",
        "        cur_alphas = signal_rates**2\n",
        "        betas = compute_beta(cur_alphas, prev_alphas)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        x_input = tf.math.multiply(x, tf.math.abs(mask - 1))\n",
        "        print(\"X, NR, SR \", x_input.shape, noise_rates.shape, signal_rates.shape, \" \\n\")\n",
        "        pred_x0, pred_noise = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        # optional second order sampling\n",
        "        if second_order_alpha is not None:\n",
        "            embed_pred_x0, pred_noises = second_order_correction(\n",
        "                model,\n",
        "                batch_time_step,\n",
        "                step_size,\n",
        "                x,\n",
        "                signal_rates,\n",
        "                noise_rates,\n",
        "                embed_pred_x0,\n",
        "                pred_noise,\n",
        "                second_order_alpha,\n",
        "                mask,\n",
        "                pixels,)\n",
        "\n",
        "        mean_x0 = tf.math.sqrt(cur_alphas) * betas / (1 - prev_alphas) * embed_pred_x0\n",
        "        mean_x = tf.math.sqrt(1 - betas) * (1 - cur_alphas) / (1 - prev_alphas) * x\n",
        "        x = mean_x + mean_x0 + tf.reshape(tf.math.sqrt(betas), (-1, 1, 1, 1)) * tf.random.normal(x.shape)\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        prev_alphas = cur_alphas\n",
        "\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "Krk0-qfIKNk1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_snr_list(nb_steps, model, eps):\n",
        "\n",
        "    start_noise_rates, start_signal_rates = model.diffusion_schedule(np.array([eps, ]))\n",
        "    start_snr = compute_snr(start_signal_rates, start_noise_rates)\n",
        "    end_noise_rates, end_signal_rates = model.diffusion_schedule(np.array([1., ]))\n",
        "    end_snr = compute_snr(end_signal_rates, end_noise_rates)\n",
        "    list_i = np.arange(0, nb_steps, 1.0, dtype=int)\n",
        "    all_snr = tf.cast(list_i / nb_steps * (start_snr - end_snr) + end_snr, dtype=tf.float32)\n",
        "    all_t = tf.cast(get_t_from_snr(all_snr), dtype=tf.float32)\n",
        "\n",
        "    return all_snr, all_t"
      ],
      "metadata": {
        "id": "MYg3ZH4rpjqp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_solver(model, img_embed_size, image_size, batch_size=10, num_steps=10, eps=1e-3, mask=None, pixels=None):\n",
        "    second_order_alpha = 1.1\n",
        "    # T and schedule\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    if mask is None:\n",
        "        mask = tf.zeros((batch_size, image_size[0], image_size[1], 1), dtype=tf.float32)\n",
        "        pixels = tf.zeros((batch_size, image_size[0], image_size[1], img_embed_size), dtype=tf.float32)\n",
        "    else:\n",
        "        \n",
        "        pixels = tf.argmax(pixels, axis=-1)\n",
        "        pixels = model.embedding_layer(pixels)\n",
        "        pixels = tf.math.multiply(pixels, mask)\n",
        "\n",
        "        mask = tf.repeat(mask, batch_size, axis=0)\n",
        "        mask = tf.cast(mask,  dtype=tf.float32)\n",
        "        pixels = tf.repeat(pixels, batch_size, axis=0)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, image_size[0], image_size[1]), 0, 4, dtype=tf.dtypes.int32)\n",
        "    # Pure white noise\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the Markov chain\n",
        "    samples_list = []\n",
        "    samples_list.append(tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    #time_steps = tf.linspace(1., eps, num_steps)\n",
        "    #step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    #prev_alphas = signal_rates**2\n",
        "    #prev_snr = compute_snr(signal_rates, noise_rates)\n",
        "    all_snr, time_steps = get_snr_list(num_steps, model, eps)\n",
        "    \n",
        "    prev_noise_rates, prev_signal_rates = noise_rates, signal_rates\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for i, time_step in enumerate(tqdm.tqdm(time_steps)):\n",
        "        prev_snr = all_snr[i]\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        print(\"TIMESTEP\", batch_time_step.shape)\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        x_input = tf.math.multiply(x, tf.math.abs(mask - 1))\n",
        "        pred_x0, pred_noise = model.denoise(x_input, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "        predicted_noise = x_input - embed_pred_x0\n",
        "\n",
        "        #snr = compute_snr(signal_rates, noise_rates)\n",
        "        snr = all_snr[i+1]\n",
        "\n",
        "        s_t = get_t_from_snr((snr + prev_snr) / 2)\n",
        "        s_t = tf.repeat(tf.reshape(s_t, (1, 1, 1, 1)), batch_size, axis=0)\n",
        "\n",
        "        print(s_t)\n",
        "\n",
        "        print(\"EST_TIMESTEP\", s_t.shape)\n",
        "\n",
        "        s_noise_rates, s_signal_rates = model.diffusion_schedule(s_t)\n",
        "        \n",
        "\n",
        "\n",
        "        u = s_signal_rates / prev_signal_rates * x - s_noise_rates * (tf.math.exp((snr - prev_snr) / 2) - 1) * predicted_noise\n",
        "\n",
        "        # PREDICT IMAGE 2\n",
        "        x_input = tf.math.multiply(u, tf.math.abs(mask - 1))\n",
        "        print(\"X, NR, SR \", x_input.shape, s_noise_rates.shape, s_signal_rates.shape, \" \\n\")\n",
        "        pred_x0, pred_noise = model.denoise(x_input, s_signal_rates, s_noise_rates, training=False, mask=mask, pixels=pixels)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "        predicted_noise = x_input - embed_pred_x0\n",
        "\n",
        "        x = signal_rates / prev_signal_rates * x - noise_rates * (tf.math.exp((snr - prev_snr)) - 1) * predicted_noise\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        #prev_alphas = cur_alphas\n",
        "        prev_snr = snr\n",
        "        prev_noise_rates, prev_signal_rates = noise_rates, signal_rates\n",
        "    pred_x0, pred_noise = model.denoise(x, noise_rates, signal_rates, training=False, mask=mask, pixels=pixels)\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "RBs0D0Ts6qNn"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_solver #@param ['ddpm_sampler', 'ddpm_solver'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (64, 128),\n",
        "                                sample_batch_size,\n",
        "                                mask=None,\n",
        "                                pixels=None)"
      ],
      "metadata": {
        "id": "T0uowLytML_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0d515f1-4275-4473-a8ea-e5725906af25"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]\n",
            "\n",
            "\n",
            " [[[0.9508901]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:04,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]\n",
            "\n",
            "\n",
            " [[[0.8442231]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:04,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]\n",
            "\n",
            "\n",
            " [[[0.72233325]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:01<00:03,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]\n",
            "\n",
            "\n",
            " [[[0.5775593]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:02<00:03,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]\n",
            "\n",
            "\n",
            " [[[0.401109]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:02<00:03,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]\n",
            "\n",
            "\n",
            " [[[0.2140945]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:03<00:02,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]\n",
            "\n",
            "\n",
            " [[[0.08819322]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:04<00:01,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]\n",
            "\n",
            "\n",
            " [[[0.03168644]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:04<00:01,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n",
            "tf.Tensor(\n",
            "[[[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]\n",
            "\n",
            "\n",
            " [[[0.00983758]]]], shape=(10, 1, 1, 1), dtype=float32)\n",
            "EST_TIMESTEP (10, 1, 1, 1)\n",
            "X, NR, SR  (10, 64, 128, 64) (10, 1, 1, 1) (10, 1, 1, 1)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:05<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTEP (10, 1, 1, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:05<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-f9558d7288cc>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m## Generate samples using the specified sampler.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m samples, samples_list = sampler(model,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                 \u001b[0mimg_embed_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-5a624bd02917>\u001b[0m in \u001b[0;36mddpm_solver\u001b[0;34m(model, img_embed_size, image_size, batch_size, num_steps, eps, mask, pixels)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#snr = compute_snr(signal_rates, noise_rates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_snr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_t_from_snr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprev_snr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7261\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7262\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 10 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(\"DEBUG\") "
      ],
      "metadata": {
        "id": "fJZxsZYbtlnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "O4GzBJX-MUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data.load_data import ConditionalDataGenerator\n",
        "\n",
        "# Load Data\n",
        "slice_size = (64, 128, 4)\n",
        "dataloader = ConditionalDataGenerator(x_test, 1, slice_size, wells=10, mode=3)\n",
        "pixels, mask, ground_truth = dataloader.__getitem__(0)\n",
        "print(pixels.shape, mask.shape, ground_truth.shape)"
      ],
      "metadata": {
        "id": "LAAAFTajBiUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler #@param ['ddpm_sampler', 'pc_sampler'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (64, 128),\n",
        "                                sample_batch_size,\n",
        "                                mask=mask,\n",
        "                                pixels=pixels)"
      ],
      "metadata": {
        "id": "iGnksfxx3JRB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QjbvDyWoK7fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from utils.visualisation import *\n",
        "from data.load_data import get_3d_flumy_data, load_data, ConditionalDataGenerator\n",
        "from models.load_trained_models import load_msgen_horizontal, wgan_horizontal,\\\n",
        "    load_msnwgen_2d_gs_horizontal, load_wgan_gs_horizontal, load_mswgen_sn_3d_horizontal\n",
        "from utils.utils import generate_noise, correct_percentage\n"
      ],
      "metadata": {
        "id": "pP5_ix6TCLdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_simulations = 3\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "\n",
        "print_conditioned_results(ground_truth, samples, mask, nb_simulations, cmap, norm)"
      ],
      "metadata": {
        "id": "0nla2sslCFTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.imshow(np.argmax(ground_truth, axis=-1).reshape((64, 128)),\n",
        "            interpolation='nearest', cmap=cmap, norm=norm)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "URj4sIq1BlYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler #@param ['ddpm_sampler', 'pc_sampler'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                (128, 256),\n",
        "                                sample_batch_size,)"
      ],
      "metadata": {
        "id": "gzMLizIXPUAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((128, 256)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p88yuQgCPUA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF"
      ],
      "metadata": {
        "id": "8X9v42ujwnt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "images = []\n",
        "for i, batch in enumerate(samples_list):\n",
        "    figure = plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Timestep {0:.3f}\".format(1 - (i / 350)))\n",
        "    plt.imshow(np.argmax(batch[0].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.savefig('foo.png', bbox_inches='tight')\n",
        "    images.append(imageio.imread('foo.png'))\n",
        "    plt.show() #close(figure)\n",
        "imageio.mimsave('/movie.gif', images)"
      ],
      "metadata": {
        "id": "m9JzX8pVMf7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Models"
      ],
      "metadata": {
        "id": "GCPKYflD2fyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SAVE_AND_TAR_RESULTS_WEIGHTS = True\n",
        "\n",
        "if SAVE_AND_TAR_RESULTS_WEIGHTS:\n",
        "  diffusion_checkpoint_path = \"diffusion_weights_horiz/cp-diffusion2d_net_horiz.ckpt\"\n",
        "  diffusion_checkpoint_dir = os.path.dirname(diffusion_checkpoint_path)\n",
        "\n",
        "  model.ema_network.save_weights(diffusion_checkpoint_path)\n",
        "\n",
        "  !tar -czvf diffusion_weights_horiz.tar.gz ./diffusion_weights_horiz\n",
        "\n",
        "  diffusion_checkpoint_path = \"diffusion_weights_horiz/cp-diffusion2d_embed_horiz.ckpt\"\n",
        "  diffusion_checkpoint_dir = os.path.dirname(diffusion_checkpoint_path)\n",
        "\n",
        "  model.embedding_layer.save_weights(diffusion_checkpoint_path)\n",
        "\n",
        "  !tar -czvf diffusion_weights_horiz.tar.gz ./diffusion_weights_horiz"
      ],
      "metadata": {
        "id": "gi9sVjP0QHdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddim",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}