{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/ddim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IDEAS \n",
        "1.   Normalization in embedding ?\n",
        "2.   Formula when I replace beta by t\n",
        "3.   Use keras inference for potential changes\n",
        "\n",
        "## What to try next?\n",
        "\n",
        "If you would like to dive in deeper to the topic, a recommend checking out\n",
        "[this repository](https://github.com/beresandras/clear-diffusion-keras) that I created in\n",
        "preparation for this code example, which implements a wider range of features in a\n",
        "similar style, such as:\n",
        "\n",
        "* stochastic sampling\n",
        "* second-order sampling based on the\n",
        "[differential equation view of DDIMs (Equation 13)](https://arxiv.org/abs/2010.02502)\n",
        "* more diffusion schedules\n",
        "* more network output types: predicting image or\n",
        "[velocity (Appendix D)](https://arxiv.org/abs/2202.00512) instead of noise\n",
        "* more datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rge41L-HIY-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkfNOJcD0Ym"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "    \n",
        "    %cd {REPO_DIR}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPH8VxsGGrb",
        "outputId": "db6a6215-9a5b-46e5-8d5e-c51c4ac78ca1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'flumy-wgan-mines'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 146 (delta 31), reused 74 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 140.19 MiB | 10.57 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (121/121), done.\n",
            "/content/flumy-wgan-mines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3E8qnnCGH5K",
        "outputId": "57080309-3164-40d6-ee4f-b83e935e9f4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VQcRg8KD0Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af72ca1-303e-40f0-bc88-285f5701b7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from data.load_data import load_data\n",
        "from utils.visualisation import get_color_map\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "1eF1rmySGCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful constants\n",
        "image_size = (64, 128)\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "facies_names = np.array([\"Sand, Channel lag\", \"Sand, Point bar\", \"Silts, Levee\", \"Shale, Overbank\"])\n",
        "x = load_data(image_size[0], image_size[1], \"./data/horizontal/dataFlumyHoriz.csv\")\n",
        "x_train = x[:2760]\n",
        "x_test = x[2760:]"
      ],
      "metadata": {
        "id": "4yPyDmhUGCTa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-ElzPrD0Yq"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FBoSc7iCD0Ys"
      },
      "outputs": [],
      "source": [
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "widths = [32, 64, 128, 256]\n",
        "block_depth = 2\n",
        "\n",
        "# Data values embedding\n",
        "img_embed_size = 64\n",
        "categories_nb = 4\n",
        "\n",
        "# optimization\n",
        "batch_size = 30\n",
        "ema = 0.999\n",
        "learning_rate = 1e-4\n",
        "embeding_net_lr = 1e-3\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diffusion Schedules"
      ],
      "metadata": {
        "id": "acL9rhHAdCCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DiffusionSchedule(ABC):\n",
        "    def __init__(self, start_log_snr, end_log_snr):\n",
        "        assert (\n",
        "            start_log_snr > end_log_snr\n",
        "        ), \"The starting SNR has to be higher than the final SNR.\"\n",
        "\n",
        "        self.start_snr = tf.exp(start_log_snr)\n",
        "        self.end_snr = tf.exp(end_log_snr)\n",
        "\n",
        "        self.start_noise_power = 1.0 / (1.0 + self.start_snr)\n",
        "        self.end_noise_power = 1.0 / (1.0 + self.end_snr)\n",
        "\n",
        "    def __call__(self, diffusion_times):\n",
        "        noise_powers = self.get_noise_powers(diffusion_times)\n",
        "\n",
        "        # the signal and noise power will always sum to one\n",
        "        signal_powers = 1.0 - noise_powers\n",
        "\n",
        "        # the rates are the square roots of the powers\n",
        "        # variance**0.5 -> standard deviation\n",
        "        signal_rates = signal_powers**0.5\n",
        "        noise_rates = noise_powers**0.5\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        pass\n",
        "\n",
        "\n",
        "class LinearSchedule(DiffusionSchedule):\n",
        "    # variance or power of noise component increases linearly\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.start_noise_power + diffusion_times * (\n",
        "            self.end_noise_power - self.start_noise_power\n",
        "        )\n",
        "\n",
        "\n",
        "class CosineSchedule(DiffusionSchedule):\n",
        "    # noise rate increases sinusoidally\n",
        "    # signal rate decreases as a cosine function\n",
        "    # simplified from the \"cosine schedule\" of Improved DDPM https://arxiv.org/abs/2102.09672\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        #start_angle = tf.asin(self.start_noise_power**0.5)\n",
        "        #end_angle = tf.asin(self.end_noise_power**0.5)\n",
        "        start_angle = tf.acos(max_signal_rate)\n",
        "        end_angle = tf.acos(min_signal_rate)\n",
        "        \n",
        "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "        return tf.sin(diffusion_angles) ** 2\n",
        "\n",
        "\n",
        "class LogSNRLinearSchedule(DiffusionSchedule):\n",
        "    # the log signal-to-noise ratio decreases linearly\n",
        "    # proposed in VDM https://arxiv.org/abs/2107.00630\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.start_snr**diffusion_times / (\n",
        "            self.start_snr * self.end_snr**diffusion_times\n",
        "            + self.start_snr**diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class LogNoiseLinearSchedule(DiffusionSchedule):\n",
        "    # the log noise power increases linearly\n",
        "    # the noise power increases exponentially\n",
        "    # the ratio between next-step and current noise powers is constant\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return (\n",
        "            self.start_noise_power\n",
        "            * (self.end_noise_power / self.start_noise_power) ** diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class LogSignalLinearSchedule(DiffusionSchedule):\n",
        "    # the log signal power decreases linearly\n",
        "    # the signal power decreases exponentially\n",
        "    # the ratio between next-step and current signal powers is constant\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return (\n",
        "            1.0\n",
        "            - (1.0 - self.start_noise_power)\n",
        "            * ((1.0 - self.end_noise_power) / (1.0 - self.start_noise_power))\n",
        "            ** diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class NoiseStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current noise powers decreases approximately linearly to 1\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.end_noise_power * (\n",
        "            self.start_noise_power / self.end_noise_power\n",
        "        ) ** ((1.0 - diffusion_times) ** 2)\n",
        "\n",
        "\n",
        "class SignalStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current signal powers decreases approximately linearly to 1\n",
        "    # similar to the \"linear schedule\" of DDPM https://arxiv.org/abs/2006.11239\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return 1.0 - (1.0 - self.start_noise_power) * (\n",
        "            (1.0 - self.end_noise_power) / (1.0 - self.start_noise_power)\n",
        "        ) ** (diffusion_times**2)"
      ],
      "metadata": {
        "id": "Z5U9ClBmdDxI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "QxyZaS_UJ_YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(tf.keras.layers.Layer):\n",
        "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights during initialization. These weights are fixed \n",
        "        # during optimization and are not trainable.\n",
        "        self.W = self.add_weight(shape=(embed_dim // 2,),\n",
        "                                 trainable=False,\n",
        "                                 initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.), name=\"GFP\") * tf.constant(scale, dtype=tf.float32)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        x_proj = x * self.W * tf.constant(2., dtype=tf.float32) * tf.constant(np.pi, dtype=tf.float32)\n",
        "        y = tf.concat([tf.math.sin(x_proj), tf.cos(x_proj)], axis=-1)\n",
        "        return y # Probleme vient pas de là :()\n",
        "\n",
        "class CustomLinear(tf.keras.layers.Layer):\n",
        "    \"\"\"Rhaaah.\"\"\"  \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.W = tf.random.uniform((input_dim, output_dim), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "        self.b = tf.random.uniform((1, output_dim, ), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = tf.tensordot(x, self.W, 1) + self.b\n",
        "        y = tf.keras.activations.gelu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "@tf.function\n",
        "def embedding_normalization(logits):\n",
        "    # normalement vont avoir taille (batch_size, sequence_size, embedding_size)\n",
        "    # axis=-1 is embedding normalement\n",
        "    return (logits / tf.norm(logits, axis=-1, keepdims=True)) * tf.constant(np.sqrt(logits.shape[-1]), dtype=tf.float32)\n",
        "\n",
        "class NormalizedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\"\"\"  \n",
        "    def __init__(self, categories_nb, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.embed_layer = tf.keras.layers.Embedding(categories_nb, img_embed_size)\n",
        "        self.embed_layer2 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer3 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer4 = layers.Conv2D(img_embed_size, kernel_size=1, activation=None)\n",
        "        self.layer_norm = layer = tf.keras.layers.LayerNormalization(axis=[1, 2])\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = self.embed_layer(x)\n",
        "        y = self.embed_layer2(y)\n",
        "        y = self.embed_layer3(y)\n",
        "        y = self.embed_layer4(y)\n",
        "        y = embedding_normalization(y)\n",
        "        y = self.layer_norm(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "Ej4nARwoGmme"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7V5eQBuUD0Y0"
      },
      "outputs": [],
      "source": [
        "def sinusoidal_embedding(x):\n",
        "    embedding_min_frequency = 1.0\n",
        "    frequencies = tf.exp(\n",
        "        tf.linspace(\n",
        "            tf.math.log(embedding_min_frequency),\n",
        "            tf.math.log(embedding_max_frequency),\n",
        "            embedding_dims // 2,\n",
        "        )\n",
        "    )\n",
        "    angular_speeds = 2.0 * math.pi * frequencies\n",
        "    embeddings = tf.concat(\n",
        "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
        "    )\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3]\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
        "        x = layers.Conv2D(\n",
        "            width, kernel_size=3, padding=\"same\", activation=keras.activations.swish\n",
        "        )(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def DownBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        for _ in range(block_depth):\n",
        "            x = ResidualBlock(width)(x)\n",
        "            skips.append(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def UpBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "        for _ in range(block_depth):\n",
        "            x = layers.Concatenate()([x, skips.pop()])\n",
        "            x = ResidualBlock(width)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def get_network(image_size, widths, block_depth, embed_size):\n",
        "    noisy_images = keras.Input(shape=(image_size[0], image_size[1], embed_size))\n",
        "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "    e = layers.UpSampling2D(size=image_size, interpolation=\"nearest\")(e)\n",
        "\n",
        "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
        "    x = layers.Concatenate()([x, e])\n",
        "\n",
        "    skips = []\n",
        "    for width in widths[:-1]:\n",
        "        x = DownBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1])(x)\n",
        "\n",
        "    for width in reversed(widths[:-1]):\n",
        "        x = UpBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    x = layers.Conv2D(4, kernel_size=1, kernel_initializer=\"zeros\", activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network(\n",
        "    image_size,\n",
        "    noise_embedding_max_frequency,\n",
        "    noise_embedding_dims,\n",
        "    image_embedding_dims,\n",
        "    block_depth,\n",
        "    widths,\n",
        "    attentions,\n",
        "    patch_size,\n",
        "    embed_size\n",
        "):\n",
        "    def EmbeddingLayer(embedding_max_frequency, embedding_dims):\n",
        "        def sinusoidal_embedding(x):\n",
        "            embedding_min_frequency = 1.0\n",
        "            frequencies = tf.exp(\n",
        "                tf.linspace(\n",
        "                    tf.math.log(embedding_min_frequency),\n",
        "                    tf.math.log(embedding_max_frequency),\n",
        "                    embedding_dims // 2,\n",
        "                )\n",
        "            )\n",
        "            angular_speeds = 2.0 * math.pi * frequencies\n",
        "            embeddings = tf.concat(\n",
        "                [\n",
        "                    tf.sin(angular_speeds * x),\n",
        "                    tf.cos(angular_speeds * x),\n",
        "                ],\n",
        "                axis=3,\n",
        "            )\n",
        "            return embeddings\n",
        "\n",
        "        def forward(x):\n",
        "            x = layers.Lambda(sinusoidal_embedding)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def ResidualBlock(width, attention):\n",
        "        def forward(x):\n",
        "            x, n = x\n",
        "            input_width = x.shape[3]\n",
        "            if input_width == width:\n",
        "                residual = x\n",
        "            else:\n",
        "                residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "\n",
        "            n = layers.Dense(width)(n)\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([x, n])\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([residual, x])\n",
        "\n",
        "            if attention:\n",
        "                residual = x\n",
        "                x = tfa.layers.GroupNormalization(groups=8, center=False, scale=False)(\n",
        "                    x\n",
        "                )\n",
        "                x = layers.MultiHeadAttention(\n",
        "                    num_heads=4, key_dim=width, attention_axes=(1, 2)\n",
        "                )(x, x)\n",
        "\n",
        "                x = layers.Add()([residual, x])\n",
        "\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def DownBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            for _ in range(block_depth):\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "                skips.append(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def UpBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "            for _ in range(block_depth):\n",
        "                x = layers.Concatenate()([x, skips.pop()])\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    images = keras.Input(shape=(image_size[0], image_size[1], embed_size))\n",
        "    noise_powers = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    x = layers.Conv2D(image_embedding_dims, kernel_size=patch_size, strides=patch_size)(\n",
        "        images\n",
        "    )\n",
        "\n",
        "    n = EmbeddingLayer(noise_embedding_max_frequency, noise_embedding_dims)(\n",
        "        noise_powers\n",
        "    )\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "\n",
        "    skips = []\n",
        "    for width, attention in zip(widths[:-1], attentions[:-1]):\n",
        "        x = DownBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1], attentions[-1])([x, n])\n",
        "\n",
        "    for width, attention in zip(widths[-2::-1], attentions[-2::-1]):\n",
        "        x = UpBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    x = layers.Conv2DTranspose(\n",
        "        4, kernel_size=patch_size, strides=patch_size, kernel_initializer=\"zeros\", activation=\"softmax\"\n",
        "    )(x)\n",
        "\n",
        "    return keras.Model([images, noise_powers], x, name=\"residual_unet\")"
      ],
      "metadata": {
        "id": "IgeH9voVvsN5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling\n"
      ],
      "metadata": {
        "id": "XEMZlA-xdLcT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lZ37576YD0Y5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth, img_embed_size,\n",
        "                 categories_nb, embedding_lr=1e-3, batch_size=30,\n",
        "                 large_model=False):\n",
        "        super().__init__()\n",
        "\n",
        "        noise_embedding_max_frequency = 1000.0\n",
        "        noise_embedding_dims = 64\n",
        "        image_embedding_dims = 64\n",
        "        block_depth = 2\n",
        "\n",
        "        if large_model:\n",
        "            widths = [64, 128, 256, 512]\n",
        "            attentions = [False, False, True, True]\n",
        "        else:\n",
        "            widths = [64, 96, 128, 256]\n",
        "            attentions = [False, False, False, False]\n",
        "            \n",
        "        patch_size = 1\n",
        "\n",
        "        self.diffusion_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        #self.diffusion_schedule = CosineSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        self.network = get_network(image_size, noise_embedding_max_frequency,\n",
        "                                   noise_embedding_dims, image_embedding_dims,\n",
        "                                   block_depth, widths, attentions, patch_size,\n",
        "                                   img_embed_size)\n",
        "        \n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Embedding\n",
        "        self.img_embed_size = img_embed_size\n",
        "        self.embedding_layer = NormalizedEmbedding(categories_nb, img_embed_size)\n",
        "        self.emb_optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=embedding_lr)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.image_loss_tracker]\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
        "        # the exponential moving average weights are used at evaluation\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        # predict noise component and calculate the image component using it\n",
        "        pred_images = network([noisy_images, noise_rates**2], training=training)\n",
        "\n",
        "        \n",
        "        int_encoded_img = tf.argmax(pred_images, axis=-1)\n",
        "        embed_pred_images = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        pred_noises = (noisy_images - signal_rates * embed_pred_images) / noise_rates\n",
        "\n",
        "        return pred_images, pred_noises\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            embed_images = self.embedding_layer(int_encoded_img)\n",
        "            noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_images, pred_noise = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True\n",
        "            )\n",
        "\n",
        "            image_loss = self.loss(images, pred_images)  # training loss\n",
        "            \n",
        "\n",
        "        gradients_model = tape1.gradient(image_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.network.trainable_weights))\n",
        "\n",
        "        gradients_embeddings = tape2.gradient(image_loss, self.embedding_layer.trainable_weights)\n",
        "        self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        # KID is not measured during the training phase for computational efficiency\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        embed_images = self.embedding_layer(int_encoded_img)\n",
        "\n",
        "        #std = marginal_prob_std(diffusion_times, sigma=sigma)\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "        #noisy_images = embed_images + noises * tf.reshape(std, (-1, 1, 1, 1))\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_images, pred_noise = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False\n",
        "        )\n",
        "\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYrG2VPD0Y7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LHcHZit9D0Y8"
      },
      "outputs": [],
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth, img_embed_size=img_embed_size, categories_nb=categories_nb, large_model=True)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, batch_size=batch_size, epochs=100, validation_data=(x_test,))"
      ],
      "metadata": {
        "id": "RDSktS3wIy4C",
        "outputId": "bc492f1e-b70a-4c33-96a8-cca49d0ad971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 179s 1s/step - i_loss: 0.5834 - val_i_loss: 1.3853\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.2991 - val_i_loss: 1.3823\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.2205 - val_i_loss: 1.3770\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1892 - val_i_loss: 1.3679\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1882 - val_i_loss: 1.3493\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1710 - val_i_loss: 1.3265\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1571 - val_i_loss: 1.2750\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1573 - val_i_loss: 1.2188\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1539 - val_i_loss: 1.1488\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1470 - val_i_loss: 1.0686\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1389 - val_i_loss: 0.9495\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1450 - val_i_loss: 0.8602\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1358 - val_i_loss: 0.7596\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1279 - val_i_loss: 0.6789\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1262 - val_i_loss: 0.5755\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1165 - val_i_loss: 0.4948\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1185 - val_i_loss: 0.4289\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1151 - val_i_loss: 0.3448\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1164 - val_i_loss: 0.3260\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1176 - val_i_loss: 0.2799\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1100 - val_i_loss: 0.2472\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1108 - val_i_loss: 0.1663\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1101 - val_i_loss: 0.1684\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1087 - val_i_loss: 0.1662\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.1113 - val_i_loss: 0.1631\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1023 - val_i_loss: 0.1342\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1006 - val_i_loss: 0.1271\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0950 - val_i_loss: 0.1015\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1004 - val_i_loss: 0.1291\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0981 - val_i_loss: 0.1116\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0915 - val_i_loss: 0.0939\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0910 - val_i_loss: 0.0961\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0942 - val_i_loss: 0.1137\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0849 - val_i_loss: 0.0716\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0850 - val_i_loss: 0.0986\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0934 - val_i_loss: 0.0941\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0875 - val_i_loss: 0.0938\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0809 - val_i_loss: 0.0894\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0857 - val_i_loss: 0.0812\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0878 - val_i_loss: 0.0860\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0764 - val_i_loss: 0.0840\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0833 - val_i_loss: 0.0791\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0789 - val_i_loss: 0.0744\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0789 - val_i_loss: 0.0797\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0758 - val_i_loss: 0.0726\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0781 - val_i_loss: 0.0772\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0747 - val_i_loss: 0.0896\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0724 - val_i_loss: 0.0635\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0722 - val_i_loss: 0.0788\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0715 - val_i_loss: 0.0690\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0688 - val_i_loss: 0.0731\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0766 - val_i_loss: 0.0698\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0695 - val_i_loss: 0.0705\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0706 - val_i_loss: 0.0747\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0691 - val_i_loss: 0.0680\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0687 - val_i_loss: 0.0716\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0624 - val_i_loss: 0.0611\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0664 - val_i_loss: 0.0685\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0632 - val_i_loss: 0.0626\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0641 - val_i_loss: 0.0491\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0621 - val_i_loss: 0.0682\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0598 - val_i_loss: 0.0513\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0607 - val_i_loss: 0.0632\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0594 - val_i_loss: 0.0513\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0582 - val_i_loss: 0.0636\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0575 - val_i_loss: 0.0509\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0546 - val_i_loss: 0.0501\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0580 - val_i_loss: 0.0569\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0610 - val_i_loss: 0.0557\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0491 - val_i_loss: 0.0555\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0601 - val_i_loss: 0.0460\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0574 - val_i_loss: 0.0347\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0571 - val_i_loss: 0.0523\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0540 - val_i_loss: 0.0484\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0561 - val_i_loss: 0.0617\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0522 - val_i_loss: 0.0637\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0542 - val_i_loss: 0.0454\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0517 - val_i_loss: 0.0531\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0556 - val_i_loss: 0.0527\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0490 - val_i_loss: 0.0599\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0526 - val_i_loss: 0.0460\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0464 - val_i_loss: 0.0428\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0495 - val_i_loss: 0.0485\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0505 - val_i_loss: 0.0373\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0539 - val_i_loss: 0.0531\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0468 - val_i_loss: 0.0453\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0446 - val_i_loss: 0.0476\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0447 - val_i_loss: 0.0411\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0469 - val_i_loss: 0.0435\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0419 - val_i_loss: 0.0423\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0407 - val_i_loss: 0.0463\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0449 - val_i_loss: 0.0516\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0446 - val_i_loss: 0.0343\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0430 - val_i_loss: 0.0292\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0421 - val_i_loss: 0.0468\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.0410 - val_i_loss: 0.0500\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0447 - val_i_loss: 0.0278\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0404 - val_i_loss: 0.0440\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0408 - val_i_loss: 0.0338\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 117s 1s/step - i_loss: 0.0378 - val_i_loss: 0.0392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6ewS3D0Y-"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def second_order_correction(\n",
        "    model,\n",
        "    diffusion_times,\n",
        "    step_size,\n",
        "    noisy_images,\n",
        "    signal_rates,\n",
        "    noise_rates,\n",
        "    pred_images,\n",
        "    pred_noises,\n",
        "    second_order_alpha,\n",
        "):\n",
        "    # generic second-order Runge-Kutta method\n",
        "    # https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods#Generic_second-order_method\n",
        "    # based on https://arxiv.org/abs/2206.00364\n",
        "\n",
        "    # use first estimate to sample alpha steps away\n",
        "    alpha_signal_rates, alpha_noise_rates = model.diffusion_schedule(\n",
        "        diffusion_times - second_order_alpha * step_size\n",
        "    )\n",
        "    alpha_noisy_images = (\n",
        "        alpha_signal_rates * pred_images + alpha_noise_rates * pred_noises\n",
        "    )\n",
        "    pred_x0, alpha_pred_noises = model.denoise(noisy_images, noise_rates, signal_rates, training=False)\n",
        "    int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "    embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "    # linearly combine the two noise estimates\n",
        "    pred_noises = (1.0 - 1.0 / (2.0 * second_order_alpha)) * pred_noises + 1.0 / (\n",
        "        2.0 * second_order_alpha\n",
        "        ) * alpha_pred_noises\n",
        "\n",
        "    pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "    return pred_images, pred_noises"
      ],
      "metadata": {
        "id": "SEJciKNQzCGs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "def compute_beta(curr_alphas, prev_alphas):\n",
        "\n",
        "    betas = 1 - (prev_alphas / curr_alphas)\n",
        "    return betas"
      ],
      "metadata": {
        "id": "wVWp820FKVRV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_sampler(model, img_embed_size, batch_size=10, num_steps=350, eps=1e-3):\n",
        "    second_order_alpha = 1.1\n",
        "    # T and schedule\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, 64, 128), 0, 4, dtype=tf.dtypes.int32)\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the chain\n",
        "    samples_list = []\n",
        "    samples_list.append( tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    time_steps = tf.linspace(1., eps, num_steps)\n",
        "    step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    prev_alphas = signal_rates**2\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for time_step in tqdm.tqdm(time_steps):\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "        cur_alphas = signal_rates**2\n",
        "        betas = compute_beta(cur_alphas, prev_alphas)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        pred_x0, pred_noise = model.denoise(x, noise_rates, signal_rates, training=False)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "\n",
        "        # optional second order sampling\n",
        "        if second_order_alpha is not None:\n",
        "            embed_pred_x0, pred_noises = second_order_correction(\n",
        "                model,\n",
        "                batch_time_step,\n",
        "                step_size,\n",
        "                x,\n",
        "                signal_rates,\n",
        "                noise_rates,\n",
        "                embed_pred_x0,\n",
        "                pred_noise,\n",
        "                second_order_alpha,)\n",
        "\n",
        "        mean_x0 = tf.math.sqrt(cur_alphas) * betas / (1 - prev_alphas) * embed_pred_x0\n",
        "        mean_x = tf.math.sqrt(1 - betas) * (1 - cur_alphas) / (1 - prev_alphas) * x\n",
        "        x = mean_x + mean_x0 + tf.reshape(tf.math.sqrt(betas), (-1, 1, 1, 1)) * tf.random.normal(x.shape)\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        prev_alphas = cur_alphas\n",
        "\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "Krk0-qfIKNk1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler #@param ['ddpm_sampler', 'pc_sampler'] {'type': 'raw'}\n",
        "\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                sample_batch_size,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0uowLytML_4",
        "outputId": "24d7e8e2-b05a-4551-c717-98ec1112fc2d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [02:58<00:00,  1.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4GzBJX-MUmk",
        "outputId": "f2335676-2fe8-492d-f856-20ca427bd41f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGVCAYAAABjBWf4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAN2UlEQVR4nO3c3W3b2AKFUfvCHYVdpI7glnExdaSOdKHUxHkwLiYPoobH+/ySaz0KSixT1M8Hwvt93/f9DQAAIPCf0Q8AAABYn7AAAABiwgIAAIgJCwAAICYsAACAmLAAAABiwgIAAIgJCwAAICYsAACA2MfZOz4eW8vHARzYfv1+evvj+7fOjwSgD+976/GcXdu2PU7dzxULAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAg9r7v+37mjlahoK1aixpH/8+RWosdFkHmVPq8eB6BHko/q0p5z6rLKhQAANCNsAAAAGLCAgAAiAkLAAAgJiwAAICYVSj4Q81FnFHrTADMy/IaZ8x2nliFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKBaFRyw2zLUYAtFa6tlfK+yc8ZxUKAADoRlgAAAAxYQEAAMSEBQAAEBMWAABAzCoUNGK16dNsKy6eF5iH1yOswSoUAADQjbAAAABiwgIAAIgJCwAAICYsAACA2PSrUBYjmF2tc7R0Pclr4LXS52XU8fceB/NrvW739tb+PaXWz+1xLJ7xnjiWVSgAAKAbYQEAAMSEBQAAEBMWAABATFgAAACx6Veh4IzWy0zWKIA7mm1h6I7vxY7Rp9ZrVFc9brVYhQIAALoRFgAAQExYAAAAMWEBAADEhAUAABCzCsVSWq8/HbEWAVyB5bv7+lnp//kx6P+vxef/11iFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKxS1ZRgGAemtOqyhdnWq9RrnK9w6rUAAAQDfCAgAAiAkLAAAgJiwAAICYsAAAAGJWoRZRuiaw+vpALY4DwHqOlopKF32o724rUkfudi5ahQIAALoRFgAAQExYAAAAMWEBAADEhAUAABBbdhXK2g9/Gnk+lC5klC5J1FrguNuCxZHWiyaO8zVY4qtr1JKQ12M/1qI+XfWcswoFAAB0IywAAICYsAAAAGLCAgAAiAkLAAAgtuwqVC2WPOZ09LwcWen5cs69Zlnka46WSJxvY5W+l5UqfR6v+voqXeLxuhjvqudiqVVWpKxCAQAA3QgLAAAgJiwAAICYsAAAAGLCAgAAiN1+Fao1yxN11VqLqrk65Tnuw4JIH6sslNQy2+v36DwvfV5qvV6uej7M9rzz7676GbDKa8wqFAAA0I2wAAAAYsICAACICQsAACAmLAAAgJhVKL6kdFWpFosd93XVRZBVrLJcAtSx+nLWbJ8Zq7+HWoUCAAC6ERYAAEBMWAAAADFhAQAAxIQFAAAQswrFS6uvQnB9sy1/tFa6LDLq+Ky+gAIw0mzfv6xCAQAA3QgLAAAgJiwAAICYsAAAAGLCAgAAiFmFAm5ltqUNAP7hPfq1UcfHKhQAANCNsAAAAGLCAgAAiAkLAAAgJiwAAICYVaibOVoTOGKFAajJ4gvAP4atPBX+XKtQAABAN8ICAACICQsAACAmLAAAgJiwAAAAYlahADqwyMadOf+ZXek5Wmr1c9oqFAAA0I2wAAAAYsICAACICQsAACAmLAAAgJhVKJjE0SLF0ZJE6f15zfEEgOesQgEAAN0ICwAAICYsAACAmLAAAABiwgIAAIhZhQIuycoTd3C38/zo9z1y1eMAvVmFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKBfBC6QrNkaN1mlGrPndbE4LZeU0yM6tQAABAN8ICAACICQsAACAmLAAAgJiwAAAAYlahAPiy0iWb0pUtizgA41mFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKBQAAHLIKBQAAdCMsAACAmLAAAABiwgIAAIgJCwAAIPYx+gEAALCG7dfvp7c/vn/r/EiYkSsWAABATFgAAAAxYQEAAMSEBQAAEBMWAABAzCoUAJdnyQbq8JrhFVcsAACAmLAAAABiwgIAAIgJCwAAICYsAACAmFUouJij9Zsjqyx81Fr1sQ50T84TgPZcsQAAAGLCAgAAiAkLAAAgJiwAAICYsAAAAGLv+77vZ+74eGytHwssyXoMsMoam/er+1rluV/lcd7Ntj1O3c8VCwAAICYsAACAmLAAAABiwgIAAIgJCwAAIGYVCnjKMge0U7oidaTW69Hrnd6cc2uxCgUAAHQjLAAAgJiwAAAAYsICAACICQsAACBmFQo6G7WEcdUFjqv+XgBfsfp74uqP/6qsQgEAAN0ICwAAICYsAACAmLAAAABiwgIAAIhZhQKARizcMDvnKGdYhQIAALoRFgAAQExYAAAAMWEBAADEhAUAABCzCgUAFJltSWi2x3MFjil/sgoFAAB0IywAAICYsAAAAGLCAgAAiAkLAAAgZhUKAAA4ZBUKAADoRlgAAAAxYQEAAMSEBQAAEBMWAABA7GP0AwAA+NP26/fT2x/fv3V+JEAJVywAAICYsAAAAGLCAgAAiAkLAAAgJiwAAICYsAAAAGLmZgGAqZiVhTGOpp7ftnP/3hULAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgZhVqEYd/pV/I0gYAwLXU+p6YcsUCAACICQsAACAmLAAAgJiwAAAAYsICAACIWYVq7Oiv9EvXmaw5AQDMYZYVptm4YgEAAMSEBQAAEBMWAABATFgAAAAxYQEAAMSsQlVSa/0JAOCuRn2fWn3lqfnxOXk/VywAAICYsAAAAGLCAgAAiAkLAAAgJiwAAIDY7Vehaq0AWH8CAMissv7ke99zrlgAAAAxYQEAAMSEBQAAEBMWAABATFgAAACx269CHfHX/gDA21u9JaGv8H3ktdLnxvFsyxULAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgtuwq1NEKwNFf+5fev/XjAQDW4LO8n5ELXM9YnSrjigUAABATFgAAQExYAAAAMWEBAADEhAUAABBbdhXqSK01gdKVp7utAFjBAgD+b7b1pFr/v+81ZVyxAAAAYsICAACICQsAACAmLAAAgJiwAAAAYu/7vu9n7vh4bE0fSK01J3+9P9ZsqxAAQLla38tq8X1hrG17nLqfKxYAAEBMWAAAADFhAQAAxIQFAAAQExYAAEDso/cPPFoZOPpr/9lWCXit1mpD6XkCPOe1BLy9tf8+5T2lj9nf012xAAAAYsICAACICQsAACAmLAAAgJiwAAAAYu/7vu9n7vh4bE9vb73yNMtfudNGrfPHeQLAnYxazVz987b199Crfk/Ztsep+7liAQAAxIQFAAAQExYAAEBMWAAAADFhAQAAxE6vQr399f70ZutPnFFrJaHWeXXV1QYA+hq1zlTK5xsJq1AAAEA3wgIAAIgJCwAAICYsAACAmLAAAABip1ehHo/t6e3WdZhZ6fn5lXUP5zrAtY1cfvIZc0+zfb+2CgUAAHQjLAAAgJiwAAAAYsICAACICQsAACAWr0LBiqxFAVxHj/f0Wnw2rKXWuVL6vP88uP1H/lC+xCoUAADQjbAAAABiwgIAAIgJCwAAICYsAACA2OlVqLe/3p/ebN2Auxu1GAHAa96fuZrSBbRqP9cqFAAA0IuwAAAAYsICAACICQsAACAmLAAAgNjpVajHY2v9WOAWVl8pGbVIMZtaz+ORux1POKP0ded1NC+fJWuxCgUAAHQjLAAAgJiwAAAAYsICAACICQsAACBmFQomt8r6UOuFj9bHodQqv5eFFVa0+noe9Nb8M9gqFAAA0IuwAAAAYsICAACICQsAACAmLAAAgJhVKG6p5npC6yWG1j+3dH2l9f9fatRxbm3U6tTRz51tleuIFaCxrDnBNVmFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKBZ2NWk1pvSLVesXISsynVdaZ+LT6ebv6+xXwXOlrzCoUAADQjbAAAABiwgIAAIgJCwAAICYsAACAmFUouDnrK2M5/nVZzRrLeXsdoxbBmJNVKAAAoBthAQAAxIQFAAAQExYAAEBMWAAAADGrUEBTpcsiqyyIXPX3GuWq61ijlnWcn9zdVd9TRrEKBQAAdCMsAACAmLAAAABiwgIAAIgJCwAAIGYVikuzCrGe1ms2o1Z6AGBVVqEAAIBuhAUAABATFgAAQExYAAAAMWEBAADErEIBl2QRDODfea98zfH5ZBUKAADoRlgAAAAxYQEAAMSEBQAAEBMWAABAzCoUAFzM0ZJNa/89WMr50flx0E7pSlKt+4/Sev1pldUpq1AAAEA3wgIAAIgJCwAAICYsAACAmLAAAABiVqEAFlK6mDLbsgj39PPg9tZrUass7lyBY/3a6sfHKhQAANCNsAAAAGLCAgAAiAkLAAAgJiwAAICYVSiACytdkZrNKospACsp/mz436lccMUCAADICQsAACAmLAAAgJiwAAAAYsICAACIWYUCYDlHiyZWpADq27bHqfu5YgEAAMSEBQAAEBMWAABATFgAAAAxYQEAAMQ+Rj8AAChl/QlgPq5YAAAAMWEBAADEhAUAABATFgAAQExYAAAAMWEBAADEhAUAABATFgAAQExYAAAAMWEBAADEhAUAABD7GP0AAJjH9uv309sf3791fiRATV7b9OCKBQAAEBMWAABATFgAAAAxYQEAAMSEBQAAEItXoawMAKxnlffuVR5na45DXXc8nlf+3e5k9nPXFQsAACAmLAAAgJiwAAAAYsICAACICQsAACD2vu/7PvpBAAAAa3PFAgAAiAkLAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgJiwAAICYsAAAAGLCAgAAiP0NuRYnB5sU2QoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPQ7NDoqwnPT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmxTCPcGwnR-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRU4hxdwwnVE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27KyMR50wnX8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JOV1lK-wnbK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ihlTCKtwneG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise TypeError(\"NAN MAIS VOUS VOUS RENDEZ COMPTE A QUELLE ALLURE VOUS ALLIEZ MONSIEUR ?\") "
      ],
      "metadata": {
        "id": "A-BmWGiFwnjx",
        "outputId": "6f12f38d-a45c-474b-980e-0ab958665306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e8672594a1e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NAN MAIS VOUS VOUS RENDEZ COMPTE A QUELLE ALLURE VOUS ALLIEZ MONSIEUR ?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: NAN MAIS VOUS VOUS RENDEZ COMPTE A QUELLE ALLURE VOUS ALLIEZ MONSIEUR ?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF"
      ],
      "metadata": {
        "id": "8X9v42ujwnt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "images = []\n",
        "for i, batch in enumerate(samples_list):\n",
        "    figure = plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Timestep {0:.3f}\".format(1 - (i / 350)))\n",
        "    plt.imshow(np.argmax(batch[0].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.savefig('foo.png', bbox_inches='tight')\n",
        "    images.append(imageio.imread('foo.png'))\n",
        "    plt.show() #close(figure)\n",
        "imageio.mimsave('/movie.gif', images)"
      ],
      "metadata": {
        "id": "m9JzX8pVMf7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddim",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}