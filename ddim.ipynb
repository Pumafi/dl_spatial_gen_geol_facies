{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pumafi/dl_spatial_gen_geol_facies/blob/main/ddim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IDEAS \n",
        "1.   Normalization in embedding ?\n",
        "2.   Formula when I replace beta by t\n",
        "3.   Use keras inference for potential changes\n",
        "\n",
        "## What to try next?\n",
        "\n",
        "If you would like to dive in deeper to the topic, a recommend checking out\n",
        "[this repository](https://github.com/beresandras/clear-diffusion-keras) that I created in\n",
        "preparation for this code example, which implements a wider range of features in a\n",
        "similar style, such as:\n",
        "\n",
        "* stochastic sampling\n",
        "* second-order sampling based on the\n",
        "[differential equation view of DDIMs (Equation 13)](https://arxiv.org/abs/2010.02502)\n",
        "* more diffusion schedules\n",
        "* more network output types: predicting image or\n",
        "[velocity (Appendix D)](https://arxiv.org/abs/2202.00512) instead of noise\n",
        "* more datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "rge41L-HIY-i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkfNOJcD0Ym"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RUNNING_IN_COLAB = True\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # Uses a private Auth Token, giving read and write access to repo\n",
        "    # TO DELETE IF REPO GOES PUBLIC\n",
        "    REPO_URL = 'https://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@github.com/Pumafi/flumy-wgan-mines'\n",
        "    BRANCH   = 'main'\n",
        "    REPO_DIR = 'flumy-wgan-mines'\n",
        "\n",
        "    from pathlib import Path\n",
        "\n",
        "    %cd /content\n",
        "\n",
        "    if Path(REPO_DIR).is_dir():\n",
        "      !rm -rf {REPO_DIR}\n",
        "\n",
        "    # Download the repository\n",
        "    if not Path(REPO_DIR).is_dir():\n",
        "        !git clone --branch {BRANCH} --depth=1 -- {REPO_URL} {REPO_DIR}\n",
        "    \n",
        "    %cd {REPO_DIR}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPH8VxsGGrb",
        "outputId": "630d1189-2516-4dde-ae32-87b1cae638b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'flumy-wgan-mines'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 146 (delta 31), reused 74 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 140.19 MiB | 10.28 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Updating files: 100% (121/121), done.\n",
            "/content/flumy-wgan-mines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3E8qnnCGH5K",
        "outputId": "ce21735c-4e26-4012-cccf-000d8695e7f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VQcRg8KD0Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3d53f6-f1e7-4659-bd9c-47363e4977b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from data.load_data import load_data\n",
        "from utils.visualisation import get_color_map\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "1eF1rmySGCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful constants\n",
        "image_size = (64, 128)\n",
        "cmap, norm = get_color_map(number_of_categories=4)\n",
        "facies_names = np.array([\"Sand, Channel lag\", \"Sand, Point bar\", \"Silts, Levee\", \"Shale, Overbank\"])\n",
        "x = load_data(image_size[0], image_size[1], \"./data/horizontal/dataFlumyHoriz.csv\")\n",
        "x_train = x[:2760]\n",
        "x_test = x[2760:]"
      ],
      "metadata": {
        "id": "4yPyDmhUGCTa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-ElzPrD0Yq"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FBoSc7iCD0Ys"
      },
      "outputs": [],
      "source": [
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "widths = [32, 64, 128, 256]\n",
        "block_depth = 2\n",
        "\n",
        "# Data values embedding\n",
        "img_embed_size = 16\n",
        "categories_nb = 4\n",
        "\n",
        "# optimization\n",
        "batch_size = 30\n",
        "ema = 0.999\n",
        "learning_rate = 1e-4\n",
        "embeding_net_lr = 1e-3\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diffusion Schedules"
      ],
      "metadata": {
        "id": "acL9rhHAdCCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class DiffusionSchedule(ABC):\n",
        "    def __init__(self, start_log_snr, end_log_snr):\n",
        "        assert (\n",
        "            start_log_snr > end_log_snr\n",
        "        ), \"The starting SNR has to be higher than the final SNR.\"\n",
        "\n",
        "        self.start_snr = tf.exp(start_log_snr)\n",
        "        self.end_snr = tf.exp(end_log_snr)\n",
        "\n",
        "        self.start_noise_power = 1.0 / (1.0 + self.start_snr)\n",
        "        self.end_noise_power = 1.0 / (1.0 + self.end_snr)\n",
        "\n",
        "    def __call__(self, diffusion_times):\n",
        "        noise_powers = self.get_noise_powers(diffusion_times)\n",
        "\n",
        "        # the signal and noise power will always sum to one\n",
        "        signal_powers = 1.0 - noise_powers\n",
        "\n",
        "        # the rates are the square roots of the powers\n",
        "        # variance**0.5 -> standard deviation\n",
        "        signal_rates = signal_powers**0.5\n",
        "        noise_rates = noise_powers**0.5\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        pass\n",
        "\n",
        "\n",
        "class LinearSchedule(DiffusionSchedule):\n",
        "    # variance or power of noise component increases linearly\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.start_noise_power + diffusion_times * (\n",
        "            self.end_noise_power - self.start_noise_power\n",
        "        )\n",
        "\n",
        "\n",
        "class CosineSchedule(DiffusionSchedule):\n",
        "    # noise rate increases sinusoidally\n",
        "    # signal rate decreases as a cosine function\n",
        "    # simplified from the \"cosine schedule\" of Improved DDPM https://arxiv.org/abs/2102.09672\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        #start_angle = tf.asin(self.start_noise_power**0.5)\n",
        "        #end_angle = tf.asin(self.end_noise_power**0.5)\n",
        "        start_angle = tf.acos(max_signal_rate)\n",
        "        end_angle = tf.acos(min_signal_rate)\n",
        "        \n",
        "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "        return tf.sin(diffusion_angles) ** 2\n",
        "\n",
        "\n",
        "class LogSNRLinearSchedule(DiffusionSchedule):\n",
        "    # the log signal-to-noise ratio decreases linearly\n",
        "    # proposed in VDM https://arxiv.org/abs/2107.00630\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.start_snr**diffusion_times / (\n",
        "            self.start_snr * self.end_snr**diffusion_times\n",
        "            + self.start_snr**diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class LogNoiseLinearSchedule(DiffusionSchedule):\n",
        "    # the log noise power increases linearly\n",
        "    # the noise power increases exponentially\n",
        "    # the ratio between next-step and current noise powers is constant\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return (\n",
        "            self.start_noise_power\n",
        "            * (self.end_noise_power / self.start_noise_power) ** diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class LogSignalLinearSchedule(DiffusionSchedule):\n",
        "    # the log signal power decreases linearly\n",
        "    # the signal power decreases exponentially\n",
        "    # the ratio between next-step and current signal powers is constant\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return (\n",
        "            1.0\n",
        "            - (1.0 - self.start_noise_power)\n",
        "            * ((1.0 - self.end_noise_power) / (1.0 - self.start_noise_power))\n",
        "            ** diffusion_times\n",
        "        )\n",
        "\n",
        "\n",
        "class NoiseStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current noise powers decreases approximately linearly to 1\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return self.end_noise_power * (\n",
        "            self.start_noise_power / self.end_noise_power\n",
        "        ) ** ((1.0 - diffusion_times) ** 2)\n",
        "\n",
        "\n",
        "class SignalStepLinearSchedule(DiffusionSchedule):\n",
        "    # the ratio between next-step and current signal powers decreases approximately linearly to 1\n",
        "    # similar to the \"linear schedule\" of DDPM https://arxiv.org/abs/2006.11239\n",
        "    def get_noise_powers(self, diffusion_times):\n",
        "        return 1.0 - (1.0 - self.start_noise_power) * (\n",
        "            (1.0 - self.end_noise_power) / (1.0 - self.start_noise_power)\n",
        "        ) ** (diffusion_times**2)"
      ],
      "metadata": {
        "id": "Z5U9ClBmdDxI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "QxyZaS_UJ_YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(tf.keras.layers.Layer):\n",
        "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights during initialization. These weights are fixed \n",
        "        # during optimization and are not trainable.\n",
        "        self.W = self.add_weight(shape=(embed_dim // 2,),\n",
        "                                 trainable=False,\n",
        "                                 initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.), name=\"GFP\") * tf.constant(scale, dtype=tf.float32)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        x_proj = x * self.W * tf.constant(2., dtype=tf.float32) * tf.constant(np.pi, dtype=tf.float32)\n",
        "        y = tf.concat([tf.math.sin(x_proj), tf.cos(x_proj)], axis=-1)\n",
        "        return y # Probleme vient pas de là :()\n",
        "\n",
        "class CustomLinear(tf.keras.layers.Layer):\n",
        "    \"\"\"Rhaaah.\"\"\"  \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.W = tf.random.uniform((input_dim, output_dim), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "        self.b = tf.random.uniform((1, output_dim, ), minval=-tf.math.sqrt(1/input_dim), maxval=tf.math.sqrt(1/input_dim))\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = tf.tensordot(x, self.W, 1) + self.b\n",
        "        y = tf.keras.activations.gelu(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "@tf.function\n",
        "def embedding_normalization(logits):\n",
        "    # normalement vont avoir taille (batch_size, sequence_size, embedding_size)\n",
        "    # axis=-1 is embedding normalement\n",
        "    return (logits / tf.norm(logits, axis=-1, keepdims=True)) * tf.constant(np.sqrt(logits.shape[-1]), dtype=tf.float32)\n",
        "\n",
        "class NormalizedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\"\"\"  \n",
        "    def __init__(self, categories_nb, img_embed_size):\n",
        "        super().__init__()\n",
        "        self.embed_layer = tf.keras.layers.Embedding(categories_nb, img_embed_size)\n",
        "        self.embed_layer2 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer3 = layers.Conv2D(img_embed_size, kernel_size=3, padding=\"same\", activation=keras.activations.swish)\n",
        "        self.embed_layer4 = layers.Conv2D(img_embed_size, kernel_size=1, activation=None)\n",
        "        self.layer_norm = layer = tf.keras.layers.LayerNormalization(axis=[1, 2])\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        y = self.embed_layer(x)\n",
        "        y = self.embed_layer2(y)\n",
        "        y = self.embed_layer3(y)\n",
        "        y = self.embed_layer4(y)\n",
        "        y = embedding_normalization(y)\n",
        "        y = self.layer_norm(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "Ej4nARwoGmme"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7V5eQBuUD0Y0"
      },
      "outputs": [],
      "source": [
        "def sinusoidal_embedding(x):\n",
        "    embedding_min_frequency = 1.0\n",
        "    frequencies = tf.exp(\n",
        "        tf.linspace(\n",
        "            tf.math.log(embedding_min_frequency),\n",
        "            tf.math.log(embedding_max_frequency),\n",
        "            embedding_dims // 2,\n",
        "        )\n",
        "    )\n",
        "    angular_speeds = 2.0 * math.pi * frequencies\n",
        "    embeddings = tf.concat(\n",
        "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
        "    )\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3]\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
        "        x = layers.Conv2D(\n",
        "            width, kernel_size=3, padding=\"same\", activation=keras.activations.swish\n",
        "        )(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def DownBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        for _ in range(block_depth):\n",
        "            x = ResidualBlock(width)(x)\n",
        "            skips.append(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def UpBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "        for _ in range(block_depth):\n",
        "            x = layers.Concatenate()([x, skips.pop()])\n",
        "            x = ResidualBlock(width)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def get_network(image_size, widths, block_depth, embed_size):\n",
        "    noisy_images = keras.Input(shape=(image_size[0], image_size[1], embed_size))\n",
        "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "    e = layers.UpSampling2D(size=image_size, interpolation=\"nearest\")(e)\n",
        "\n",
        "    x = layers.Conv2D(widths[0], kernel_size=1)(noisy_images)\n",
        "    x = layers.Concatenate()([x, e])\n",
        "\n",
        "    skips = []\n",
        "    for width in widths[:-1]:\n",
        "        x = DownBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1])(x)\n",
        "\n",
        "    for width in reversed(widths[:-1]):\n",
        "        x = UpBlock(width, block_depth)([x, skips])\n",
        "\n",
        "    x = layers.Conv2D(4, kernel_size=1, kernel_initializer=\"zeros\", activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model([noisy_images, noise_variances], x, name=\"residual_unet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network(\n",
        "    image_size,\n",
        "    noise_embedding_max_frequency,\n",
        "    noise_embedding_dims,\n",
        "    image_embedding_dims,\n",
        "    block_depth,\n",
        "    widths,\n",
        "    attentions,\n",
        "    patch_size,\n",
        "    embed_size\n",
        "):\n",
        "    def EmbeddingLayer(embedding_max_frequency, embedding_dims):\n",
        "        def sinusoidal_embedding(x):\n",
        "            embedding_min_frequency = 1.0\n",
        "            frequencies = tf.exp(\n",
        "                tf.linspace(\n",
        "                    tf.math.log(embedding_min_frequency),\n",
        "                    tf.math.log(embedding_max_frequency),\n",
        "                    embedding_dims // 2,\n",
        "                )\n",
        "            )\n",
        "            angular_speeds = 2.0 * math.pi * frequencies\n",
        "            embeddings = tf.concat(\n",
        "                [\n",
        "                    tf.sin(angular_speeds * x),\n",
        "                    tf.cos(angular_speeds * x),\n",
        "                ],\n",
        "                axis=3,\n",
        "            )\n",
        "            return embeddings\n",
        "\n",
        "        def forward(x):\n",
        "            x = layers.Lambda(sinusoidal_embedding)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def ResidualBlock(width, attention):\n",
        "        def forward(x):\n",
        "            x, n = x\n",
        "            input_width = x.shape[3]\n",
        "            if input_width == width:\n",
        "                residual = x\n",
        "            else:\n",
        "                residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "\n",
        "            n = layers.Dense(width)(n)\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([x, n])\n",
        "\n",
        "            x = tfa.layers.GroupNormalization(groups=8)(x)\n",
        "            x = keras.activations.swish(x)\n",
        "            x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "\n",
        "            x = layers.Add()([residual, x])\n",
        "\n",
        "            if attention:\n",
        "                residual = x\n",
        "                x = tfa.layers.GroupNormalization(groups=8, center=False, scale=False)(\n",
        "                    x\n",
        "                )\n",
        "                x = layers.MultiHeadAttention(\n",
        "                    num_heads=4, key_dim=width, attention_axes=(1, 2)\n",
        "                )(x, x)\n",
        "\n",
        "                x = layers.Add()([residual, x])\n",
        "\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def DownBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            for _ in range(block_depth):\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "                skips.append(x)\n",
        "            x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    def UpBlock(block_depth, width, attention):\n",
        "        def forward(x):\n",
        "            x, n, skips = x\n",
        "            x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "            for _ in range(block_depth):\n",
        "                x = layers.Concatenate()([x, skips.pop()])\n",
        "                x = ResidualBlock(width, attention)([x, n])\n",
        "            return x\n",
        "\n",
        "        return forward\n",
        "\n",
        "    images = keras.Input(shape=(image_size[0], image_size[1], embed_size))\n",
        "    noise_powers = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    x = layers.Conv2D(image_embedding_dims, kernel_size=patch_size, strides=patch_size)(\n",
        "        images\n",
        "    )\n",
        "\n",
        "    n = EmbeddingLayer(noise_embedding_max_frequency, noise_embedding_dims)(\n",
        "        noise_powers\n",
        "    )\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "    n = layers.Dense(noise_embedding_dims, activation=keras.activations.swish)(n)\n",
        "\n",
        "    skips = []\n",
        "    for width, attention in zip(widths[:-1], attentions[:-1]):\n",
        "        x = DownBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1], attentions[-1])([x, n])\n",
        "\n",
        "    for width, attention in zip(widths[-2::-1], attentions[-2::-1]):\n",
        "        x = UpBlock(block_depth, width, attention)([x, n, skips])\n",
        "\n",
        "    x = layers.Conv2DTranspose(\n",
        "        4, kernel_size=patch_size, strides=patch_size, kernel_initializer=\"zeros\", activation=\"softmax\"\n",
        "    )(x)\n",
        "\n",
        "    return keras.Model([images, noise_powers], x, name=\"residual_unet\")"
      ],
      "metadata": {
        "id": "IgeH9voVvsN5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling\n"
      ],
      "metadata": {
        "id": "XEMZlA-xdLcT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lZ37576YD0Y5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth, img_embed_size, categories_nb, embedding_lr=1e-3, batch_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        #embedding_dims = 32\n",
        "        #embedding_max_frequency = 1000.0\n",
        "        noise_embedding_max_frequency = 1000.0\n",
        "        noise_embedding_dims = 32\n",
        "        image_embedding_dims = 64\n",
        "        block_depth = 2\n",
        "        widths = [64, 128, 256, 512]\n",
        "        attentions = [False, False, True, True]\n",
        "        patch_size = 1\n",
        "\n",
        "        self.diffusion_schedule = SignalStepLinearSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        #self.diffusion_schedule = CosineSchedule(start_log_snr=3.0, end_log_snr=-10.0,)\n",
        "        self.network = get_network(image_size, noise_embedding_max_frequency,\n",
        "                                   noise_embedding_dims, image_embedding_dims,\n",
        "                                   block_depth, widths, attentions, patch_size,\n",
        "                                   img_embed_size)\n",
        "        \n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Embedding\n",
        "        self.img_embed_size = img_embed_size\n",
        "        self.embedding_layer = NormalizedEmbedding(categories_nb, img_embed_size)\n",
        "        self.emb_optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=embedding_lr)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.image_loss_tracker]\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
        "        # the exponential moving average weights are used at evaluation\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        # predict noise component and calculate the image component using it\n",
        "        pred_images = network([noisy_images, noise_rates**2], training=training)\n",
        "\n",
        "        return pred_images\n",
        "\n",
        "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "        # reverse diffusion = sampling\n",
        "        num_images = initial_noise.shape[0]\n",
        "        step_size = 1.0 / diffusion_steps\n",
        "\n",
        "        # important line:\n",
        "        # at the first sampling step, the \"noisy image\" is pure noise\n",
        "        # but its signal rate is assumed to be nonzero (min_signal_rate)\n",
        "        next_noisy_images = initial_noise\n",
        "        for step in range(diffusion_steps):\n",
        "            noisy_images = next_noisy_images\n",
        "\n",
        "            # separate the current noisy image to its components\n",
        "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
        "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=False\n",
        "            )\n",
        "            # network used in eval mode\n",
        "\n",
        "            # remix the predicted components using the next signal and noise rates\n",
        "            next_diffusion_times = diffusion_times - step_size\n",
        "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
        "                next_diffusion_times\n",
        "            )\n",
        "            next_noisy_images = (\n",
        "                next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
        "            )\n",
        "            # this new noisy image will be used in the next step\n",
        "\n",
        "        return pred_images\n",
        "\n",
        "    def generate(self, num_images, diffusion_steps):\n",
        "        # noise -> images -> denormalized images\n",
        "        initial_noise = tf.random.normal(shape=(num_images, image_size, image_size, 3))\n",
        "        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
        "        generated_images = self.denormalize(generated_images)\n",
        "        return generated_images\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            embed_images = self.embedding_layer(int_encoded_img)\n",
        "            noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True\n",
        "            )\n",
        "\n",
        "            image_loss = self.loss(images, pred_images)  # training loss\n",
        "            \n",
        "\n",
        "        gradients_model = tape1.gradient(image_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients_model, self.network.trainable_weights))\n",
        "\n",
        "        gradients_embeddings = tape2.gradient(image_loss, self.embedding_layer.trainable_weights)\n",
        "        self.emb_optimiser.apply_gradients(zip(gradients_embeddings, self.embedding_layer.trainable_weights))\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        # KID is not measured during the training phase for computational efficiency\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        noises = tf.random.normal(shape=(self.batch_size, self.image_size[0], self.image_size[1], self.img_embed_size))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        int_encoded_img = tf.argmax(images, axis=-1)\n",
        "\n",
        "        embed_images = self.embedding_layer(int_encoded_img)\n",
        "\n",
        "        #std = marginal_prob_std(diffusion_times, sigma=sigma)\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * embed_images + noise_rates * noises\n",
        "        #noisy_images = embed_images + noises * tf.reshape(std, (-1, 1, 1, 1))\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_images = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False\n",
        "        )\n",
        "\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYrG2VPD0Y7"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LHcHZit9D0Y8"
      },
      "outputs": [],
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth, img_embed_size=img_embed_size, categories_nb=categories_nb)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, batch_size=batch_size, epochs=100, validation_data=(x_test,))"
      ],
      "metadata": {
        "id": "RDSktS3wIy4C",
        "outputId": "363f51f2-4273-41c0-fcb5-f7c6c0ea8dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1025 - val_i_loss: 0.1097\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1145 - val_i_loss: 0.0725\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1026 - val_i_loss: 0.1160\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 112s 1s/step - i_loss: 0.1032 - val_i_loss: 0.0993\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 115s 1s/step - i_loss: 0.1032 - val_i_loss: 0.0872\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1005 - val_i_loss: 0.1130\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1029 - val_i_loss: 0.0925\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 114s 1s/step - i_loss: 0.1008 - val_i_loss: 0.0906\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 114s 1s/step - i_loss: 0.1024 - val_i_loss: 0.0833\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 114s 1s/step - i_loss: 0.0983 - val_i_loss: 0.1011\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.1030 - val_i_loss: 0.0858\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0967 - val_i_loss: 0.0996\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0974 - val_i_loss: 0.1060\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 112s 1s/step - i_loss: 0.0989 - val_i_loss: 0.0974\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0976 - val_i_loss: 0.0827\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 112s 1s/step - i_loss: 0.0918 - val_i_loss: 0.0984\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0937 - val_i_loss: 0.0833\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0916 - val_i_loss: 0.0912\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0886 - val_i_loss: 0.0880\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 114s 1s/step - i_loss: 0.0853 - val_i_loss: 0.0935\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 114s 1s/step - i_loss: 0.0921 - val_i_loss: 0.0853\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 113s 1s/step - i_loss: 0.0898 - val_i_loss: 0.0971\n",
            "Epoch 23/100\n",
            "75/92 [=======================>......] - ETA: 20s - i_loss: 0.0835"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f495ad5df106>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fky6ewS3D0Y-"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "def compute_beta(curr_alphas, prev_alphas):\n",
        "\n",
        "    betas = 1 - (prev_alphas / curr_alphas)\n",
        "    return betas"
      ],
      "metadata": {
        "id": "wVWp820FKVRV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import xla\n",
        "def ddpm_sampler(model, img_embed_size, batch_size=10, num_steps=350, eps=1e-3):\n",
        "    # T and schedule\n",
        "    t = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32)\n",
        "    noise_rates, signal_rates = model.diffusion_schedule(t)\n",
        "\n",
        "    # Sample noise\n",
        "    uniform_init_x = tf.random.uniform((batch_size, 64, 128), 0, 4, dtype=tf.dtypes.int32)\n",
        "    noises = tf.random.normal(shape=(batch_size, image_size[0], image_size[1], img_embed_size))\n",
        "    init_x = signal_rates * model.embedding_layer(uniform_init_x) + noise_rates * noises\n",
        "\n",
        "    # Keep track of the chain\n",
        "    samples_list = []\n",
        "    samples_list.append( tf.keras.backend.constant(keras.utils.to_categorical(uniform_init_x)))\n",
        "\n",
        "    # Steps and other algorithmic variables\n",
        "    time_steps = tf.linspace(1., eps, num_steps)\n",
        "    step_size = time_steps[0] - time_steps[1]\n",
        "    x = init_x\n",
        "    prev_alphas = signal_rates**2\n",
        "\n",
        "    # INFERENCE REVERSE LOOP\n",
        "    for time_step in tqdm.tqdm(time_steps):\n",
        "        batch_time_step = tf.ones((batch_size, 1, 1, 1), dtype=tf.float32) * time_step\n",
        "        noise_rates, signal_rates = model.diffusion_schedule(batch_time_step)\n",
        "        cur_alphas = signal_rates**2\n",
        "        betas = compute_beta(cur_alphas, prev_alphas)\n",
        "\n",
        "        # PREDICT IMAGE\n",
        "        pred_x0 = model.denoise(x, noise_rates, signal_rates, training=False)\n",
        "        int_encoded_img = tf.argmax(pred_x0, axis=-1)\n",
        "        embed_pred_x0 = model.embedding_layer(int_encoded_img)\n",
        "        \n",
        "        mean_x0 = tf.math.sqrt(cur_alphas) * betas / (1 - prev_alphas) * embed_pred_x0\n",
        "        mean_x = tf.math.sqrt(1 - betas) * (1 - cur_alphas) / (1 - prev_alphas) * x\n",
        "        x = mean_x + mean_x0 + tf.reshape(tf.math.sqrt(betas), (-1, 1, 1, 1)) * tf.random.normal(x.shape)\n",
        "\n",
        "        samples_list.append(pred_x0)\n",
        "        prev_alphas = cur_alphas\n",
        "\n",
        "    return pred_x0, samples_list"
      ],
      "metadata": {
        "id": "Krk0-qfIKNk1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Sampling (double click to expand or collapse)\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "## Load the pre-trained checkpoint from disk.\n",
        "\n",
        "sample_batch_size = 10 #@param {'type':'integer'}\n",
        "sampler = ddpm_sampler\n",
        "\n",
        "## Generate samples using the specified sampler.\n",
        "samples, samples_list = sampler(model,\n",
        "                                img_embed_size,\n",
        "                                sample_batch_size,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0uowLytML_4",
        "outputId": "4105839a-021b-432c-935f-1262a3b04d7b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [01:26<00:00,  4.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(sample_batch_size):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(np.argmax(samples[i].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4GzBJX-MUmk",
        "outputId": "3bac2cd1-f66a-412c-82c4-4f41b89766a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGVCAYAAABjBWf4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMSklEQVR4nO3c623cOACFUc9iOhp2YSBdpI5g60gXC7gLTk3cH9knMEokX4nU45yfhtamn5MPxN5ba629AQAABH4bfQAAAOD4hAUAABATFgAAQExYAAAAMWEBAADEhAUAABATFgAAQExYAAAAMWEBAADE7rOf/P224TH4W31/jD4CB1c+ni/fvtbP1tT739rU+bc+z9KP63cYoJ/vK72fryu9n6WO8lpSSp31nBsLAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgdmuttVlPWoU6hb2tDPB5ay1JjFp5Ojq/SwBchVUoAACgG2EBAADEhAUAABATFgAAQExYAAAAse6rUEdfrDn6+QHe3qxaATCfVSgAAKAbYQEAAMSEBQAAEBMWAABATFgAAACxzVahLI78nLWofZr6ud3j9+tIZ+X4/E0HuC6rUAAAQDfCAgAAiAkLAAAgJiwAAICYsAAAAGKzV6FqLVufhQ4sBrGVo68GnfV34yjrYUf/+QE4M6tQAABAN8ICAACICQsAACAmLAAAgJiwAAAAYlahuKS9LeL0YHVnXVf8GRrBzy0cw9K/iX63j8UqFAAA0I2wAAAAYsICAACICQsAACAmLAAAgJhVKAD+cZS1K4syAP1YhQIAALoRFgAAQExYAAAAMWEBAADEhAUAABC7jz4AANuZWnlauqo09fyoFamlH9eKFEe11u8w9ODGAgAAiAkLAAAgJiwAAICYsAAAAGLCAgAAiN1aa23Og7WWrc8CwF/WWoI5yqLMqHWpKXv7+gCMVEqd9ZwbCwAAICYsAACAmLAAAABiwgIAAIgJCwAAIGYVCoDd2tta1ChWqoCRrEIBAADdCAsAACAmLAAAgJiwAAAAYsICAACIWYUC4HCsRa1ranVq6uu89UrVWt/fpZ/X0vcDV2EVCgAA6EZYAAAAMWEBAADEhAUAABATFgAAQMwqFACnsbc1Ia5rb0tbU/Z2HvbJKhQAANCNsAAAAGLCAgAAiAkLAAAgJiwAAICYVaiNHWVt4Sjn5Nd8L2H/rEuxFX/r2YJVKAAAoBthAQAAxIQFAAAQExYAAEBMWAAAALHTrUIdfRFnraWQo3++Rzk/wEjWpdjK3l6Hl/6s7+38W9v631NWoQAAgG6EBQAAEBMWAABATFgAAAAxYQEAAMROtwoFALAm61v/utraEj9YhQIAALoRFgAAQExYAAAAMWEBAADEhAUAABCzCgUA0MnVFqasSJ2DVSgAAKAbYQEAAMSEBQAAEBMWAABATFgAAAAxq1CcwtTKhjUKAM7orOtSXrf3ySoUAADQjbAAAABiwgIAAIgJCwAAICYsAACAmFUoAICTO+uK1BTrUuuyCgUAAHQjLAAAgJiwAAAAYsICAACICQsAACBmFWqQqXUGKwYAwNFYnTo3q1AAAEA3wgIAAIgJCwAAICYsAACAmLAAAABiVqE2Zv0JAOD/rrYitdTe/p1oFQoAAOhGWAAAADFhAQAAxIQFAAAQExYAAEDMKhSwyFpLZxbTjsX3C+jBWlQfi1+zrUIBAAC9CAsAACAmLAAAgJiwAAAAYsICAACIWYUCAODSrFH9MLUWZRUKAADoRlgAAAAxYQEAAMSEBQAAEBMWAABAzCoUAABsaGp1amqFaeuPu9i3WbngxgIAAMgJCwAAICYsAACAmLAAAABiwgIAAIhZhQIAFhm1cANXt9bv3uK1KKtQAABAL8ICAACICQsAACAmLAAAgJiwAAAAYlahANitpQso1ooA1ldKnfWcGwsAACAmLAAAgJiwAAAAYsICAACICQsAACBmFQoAAJhkFQoAAOhGWAAAADFhAQAAxIQFAAAQExYAAEBMWAAAADFhAQAAxIQFAAAQExYAAEBMWAAAADFhAQAAxO6jDwAAR1E+ni/fXt8fnU8CsD9uLAAAgJiwAAAAYsICAACICQsAACAmLAAAgFi8CnXWhYyzfl4AfJ7XAIBpbiwAAICYsAAAAGLCAgAAiAkLAAAgJiwAAIDYrbXW5jxYa9n6LAAAwM6UUmc958YCAACICQsAACAmLAAAgJiwAAAAYsICAACICQsAACAmLAAAgJiwAAAAYsICAACICQsAACAmLAAAgNh99AGAffo+8favXU8BAByFGwsAACAmLAAAgJiwAAAAYsICAACICQsAACBmFQp4yfoTALCEGwsAACAmLAAAgJiwAAAAYsICAACICQsAACAmLAAAgJi52YspH89V3k99f6zycafez9LnGc/3DK7D7zvwihsLAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgdmuttTkP1lq2PgsAsAKrTcCaSqmznnNjAQAAxIQFAAAQExYAAEBMWAAAADFhAQAAxO6jDwAArMv6EzCCGwsAACAmLAAAgJiwAAAAYsICAACICQsAACBmFQoAADb0fP7x8u2Px5fOJ9mWGwsAACAmLAAAgJiwAAAAYsICAACICQsAACBmFWpnysfz5dvr+2PI+wEAIHO29acpbiwAAICYsAAAAGLCAgAAiAkLAAAgJiwAAIDYrbXW5jxYa9n6LACXs3TBzeLbunw9AX6tlDrrOTcWAABATFgAAAAxYQEAAMSEBQAAEBMWAABAzCoUXRxleWXqnD+zt88BAGBNVqEAAIBuhAUAABATFgAAQExYAAAAMWEBAADErEIBAMACo9Yut/64k+uY32blghsLAAAgJywAAICYsAAAAGLCAgAAiAkLAAAgZhUKAAAGmFxhmrB0/WmtFalS6qzn3FgAAAAxYQEAAMSEBQAAEBMWAABATFgAAACx++gD9LLW/xUPKT+LAHAto177e//bwo0FAAAQExYAAEBMWAAAADFhAQAAxIQFAAAQu7XW2pwHay1bn2URyzqwjN8ZAOAzSqmznnNjAQAAxIQFAAAQExYAAEBMWAAAADFhAQAAxO6jD/ArlmxgHX5n4Dq8dgIjuLEAAABiwgIAAIgJCwAAICYsAACAmLAAAABi3VehppYqpliwAIBlpl47rUUdz6jv2VF+Vo5yzqtwYwEAAMSEBQAAEBMWAABATFgAAAAxYQEAAMRurbU258Fay9ZngV+y/gDAXJYoP2+t11uv2+dQSp31nBsLAAAgJiwAAICYsAAAAGLCAgAAiAkLAAAgZhUKAKCTUStJ1plIWIUCAAC6ERYAAEBMWAAAADFhAQAAxIQFAAAQswoFrMLiCMDn+RvKnlmFAgAAuhEWAABATFgAAAAxYQEAAMSEBQAAELMKBf9hlQMYyd8gYI+sQgEAAN0ICwAAICYsAACAmLAAAABiwgIAAIhZhQKAnZtai9ra1BrVWuexdgXHYBUKAADoRlgAAAAxYQEAAMSEBQAAEBMWAABA7D76AADAzx19PWnp+adWp/b4dTjSWWFrbiwAAICYsAAAAGLCAgAAiAkLAAAgJiwAAIDYrbXW5jxYa9n6LAAAi00tM63FwhNXV0qd9ZwbCwAAICYsAACAmLAAAABiwgIAAIgJCwAAIHYffQAAgITVJtgHNxYAAEBMWAAAADFhAQAAxIQFAAAQExYAAEDMKhQAhMrH8+XbrRX94OsD1+DGAgAAiAkLAAAgJiwAAICYsAAAAGLCAgAAiN1aa23Og7WWrc8CAOzI8/nHoucfjy8bnQQYqZQ66zk3FgAAQExYAAAAMWEBAADEhAUAABATFgAAQOw++gAAwD5ZeQKWcGMBAADEhAUAABATFgAAQExYAAAAMWEBAADErEJBqHw8X769vj86nwQA4POm/k3zVub9924sAACAmLAAAABiwgIAAIgJCwAAICYsAACA2K211uY8WOvM/x0cAAA4jVLqrOfcWAAAADFhAQAAxIQFAAAQExYAAEBMWAAAALF77w9YPp4v317fH51PAgAArMWNBQAAEBMWAABATFgAAAAxYQEAAMSEBQAAEOu+CmX9CQAAzseNBQAAEBMWAABATFgAAAAxYQEAAMSEBQAAEBMWAABATFgAAAAxYQEAAMSEBQAAEBMWAABATFgAAACx++gDXFX5eL58e31/dD4JAADk3FgAAAAxYQEAAMSEBQAAEBMWAABATFgAAAAxq1CDWH8CAGCJva+KurEAAABiwgIAAIgJCwAAICYsAACAmLAAAABit9ZaG30IAADg2NxYAAAAMWEBAADEhAUAABATFgAAQExYAAAAMWEBAADEhAUAABATFgAAQExYAAAAsT8BYaicQ07dDkkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGVCAYAAABjBWf4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMa0lEQVR4nO3c0W3c2AGGUU2gjsQuDLgLI2UEW4e7MOAuqLTEPCyCdRLRIfUNySHnnMcBV74rj0b74WL/2zRN0wsAAEDwt6MPAAAAnJ+wAAAAMmEBAABkwgIAAMiEBQAAkAkLAAAgExYAAEAmLAAAgExYAAAA2evSB8dx2PIcAMCdDD/fP3x9/PK26dc/u3t9f+BqhmFc9JwbCwAAIBMWAABAJiwAAIBMWAAAAJmwAAAAsts0TdOSB61CAVzH2lWfs6zlbL2GBEsdtczlvc4WrEIBAAC7ERYAAEAmLAAAgExYAAAAmbAAAAAyq1AAXN5VV7DWsiQEfIZVKAAAYDfCAgAAyIQFAACQCQsAACATFgAAQPZ69AEAYGtzq0dr16LOzvoTsCU3FgAAQCYsAACATFgAAACZsAAAADJhAQAAZFahAHhaa1eStl6RstoEnJkbCwAAIBMWAABAJiwAAIBMWAAAAJmwAAAAMqtQAJzO3DrT1qtKVpsA5rmxAAAAMmEBAABkwgIAAMiEBQAAkAkLAAAgswoFOztqzQau5KifFz+/APPcWAAAAJmwAAAAMmEBAABkwgIAAMiEBQAAkN2maZqWPDiOw9ZnAQAAHswwjIuec2MBAABkwgIAAMiEBQAAkAkLAAAgExYAAEAmLAAAgExYAAAAmbAAAAAyYQEAAGTCAgAAyIQFAACQCQsAACATFgAAQCYsAACATFgAAACZsAAAADJhAQAAZMICAADIhAUAAJAJCwAAIBMWAABAJiwAAIBMWAAAANnr0QcAAPjV+/uPD19/e/u680mANdxYAAAAmbAAAAAyYQEAAGTCAgAAyIQFAACQPcwq1PDz/cPXxy9vO58E4Hx8hnIl1p+uw2fTc3FjAQAAZMICAADIhAUAAJAJCwAAIBMWAABAdpumaVry4DgOW5/lks6yhjB3zjmPdn4AALYxDOOi59xYAAAAmbAAAAAyYQEAAGTCAgAAyIQFAACQWYUC+I2zLLsBwFasQgEAALsRFgAAQCYsAACATFgAAACZsAAAALLXow8A8MisP+3D+hbA+bmxAAAAMmEBAABkwgIAAMiEBQAAkAkLAAAgswoFwOGsPwGcnxsLAAAgExYAAEAmLAAAgExYAAAAmbAAAAAyYQEAAGTCAgAAyIQFAACQCQsAACATFgAAQCYsAACATFgAAACZsAAAADJhAQAAZMICAADIhAUAAJAJCwAAIHs9+gD/Nvx8//D18cvbzicBAADWcmMBAABkwgIAAMiEBQAAkAkLAAAgExYAAEB2m6ZpWvTkH7cPX7baBACwjXutZq79Okf9uTymYRgXPefGAgAAyIQFAACQCQsAACATFgAAQCYsAACAbPEq1DgOW58FAAD+h3WpY1mFAgAAdiMsAACATFgAAACZsAAAADJhAQAAZK9HH+Dqvs+8/m3XU8D5WQQBeF4+68/BjQUAAJAJCwAAIBMWAABAJiwAAIBMWAAAANltmqZpyYPjOGx9locyt+a0NWtRPLutf/au+jNmNQuArQzDuOg5NxYAAEAmLAAAgExYAAAAmbAAAAAyYQEAAGRWoR6MZRcAeCxzv5tfXvx+5jlYhQIAAHYjLAAAgExYAAAAmbAAAAAyYQEAAGRWoQAu7HdrNh+xcPOY3t9/rHr+7e3rRicBnpFVKAAAYDfCAgAAyIQFAACQCQsAACATFgAAQGYVCnY2t9JjjQcAeERWoQAAgN0ICwAAIBMWAABAJiwAAIBMWAAAANnr0QeAe/g+8/q3XU+xzKOtP1mpYgtz76s53m/wXPzuuSY3FgAAQCYsAACATFgAAACZsAAAADJhAQAAZLdpmqYlD47jsPVZgAuy/AEA5zYM46Ln3FgAAACZsAAAADJhAQAAZMICAADIhAUAAJC9Hn0A4NqsPwHAc3BjAQAAZMICAADIhAUAAJAJCwAAIBMWAABAZhUKNjL8fP/wdStJAMAVubEAAAAyYQEAAGTCAgAAyIQFAACQCQsAACCzCgUbsf4EABxpbqFy/Rda9pgbCwAAIBMWAABAJiwAAIBMWAAAAJmwAAAAsrwKNfd/m1vEAQCA9e625rQzNxYAAEAmLAAAgExYAAAAmbAAAAAyYQEAAGTCAgAAyBbPzZqVBQCA9c46H7uWGwsAACATFgAAQCYsAACATFgAAACZsAAAALLFq1DWnwCuw9IfwOdddeVp7nfAsPCfd2MBAABkwgIAAMiEBQAAkAkLAAAgExYAAEB2m6ZpWvLgOC79/8EBAOA4V11tOsw/FuWCGwsAAKATFgAAQCYsAACATFgAAACZsAAAALLXow8AAAC/c/aVp/HL29FH+A9z38+5cy7dhnVjAQAAZMICAADIhAUAAJAJCwAAIBMWAABAZhUKAIBFzr7OdC+PtvK01lbnd2MBAABkwgIAAMiEBQAAkAkLAAAgExYAAEBmFQoA4Ek928rT2decHp0bCwAAIBMWAABAJiwAAIBMWAAAAJmwAAAAMqtQAAAXcfaVJ6tN5+bGAgAAyIQFAACQCQsAACATFgAAQCYsAACAzCoUXMzcIoilDYDreLT1J79jeHlxYwEAANyBsAAAADJhAQAAZMICAADIhAUAAJBZhYJfXGFR6UxnBXg21py4MjcWAABAJiwAAIBMWAAAAJmwAAAAMmEBAABkp12FusJ6D4/H+weAe7D+xDNyYwEAAGTCAgAAyIQFAACQCQsAACATFgAAQHbaVai16wZWpACAq/DfLzwiNxYAAEAmLAAAgExYAAAAmbAAAAAyYQEAAGR5FeqotaW5P/eor3OUe32f7/V9OMvf+5lY/gB4XGf5/Ql7cGMBAABkwgIAAMiEBQAAkAkLAAAgExYAAEB2m6ZpWvLgOA6rvvAzrvew3twKhvfP51kWAdjP2t9XPqM5o2EYFz3nxgIAAMiEBQAAkAkLAAAgExYAAEAmLAAAgGzxKtTLH7eNj3KMtesM1oq4mnstlMz9bFhAAc7uM7/7ffZxJVahAACA3QgLAAAgExYAAEAmLAAAgExYAAAA2cOvQj3bqsKzrU4d9fe79vu8xzmf7e9+rWf7LAD2d8/PYZ9ZXIlVKAAAYDfCAgAAyIQFAACQCQsAACATFgAAQLZ4FWoch7v8gXOLC9YTYB0rUn/y2QHbecQFvS3N/fv+/cB/r2+H/cnwF6tQAADAboQFAACQCQsAACATFgAAQCYsAACAbPdVKOAYz7YidfZ1GqB7f/+x6vl/vn3d6CR/sfLEGVmFAgAAdiMsAACATFgAAACZsAAAADJhAQAAZFahgE1ZowKOMvf54+eUpbyH/mQVCgAA2I2wAAAAMmEBAABkwgIAAMiEBQAAkFmFAh7Ks61IrfVsSySwhOUe2JZVKAAAYDfCAgAAyIQFAACQCQsAACATFgAAQGYVCrgk61KfY0UHgP9mFQoAANiNsAAAADJhAQAAZMICAADIhAUAAJBZhYJobn3Iug6/uupKlfc5wPVZhQIAAHYjLAAAgExYAAAAmbAAAAAyYQEAAGRWoYAPWbv6nKuuP92L9w/A+ViFAgAAdiMsAACATFgAAACZsAAAADJhAQAAZFahYCNr14Hm1nLu9XW4trOvUXnfAjwuq1AAAMBuhAUAAJAJCwAAIBMWAABAJiwAAIDMKhTAEzr7itScrdelvs+8/m3TPxXgWFahAACA3QgLAAAgExYAAEAmLAAAgExYAAAA2cOvQs0tl2y9/AHA/7f2M/rR1qjmzrl2/Wnu+TlWpIAzsQoFAADsRlgAAACZsAAAADJhAQAAZMICAADIHn4VCoDrO8talKVC4BlZhQIAAHYjLAAAgExYAAAAmbAAAAAyYQEAAGSvRx8AAB7N2pWqtc9bnQKuyI0FAACQCQsAACATFgAAQCYsAACATFgAAADZbZqmacmD4zhsfRY4pXutuFiDgeXWrjBdlc8HYA/DMC56zo0FAACQCQsAACATFgAAQCYsAACATFgAAACZVSgALsNa1O9ZkQI+wyoUAACwG2EBAABkwgIAAMiEBQAAkAkLAAAgswoFwNOyIrUPa1RwblahAACA3QgLAAAgExYAAEAmLAAAgExYAAAA2evRBwCAo6xdK7rXitS9VpKOWrWy8vS8vq98/tvM63PvXe+tc3NjAQAAZMICAADIhAUAAJAJCwAAIBMWAABAdpumaTr6EAAAwLm5sQAAADJhAQAAZMICAADIhAUAAJAJCwAAIBMWAABAJiwAAIBMWAAAAJmwAAAAsn8BrlhFq5OKjdcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPQ7NDoqwnPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmxTCPcGwnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRU4hxdwwnVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27KyMR50wnX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JOV1lK-wnbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ihlTCKtwneG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raise TypeError(\"NAN MAIS VOUS VOUS RENDEZ COMPTE A QUELLE ALLURE VOUS ALLIEZ MONSIEUR ?\") "
      ],
      "metadata": {
        "id": "A-BmWGiFwnjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIF"
      ],
      "metadata": {
        "id": "8X9v42ujwnt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "images = []\n",
        "for i, batch in enumerate(samples_list):\n",
        "    figure = plt.figure(figsize=(10, 5))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Timestep {0:.3f}\".format(1 - (i / 350)))\n",
        "    plt.imshow(np.argmax(batch[0].numpy(), axis=-1).reshape((64, 128)),\n",
        "                interpolation='nearest', cmap=cmap, norm=norm)\n",
        "    plt.savefig('foo.png', bbox_inches='tight')\n",
        "    images.append(imageio.imread('foo.png'))\n",
        "    plt.show() #close(figure)\n",
        "imageio.mimsave('/movie.gif', images)"
      ],
      "metadata": {
        "id": "m9JzX8pVMf7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ddim",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}